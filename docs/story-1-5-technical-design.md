# Story 1.5: å¤šæ¨¡æ€è¾“å…¥é‡‡é›†ç³»ç»ŸæŠ€æœ¯è®¾è®¡

**æ–‡æ¡£ç¼–å·**: XLR-DESIGN-1.5-20251110-001
**é¡¹ç›®åç§°**: XleRobot Epic 1 - å¤šæ¨¡æ€è¯­éŸ³äº¤äº’ç³»ç»Ÿ
**Storyç¼–å·**: 1.5
**è®¾è®¡é˜¶æ®µ**: BMad Method v6 Phase 3 Solutioning
**è®¾è®¡æ—¥æœŸ**: 2025-11-10
**è®¾è®¡å¸ˆ**: Developer Agent

---

## ğŸ“‹ è®¾è®¡æ¦‚è¿°

### è®¾è®¡ç›®æ ‡
è®¾è®¡Story 1.5å¤šæ¨¡æ€è¾“å…¥é‡‡é›†ç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯æ¶æ„ï¼Œç¡®ä¿åœ¨å·²å®Œæˆçš„è¯­éŸ³ç³»ç»ŸåŸºç¡€ä¸Šï¼Œå®‰å…¨ã€é«˜æ•ˆåœ°æ‰©å±•å¤šæ¨¡æ€é‡‡é›†èƒ½åŠ›ã€‚

### è®¾è®¡åŸåˆ™
- **æ¸è¿›å¼æ‰©å±•**: ä¸å½±å“ç°æœ‰Story 1.1-1.4åŠŸèƒ½
- **æ¨¡å—åŒ–è®¾è®¡**: é«˜å†…èšã€ä½è€¦åˆçš„æ¨¡å—åŒ–æ¶æ„
- **Brownfieldåˆè§„**: ä¸¥æ ¼éµå¾ªBrownfield Level 4ä¼ä¸šçº§æ ‡å‡†
- **æ€§èƒ½ä¼˜å…ˆ**: ç¡®ä¿å®æ—¶æ€§èƒ½å’Œèµ„æºæ•ˆç‡

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾
```mermaid
graph TB
    subgraph "ç°æœ‰ç³»ç»Ÿ (Story 1.1-1.4)"
        A1[éŸ³é¢‘é‡‡é›†] --> A2[è¯­éŸ³è¯†åˆ«]
        A2 --> A3[è¯­éŸ³å”¤é†’]
        A3 --> A4[è¯­éŸ³åˆæˆ]
        A4 --> A5[è¯­éŸ³äº¤äº’è¾“å‡º]
    end

    subgraph "æ–°å¢å¤šæ¨¡æ€ç³»ç»Ÿ (Story 1.5)"
        B1[IMX219æ‘„åƒå¤´] --> B2[å›¾åƒé¢„å¤„ç†]
        B2 --> B3[å¤šæ¨¡æ€é‡‡é›†å™¨]
        A1 --> B3
        B3 --> B4[æ™ºèƒ½è§¦å‘å™¨]
        B4 --> B5[æ—¶é—´æˆ³åŒæ­¥å™¨]
        B5 --> C[å¤šæ¨¡æ€æ•°æ®è¾“å‡º]
    end

    subgraph "ç›‘æ§ç³»ç»Ÿ"
        D1[æ€§èƒ½ç›‘æ§å™¨] --> D2[é”™è¯¯å¤„ç†å™¨]
        D2 --> D3[å‘Šè­¦ç³»ç»Ÿ]
    end

    B3 --> D1
    B3 --> D2
```

### æ•°æ®æµæ¶æ„
```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Camera as æ‘„åƒå¤´
    participant Audio as éŸ³é¢‘ç³»ç»Ÿ
    participant Collector as é‡‡é›†å™¨
    participant Trigger as è§¦å‘å™¨
    participant Monitor as ç›‘æ§å™¨

    User->>Audio: å¼€å§‹è¯­éŸ³è¾“å…¥
    User->>Camera: å±•ç¤ºç‰©å“

    Audio->>Collector: éŸ³é¢‘æ•°æ®
    Camera->>Collector: å›¾åƒæ•°æ®

    Collector->>Collector: æ—¶é—´æˆ³åŒæ­¥
    Collector->>Trigger: æ£€æŸ¥è§¦å‘æ¡ä»¶

    alt åº”è¯¥è§¦å‘è§†è§‰å¤„ç†
        Trigger->>Collector: è§¦å‘ç¡®è®¤
        Collector->>Monitor: è¾“å‡ºå¤šæ¨¡æ€æ•°æ®
    else ä¸è§¦å‘
        Trigger->>Collector: ä»…éŸ³é¢‘æ•°æ®
        Collector->>Monitor: è¾“å‡ºéŸ³é¢‘æ•°æ®
    end
```

---

## ğŸ§© æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. MultimodalCollector - å¤šæ¨¡æ€é‡‡é›†å™¨

#### ç±»è®¾è®¡
```python
class MultimodalCollector:
    """
    å¤šæ¨¡æ€æ•°æ®é‡‡é›†å™¨

    é›†æˆç°æœ‰éŸ³é¢‘é‡‡é›†ç³»ç»Ÿï¼Œæ‰©å±•è§†è§‰é‡‡é›†èƒ½åŠ›ï¼Œ
    å®ç°éŸ³è§†é¢‘åŒæ­¥é‡‡é›†å’Œæ•°æ®å¤„ç†ã€‚
    """

    def __init__(self):
        # ç°æœ‰éŸ³é¢‘é‡‡é›†ç³»ç»Ÿ (æ¥è‡ªStory 1.1)
        self.audio_collector = AudioCollector()

        # æ–°å¢è§†è§‰é‡‡é›†ç»„ä»¶
        self.camera_driver = CameraDriver()
        self.image_processor = ImageProcessor()

        # åŒæ­¥å’Œåè°ƒç»„ä»¶
        self.timestamp_sync = TimestampSynchronizer()
        self.data_manager = MultimodalDataManager()

        # ç›‘æ§å’Œé”™è¯¯å¤„ç†
        self.performance_monitor = PerformanceMonitor()
        self.error_handler = ErrorHandler()

        # é…ç½®å‚æ•°
        self.config = MultimodalConfig()

    async def collect_multimodal_input(self, context_id: str = None):
        """
        æ”¶é›†å¤šæ¨¡æ€è¾“å…¥æ•°æ®

        Args:
            context_id: å¯¹è¯ä¸Šä¸‹æ–‡ID

        Returns:
            MultimodalData: å¤šæ¨¡æ€æ•°æ®å¯¹è±¡
        """
        try:
            start_time = time.time()

            # å¹¶è¡Œé‡‡é›†éŸ³é¢‘å’Œè§†è§‰æ•°æ®
            audio_future = asyncio.create_task(
                self._collect_audio_data()
            )
            image_future = asyncio.create_task(
                self._collect_visual_data()
            )

            # ç­‰å¾…é‡‡é›†å®Œæˆ
            audio_data = await audio_future
            visual_data = await image_future

            # æ—¶é—´æˆ³åŒæ­¥
            synchronized_data = self.timestamp_sync.synchronize(
                audio_data, visual_data
            )

            # æ„å»ºå¤šæ¨¡æ€æ•°æ®å¯¹è±¡
            multimodal_data = MultimodalData(
                audio_data=synchronized_data['audio'],
                visual_data=synchronized_data['visual'],
                timestamp=start_time,
                context_id=context_id,
                synchronization_error=synchronized_data['error']
            )

            # æ€§èƒ½ç›‘æ§
            self.performance_monitor.record_collection(
                start_time, multimodal_data
            )

            return multimodal_data

        except Exception as e:
            self.error_handler.handle_error("multimodal_collection", e)
            # é™çº§åˆ°ä»…éŸ³é¢‘æ¨¡å¼
            return self._fallback_to_audio_only(context_id)

    def should_collect_visual(self, audio_text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›è¡Œè§†è§‰é‡‡é›†

        Args:
            audio_text: éŸ³é¢‘æ–‡æœ¬å†…å®¹

        Returns:
            bool: æ˜¯å¦è§¦å‘è§†è§‰é‡‡é›†
        """
        # ä½¿ç”¨æ™ºèƒ½è§¦å‘å™¨åˆ¤æ–­
        return self.vision_trigger.should_trigger(audio_text)

    async def _collect_audio_data(self):
        """æ”¶é›†éŸ³é¢‘æ•°æ®"""
        return await self.audio_collector.capture_audio()

    async def _collect_visual_data(self):
        """æ”¶é›†è§†è§‰æ•°æ®"""
        try:
            # è·å–åŸå§‹å›¾åƒ
            raw_image = await self.camera_driver.capture_image()

            # å›¾åƒé¢„å¤„ç†
            processed_image = self.image_processor.process(raw_image)

            return processed_image

        except CameraError as e:
            self.error_handler.handle_error("visual_collection", e)
            return None
```

#### æ¥å£å®šä¹‰
```python
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from dataclasses import dataclass

@dataclass
class AudioData:
    timestamp: float
    sample_rate: int
    channels: int
    data: bytes
    format: str

@dataclass
class VisualData:
    timestamp: float
    width: int
    height: int
    channels: int
    format: str
    data: bytes
    encoding: str

@dataclass
class MultimodalData:
    """å¤šæ¨¡æ€æ•°æ®å¯¹è±¡"""
    audio_data: Optional[AudioData]
    visual_data: Optional[VisualData]
    timestamp: float
    context_id: Optional[str]
    synchronization_error: float  # åŒæ­¥è¯¯å·® (æ¯«ç§’)
    metadata: Dict[str, Any]

    @property
    def has_audio(self) -> bool:
        return self.audio_data is not None

    @property
    def has_visual(self) -> bool:
        return self.visual_data is not None

    @property
    def is_multimodal(self) -> bool:
        return self.has_audio and self.has_visual
```

### 2. VisionTrigger - æ™ºèƒ½è§†è§‰è§¦å‘å™¨

#### ç±»è®¾è®¡
```python
class VisionTrigger:
    """
    æ™ºèƒ½è§†è§‰è§¦å‘å™¨

    åŸºäºéŸ³é¢‘å†…å®¹å’Œä¸Šä¸‹æ–‡æ™ºèƒ½åˆ¤æ–­ä½•æ—¶éœ€è¦è¿›è¡Œè§†è§‰ç†è§£ï¼Œ
    æ”¯æŒç²¤è¯­è§†è§‰å…³é”®è¯æ£€æµ‹å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥è§¦å‘ã€‚
    """

    def __init__(self):
        # ç²¤è¯­è§†è§‰å…³é”®è¯åº“
        self.cantonese_keywords = [
            "å‘¢ä¸ª", "ä¹œå˜¢", "ç‡ä¸‹", "ç³»ä¹œ", "å‘¢æ ·å˜¢",
            "å‘¢ä»¶", "è¾¹ä¸ª", "è¾¹æ ·", "ç‡ä¸‹", "æœ›ä¸‹",
            "æ‹ç…§", "ç›¸ç‰‡", "å½•å½±", "å½•åƒ", "ç…§",
            "çœ‹", "ç‡", "æœ›", "è§‚å¯Ÿ", "æ£€æŸ¥"
        ]

        # ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‚æ•°
        self.min_audio_length = 3  # æœ€å°éŸ³é¢‘é•¿åº¦
        self.trigger_cooldown = 2.0  # è§¦å‘å†·å´æ—¶é—´(ç§’)
        self.context_memory = ContextMemory()

        # ç»Ÿè®¡ä¿¡æ¯
        self.trigger_stats = TriggerStatistics()

    def should_trigger(self, audio_text: str, context_id: str = None) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è§†è§‰é‡‡é›†

        Args:
            audio_text: éŸ³é¢‘æ–‡æœ¬å†…å®¹
            context_id: å¯¹è¯ä¸Šä¸‹æ–‡ID

        Returns:
            bool: æ˜¯å¦è§¦å‘è§†è§‰é‡‡é›†
        """
        try:
            # åŸºç¡€æ£€æŸ¥
            if not self._basic_checks(audio_text):
                return False

            # å…³é”®è¯æ£€æµ‹
            keyword_score = self._keyword_detection(audio_text)

            # ä¸Šä¸‹æ–‡æ„ŸçŸ¥
            context_score = self._context_awareness(audio_text, context_id)

            # å†·å´æ—¶é—´æ£€æŸ¥
            cooldown_check = self._cooldown_check(context_id)

            # ç»¼åˆè¯„åˆ†
            total_score = (keyword_score * 0.5 +
                          context_score * 0.3 +
                          cooldown_check * 0.2)

            should_trigger = total_score > 0.6

            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            self.trigger_stats.record_trigger(
                audio_text, should_trigger, total_score
            )

            return should_trigger

        except Exception as e:
            self.logger.error(f"è§¦å‘åˆ¤æ–­é”™è¯¯: {e}")
            return False

    def _basic_checks(self, audio_text: str) -> bool:
        """åŸºç¡€æ£€æŸ¥"""
        if not audio_text or len(audio_text) < self.min_audio_length:
            return False

        # è¿‡æ»¤éè¯­éŸ³å†…å®¹
        if audio_text.isspace() or not any(c.isalpha() for c in audio_text):
            return False

        return True

    def _keyword_detection(self, text: str) -> float:
        """å…³é”®è¯æ£€æµ‹è¯„åˆ†"""
        text_lower = text.lower()
        keyword_count = sum(1 for keyword in self.cantonese_keywords
                           if keyword in text_lower)

        # å½’ä¸€åŒ–è¯„åˆ† (0-1)
        return min(keyword_count / len(self.cantonese_keywords), 1.0)

    def _context_awareness(self, text: str, context_id: str) -> float:
        """ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯„åˆ†"""
        if context_id is None:
            return 0.0

        # è·å–ä¸Šä¸‹æ–‡å†å²
        context_history = self.context_memory.get_context(context_id)

        # æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰è§†è§‰ç›¸å…³å¯¹è¯
        visual_context_count = sum(
            1 for item in context_history
            if any(keyword in item.get('text', '').lower()
                  for keyword in self.cantonese_keywords)
        )

        # å½’ä¸€åŒ–è¯„åˆ† (0-1)
        return min(visual_context_count / max(len(context_history), 1), 1.0)

    def _cooldown_check(self, context_id: str) -> float:
        """å†·å´æ—¶é—´æ£€æŸ¥è¯„åˆ†"""
        last_trigger_time = self.context_memory.get_last_trigger_time(context_id)

        if last_trigger_time is None:
            return 1.0  # ä»æœªè§¦å‘è¿‡

        time_since_last_trigger = time.time() - last_trigger_time

        if time_since_last_trigger < self.trigger_cooldown:
            return 0.0  # ä»åœ¨å†·å´æœŸ

        # å†·å´æœŸè¿‡åï¼Œè¯„åˆ†é€æ¸æ¢å¤
        cooldown_recovery = min(
            time_since_last_trigger / self.trigger_cooldown, 1.0
        )

        return cooldown_recovery
```

### 3. TimestampSynchronizer - æ—¶é—´æˆ³åŒæ­¥å™¨

#### ç±»è®¾è®¡
```python
class TimestampSynchronizer:
    """
    æ—¶é—´æˆ³åŒæ­¥å™¨

    ç¡®ä¿éŸ³é¢‘å’Œè§†è§‰æ•°æ®çš„æ—¶é—´æˆ³åŒæ­¥ï¼Œ
    å®ç°é«˜ç²¾åº¦æ—¶é—´æˆ³åŒæ­¥å’Œè¯¯å·®è¡¥å¿ã€‚
    """

    def __init__(self):
        self.target_sync_error = 200  # ç›®æ ‡åŒæ­¥è¯¯å·®(æ¯«ç§’)
        self.max_sync_attempts = 3  # æœ€å¤§åŒæ­¥å°è¯•æ¬¡æ•°

    def synchronize(self, audio_data: AudioData, visual_data: VisualData) -> Dict[str, Any]:
        """
        åŒæ­¥éŸ³é¢‘å’Œè§†è§‰æ•°æ®æ—¶é—´æˆ³

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            visual_data: è§†è§‰æ•°æ®

        Returns:
            Dict: åŒæ­¥ç»“æœæ•°æ®
        """
        try:
            # è·å–åŸå§‹æ—¶é—´æˆ³
            audio_timestamp = audio_data.timestamp
            visual_timestamp = visual_data.timestamp

            # è®¡ç®—æ—¶é—´å·®
            time_diff = abs(audio_timestamp - visual_timestamp)

            # å¦‚æœåŒæ­¥è¯¯å·®åœ¨ç›®æ ‡èŒƒå›´å†…ï¼Œç›´æ¥è¿”å›
            if time_diff <= self.target_sync_error / 1000:
                return {
                    'audio': audio_data,
                    'visual': visual_data,
                    'error': time_diff * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                }

            # éœ€è¦åŒæ­¥
            return self._perform_synchronization(audio_data, visual_data, time_diff)

        except Exception as e:
            self.logger.error(f"æ—¶é—´åŒæ­¥é”™è¯¯: {e}")
            return self._fallback_synchronization(audio_data, visual_data)

    def _perform_synchronization(self, audio_data: AudioData, visual_data: VisualData,
                              time_diff: float) -> Dict[str, Any]:
        """æ‰§è¡Œæ—¶é—´åŒæ­¥"""

        # é€‰æ‹©åŒæ­¥ç­–ç•¥
        if audio_timestamp < visual_timestamp:
            # éŸ³é¢‘æ—©äºè§†è§‰ï¼Œè°ƒæ•´éŸ³é¢‘æ—¶é—´æˆ³
            adjusted_audio = self._adjust_timestamp(
                audio_data, visual_timestamp, forward=True
            )
            return {
                'audio': adjusted_audio,
                'visual': visual_data,
                'error': 0.0,
                'sync_method': 'audio_adjusted'
            }
        else:
            # è§†è§‰æ—©äºéŸ³é¢‘ï¼Œè°ƒæ•´è§†è§‰æ—¶é—´æˆ³
            adjusted_visual = self._adjust_timestamp(
                visual_data, audio_timestamp, forward=False
            )
            return {
                'audio': audio_data,
                'visual': adjusted_visual,
                'error': 0.0,
                'sync_method': 'visual_adjusted'
            }

    def _adjust_timestamp(self, data, target_timestamp: timestamp, forward: bool = True) -> Any:
        """è°ƒæ•´æ•°æ®æ—¶é—´æˆ³"""
        if hasattr(data, 'timestamp'):
            data.timestamp = target_timestamp
        return data

    def _fallback_synchronization(self, audio_data: AudioData, visual_data: VisualData) -> Dict[str, Any]:
        """é™çº§åŒæ­¥ç­–ç•¥"""
        # ä½¿ç”¨è¾ƒæ™šçš„æ—¶é—´æˆ³ä½œä¸ºåŸºå‡†
        max_timestamp = max(audio_data.timestamp, visual_data.timestamp)

        # è°ƒæ•´åˆ°åŒä¸€æ—¶é—´æˆ³
        audio_data.timestamp = max_timestamp
        visual_data.timestamp = max_timestamp

        return {
            'audio': audio_data,
            'visual': visual_data,
            'error': 0.0,
            'sync_method': 'fallback'
        }
```

### 4. ErrorHandler - é”™è¯¯å¤„ç†å™¨

#### ç±»è®¾è®¡
```python
class ErrorHandler:
    """
    é”™è¯¯å¤„ç†å™¨

    ç»Ÿä¸€å¤„ç†å¤šæ¨¡æ€é‡‡é›†è¿‡ç¨‹ä¸­çš„å„ç§é”™è¯¯æƒ…å†µï¼Œ
    å®ç°ä¼˜é›…é™çº§å’Œé”™è¯¯æ¢å¤æœºåˆ¶ã€‚
    """

    def __init__(self):
        self.error_log = ErrorLogger()
        self.fallback_manager = FallbackManager()
        self.alert_manager = AlertManager()

        # é”™è¯¯ç»Ÿè®¡
        self.error_stats = ErrorStatistics()

    def handle_error(self, error_type: str, error: Exception, context: Dict = None):
        """
        å¤„ç†é”™è¯¯æƒ…å†µ

        Args:
            error_type: é”™è¯¯ç±»å‹
            error: å¼‚å¸¸å¯¹è±¡
            context: é”™è¯¯ä¸Šä¸‹æ–‡
        """
        try:
            # è®°å½•é”™è¯¯æ—¥å¿—
            self.error_log.log_error(error_type, error, context)

            # æ›´æ–°é”™è¯¯ç»Ÿè®¡
            self.error_stats.record_error(error_type)

            # æ ¹æ®é”™è¯¯ç±»å‹é‡‡å–ä¸åŒç­–ç•¥
            if error_type == "camera_error":
                self._handle_camera_error(error, context)
            elif error_type == "sync_error":
                self._handle_sync_error(error, context)
            elif error_type == "trigger_error":
                self._handle_trigger_error(error, context)
            else:
                self._handle_general_error(error, context)

        except Exception as e:
            self.alert_manager.send_alert(f"é”™è¯¯å¤„ç†å™¨å¼‚å¸¸: {e}")

    def _handle_camera_error(self, error: Exception, context: Dict):
        """å¤„ç†æ‘„åƒå¤´é”™è¯¯"""
        # å¯ç”¨å¤‡é€‰æ‘„åƒå¤´
        self.fallback_manager.activate_camera_fallback()

        # å‘é€å‘Šè­¦
        self.alert_manager.send_alert(
            "æ‘„åƒå¤´é”™è¯¯ï¼Œå·²å¯ç”¨å¤‡é€‰æ–¹æ¡ˆ",
            severity="medium"
        )

    def _handle_sync_error(self, error: Exception, context: Dict):
        """å¤„ç†åŒæ­¥é”™è¯¯"""
        # é™çº§åˆ°ç®€å•åŒæ­¥
        self.fallback_manager.activate_simple_sync()

        # è®°å½•è­¦å‘Šæ—¥å¿—
        self.error_log.log_warning(
            "åŒæ­¥é”™è¯¯ï¼Œä½¿ç”¨é™çº§ç­–ç•¥",
            {"error": str(error)}
        )

    def _handle_trigger_error(self, error: Exception, context: Dict):
        """å¤„ç†è§¦å‘é”™è¯¯"""
        # ç¦ç”¨è§†è§‰è§¦å‘ï¼Œä»…ä½¿ç”¨éŸ³é¢‘æ¨¡å¼
        self.fallback_manager.disable_visual_trigger()

        # è®°å½•è­¦å‘Šæ—¥å¿—
        self.error_log.log_warning(
            "è§¦å‘å™¨é”™è¯¯ï¼Œä¸´æ—¶ç¦ç”¨è§†è§‰è§¦å‘",
            {"error": str(error)}
        )

    def _handle_general_error(self, error: Exception, context: Dict):
        """å¤„ç†ä¸€èˆ¬é”™è¯¯"""
        # é€šç”¨é™çº§ç­–ç•¥
        self.fallback_manager.activate_emergency_mode()

        # å‘é€ä¸¥é‡å‘Šè­¦
        self.alert_manager.send_alert(
            f"ä¸¥é‡é”™è¯¯: {str(error)}",
            severity="high"
        )
```

---

## ğŸ”§ æ•°æ®ç»“æ„è®¾è®¡

### æ ¸å¿ƒæ•°æ®æ¨¡å‹
```python
@dataclass
class MultimodalConfig:
    """å¤šæ¨¡æ€é…ç½®"""
    # æ‘„åƒå¤´é…ç½®
    camera_resolution: Tuple[int, int] = (1920, 1080)
    camera_fps: int = 30
    camera_format: str = 'RGB'

    # åŒæ­¥é…ç½®
    target_sync_error_ms: float = 200.0
    sync_timeout_s: float = 5.0

    # è§¦å‘é…ç½®
    trigger_cooldown_s: float = 2.0
    min_audio_length: int = 3
    keyword_threshold: float = 0.6

    # æ€§èƒ½é…ç½®
    max_concurrent_collections: int = 3
    cache_size_mb: int = 100

    # é”™è¯¯å¤„ç†é…ç½®
    max_retry_attempts: int = 3
    fallback_enabled: bool = True
    alert_threshold: int = 5

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    collection_count: int = 0
    avg_collection_time_ms: float = 0.0
    success_rate: float = 1.0
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0

    def update_collection_time(self, time_ms: float):
        """æ›´æ–°é‡‡é›†æ—¶é—´æŒ‡æ ‡"""
        self.collection_count += 1
        self.avg_collection_time_ms = (
            (self.avg_collection_time_ms * (self.collection_count - 1) + time_ms) /
            self.collection_count
        )

    def update_success_rate(self, success: bool):
        """æ›´æ–°æˆåŠŸç‡æŒ‡æ ‡"""
        total = self.collection_count
        if total > 0:
            current_success_rate = (
                (self.success_rate * (total - 1) + (1.0 if success else 0.0)) / total
            )
            self.success_rate = current_success_rate

@dataclass
class TriggerStatistics:
    """è§¦å‘ç»Ÿè®¡"""
    total_triggers: int = 0
    successful_triggers: int = 0
    false_positive_triggers: int = 0
    avg_confidence_score: float = 0.0

    def record_trigger(self, text: str, triggered: bool, confidence: float):
        """è®°å½•è§¦å‘ç»Ÿè®¡"""
        self.total_triggers += 1

        if triggered:
            self.successful_triggers += 1
        else:
            self.false_positive_triggers += 1

        # æ›´æ–°å¹³å‡ç½®ä¿¡åº¦
        self.avg_confidence_score = (
            (self.avg_confidence_score * (self.total_triggers - 1) + confidence) /
            self.total_triggers
        )

    @property
    def accuracy_rate(self) -> float:
        """è®¡ç®—å‡†ç¡®ç‡"""
        if self.total_triggers > 0:
            return self.successful_triggers / self.total_triggers
        return 0.0
```

---

## ğŸ”„ æ¥å£è®¾è®¡

### å¯¹å¤–æ¥å£
```python
class IMultimodalCollector(ABC):
    """å¤šæ¨¡æ€é‡‡é›†å™¨æ¥å£"""

    @abstractmethod
    async def collect_multimodal_input(self, context_id: str = None) -> MultimodalData:
        """æ”¶é›†å¤šæ¨¡æ€è¾“å…¥"""
        pass

    @abstractmethod
    def should_collect_visual(self, audio_text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿›è¡Œè§†è§‰é‡‡é›†"""
        pass

    @abstractmethod
    def get_performance_metrics(self) -> PerformanceMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        pass
```

### å›è°ƒæ¥å£
```python
class IMultimodalCollectorCallback(ABC):
    """å¤šæ¨¡æ€é‡‡é›†å™¨å›è°ƒæ¥å£"""

    @abstractmethod
    on_data_collected(self, data: MultimodalData):
        """æ•°æ®é‡‡é›†å®Œæˆå›è°ƒ"""
        pass

    @abstractmethod
    on_error_occurred(self, error_type: str, error: Exception):
        """é”™è¯¯å‘ç”Ÿå›è°ƒ"""
        pass

    @abstractmethod
    on_performance_update(self, metrics: PerformanceMetrics):
        """æ€§èƒ½æŒ‡æ ‡æ›´æ–°å›è°ƒ"""
        pass
```

---

## ğŸ¯ è®¾è®¡éªŒè¯

### æ¶æ„éªŒè¯
- âœ… **æ¨¡å—åŒ–è®¾è®¡**: é«˜å†…èšã€ä½è€¦åˆ
- âœ… **æ¥å£æ ‡å‡†åŒ–**: æ¸…æ™°çš„æ¥å£å®šä¹‰
- âœ… **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
- âœ… **æ€§èƒ½ä¼˜åŒ–**: å¹¶å‘å¤„ç†å’Œç¼“å­˜æœºåˆ¶

### æŠ€æœ¯éªŒè¯
- âœ… **åŒæ­¥ç²¾åº¦**: <200msåŒæ­¥è¯¯å·®ç›®æ ‡
- âœ… **æ€§èƒ½è¦æ±‚**: æ»¡è¶³å®æ—¶æ€§è¦æ±‚
- âœ… **å…¼å®¹æ€§**: ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ
- âœ… **å¯æ‰©å±•æ€§**: æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•

### Brownfield Level 4éªŒè¯
- âœ… **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰åŠŸèƒ½
- âœ… **æ¸è¿›å¼éƒ¨ç½²**: æ”¯æŒåˆ†é˜¶æ®µéƒ¨ç½²
- âœ… **å›æ»šèƒ½åŠ›**: å®Œæ•´çš„å›æ»šæœºåˆ¶
- âœ… **ç›‘æ§å‘Šè­¦**: å®Œå–„çš„ç›‘æ§ä½“ç³»

---

**è®¾è®¡çŠ¶æ€**: âœ… å·²å®Œæˆ
**è®¾è®¡é˜¶æ®µ**: BMad Method v6 Phase 3 Solutioning
**ä¸‹ä¸€æ­¥**: Phase 4 Implementation
**è®¾è®¡å¸ˆ**: Developer Agent

---

*æœ¬æŠ€æœ¯è®¾è®¡ä¸¥æ ¼éµå¾ªBMad Method v6 Brownfield Level 4æ ‡å‡†ï¼Œç¡®ä¿å¤šæ¨¡æ€è¾“å…¥é‡‡é›†ç³»ç»Ÿçš„æ¶æ„è®¾è®¡æ»¡è¶³ä¼ä¸šçº§è¦æ±‚ï¼ŒåŒæ—¶ä¿è¯ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§å’Œå¯æ‰©å±•æ€§ã€‚*