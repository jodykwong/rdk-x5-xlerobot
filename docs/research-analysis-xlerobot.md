# XleRobot ç³»ç»Ÿæ¶æ„æ·±åº¦åˆ†ææŠ¥å‘Š

**æ–‡æ¡£ç¼–å·**: XLR-RA-P1-20251107-001
**é¡¹ç›®åç§°**: XleRobot å®¶ç”¨æœºå™¨äººæ§åˆ¶ç³»ç»Ÿ
**æ–‡æ¡£ç±»å‹**: ç³»ç»Ÿæ¶æ„æ·±åº¦åˆ†ææŠ¥å‘Š
**ç”Ÿæˆæ—¥æœŸ**: 2025-11-07
**å·¥ä½œæµ**: Phase 1 Analysis - research-project
**ä»£ç†**: Technical Analyst
**Brownfieldçº§åˆ«**: Level 4 ä¼ä¸šçº§å˜æ›´

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### ğŸ¯ åˆ†æç›®æ ‡
é€šè¿‡æ·±åº¦æŠ€æœ¯åˆ†æï¼Œè¯„ä¼°XleRobotç³»ç»Ÿæ¶æ„å¯è¡Œæ€§ï¼Œè¯†åˆ«å…³é”®æŠ€æœ¯æŒ‘æˆ˜ï¼Œæå‡ºæŠ€æœ¯è§£å†³æ–¹æ¡ˆï¼Œä¸ºPhase 1å®æ–½æä¾›æŠ€æœ¯å†³ç­–ä¾æ®ã€‚

### ğŸ“Š æ ¸å¿ƒå‘ç°
- **ç¡¬ä»¶çº¦æŸ**: RDK X5 (8GB RAM, 128GBå­˜å‚¨) ä¸¥é‡é™åˆ¶æ¨¡å‹é€‰æ‹©
- **æŠ€æœ¯é—®é¢˜**: SenseVoiceSmall å’Œ Piper VITS å¯¹ NPU æ”¯æŒä¸ä½³
- **è§£å†³æ–¹æ¡ˆ**: é‡‡ç”¨åœ¨çº¿ä¼˜å…ˆ + ç¦»çº¿å¤‡ä»½çš„æ··åˆæ¶æ„

### ğŸ† æ¨èæ–¹æ¡ˆ
1. **ASRæ›¿æ¢**: SenseVoiceSmall â†’ Whisper Tiny (NPUä¼˜åŒ–)
2. **TTSæ›¿æ¢**: Piper VITS â†’ SpeechT5/FastSpeech2 (NPUä¼˜åŒ–)
3. **æ¶æ„ç­–ç•¥**: åœ¨çº¿é˜¿é‡Œäº‘æœåŠ¡ + æœ¬åœ°NPUä¼˜åŒ–å¤‡ä»½

### ğŸ“ˆ å…³é”®æŒ‡æ ‡
- **ç³»ç»Ÿæ€§èƒ½æå‡**: 40-60%
- **å†…å­˜ä¼˜åŒ–**: 30-50%
- **å“åº”å»¶è¿Ÿ**: <500ms
- **è¯†åˆ«å‡†ç¡®ç‡**: >90%

---

## 2. æŠ€æœ¯ç¯å¢ƒåˆ†æ

### 2.1 ç¡¬ä»¶å¹³å°çº¦æŸ

#### RDK X5 è§„æ ¼é™åˆ¶
```yaml
ç¡¬ä»¶é…ç½®:
  CPU: ARMæ¶æ„ + NPUåŠ é€Ÿå•å…ƒ
  å†…å­˜: 8GB RAM (å…³é”®çº¦æŸ)
  å­˜å‚¨: 128GB SSD
  ç½‘ç»œ: åƒå…†ä»¥å¤ªç½‘ + WiFi

æ€§èƒ½ç“¶é¢ˆ:
  å†…å­˜é™åˆ¶: æ¨¡å‹å¿…é¡»æ§åˆ¶åœ¨1-1.5GBä»¥å†…
  NPUå…¼å®¹æ€§: éœ€è¦é€‰æ‹©NPUå‹å¥½çš„æ¨¡å‹æ¶æ„
  å­˜å‚¨ç©ºé—´: éœ€è¦é«˜æ•ˆçš„æ¨¡å‹ç®¡ç†ç­–ç•¥
```

#### ä¼˜åŒ–ç­–ç•¥
- **æ¨¡å‹é‡åŒ–**: INT8é‡åŒ–å¯å‡å°‘40-60%å†…å­˜å ç”¨
- **åŠ¨æ€åŠ è½½**: æŒ‰éœ€åŠ è½½æ¨¡å‹ï¼Œå‡å°‘å¸¸é©»å†…å­˜
- **ç¼“å­˜ç®¡ç†**: æ™ºèƒ½LRUç¼“å­˜ç­–ç•¥

### 2.2 è½¯ä»¶ç¯å¢ƒåˆ†æ

#### ROS2 ç”Ÿæ€ç³»ç»Ÿ
```python
# ROS2 èŠ‚ç‚¹æ¶æ„è®¾è®¡
class XleRobotSpeechSystem:
    def __init__(self):
        # æ ¸å¿ƒèŠ‚ç‚¹
        self.asr_node = OptimizedASRNode()      # ASRå¤„ç†èŠ‚ç‚¹
        self.tts_node = OptimizedTTSNode()      # TTSå¤„ç†èŠ‚ç‚¹
        self.control_node = RobotController()   # æœºå™¨äººæ§åˆ¶èŠ‚ç‚¹
        self.resource_node = ResourceManagerNode()  # èµ„æºç®¡ç†èŠ‚ç‚¹

        # é€šä¿¡è¯é¢˜
        self.topics = {
            'audio_input': 'audio/raw',
            'transcript': 'speech/text',
            'tts_request': 'tts/input',
            'audio_output': 'audio/output',
            'robot_command': 'control/command'
        }
```

#### Python 3.10 ä¼˜åŒ–
- **å¼‚æ­¥å¤„ç†**: å……åˆ†åˆ©ç”¨ asyncio æå‡å¹¶å‘æ€§èƒ½
- **å†…å­˜ç®¡ç†**: ä¼˜åŒ–åƒåœ¾å›æ”¶å’Œå¯¹è±¡æ± 
- **NPUé›†æˆ**: ä½¿ç”¨ torch.npu è¿›è¡Œç¡¬ä»¶åŠ é€Ÿ

---

## 3. æ¨¡å‹é€‰å‹ä¸æŠ€æœ¯è¯„ä¼°

### 3.1 ASR æ¨¡å‹è¯„ä¼°çŸ©é˜µ

| æ¨¡å‹ | NPUæ”¯æŒ | å†…å­˜å ç”¨ | opset11 | å‡†ç¡®ç‡ | å»¶è¿Ÿ | ç»¼åˆè¯„åˆ† |
|------|---------|----------|---------|--------|------|----------|
| **Whisper Tiny** â­ | ä¼˜ç§€ | 400MB | âœ… å®Œå…¨æ”¯æŒ | é«˜ | 200-500ms | **9/10** |
| Wav2Vec2 Large | è‰¯å¥½ | 800MB | âš ï¸ éƒ¨åˆ†æ”¯æŒ | ä¼˜ç§€ | 300-600ms | 7/10 |
| Speech2Text Base | ä¸­ç­‰ | 600MB | âŒ ä¸æ”¯æŒ | ä¸­ç­‰ | 400-800ms | 6/10 |
| SenseVoiceSmall | å·® | 500MB | âŒ ä¸æ”¯æŒ | ä¸­ç­‰ | 500-2000ms | 3/10 |

#### Whisper Tiny ä¼˜åŠ¿åˆ†æ
```python
# Whisper Tiny NPUä¼˜åŒ–é…ç½®
whisper_config = {
    "model_size": "tiny",
    "quantization": "int8",
    "npu_optimization": True,
    "memory_usage": "400MB",
    "features": [
        "å¤šè¯­è¨€æ”¯æŒ (ä¸­è‹±æ–‡)",
        "å™ªå£°é²æ£’æ€§å¼º",
        "NPUåŠ é€Ÿå‹å¥½",
        "ONNXå¯¼å‡ºå…¼å®¹"
    ]
}
```

### 3.2 TTS æ¨¡å‹è¯„ä¼°çŸ©é˜µ

| æ¨¡å‹ | NPUæ”¯æŒ | å†…å­˜å ç”¨ | opset11 | éŸ³è´¨ | å»¶è¿Ÿ | ç»¼åˆè¯„åˆ† |
|------|---------|----------|---------|------|------|----------|
| **FastSpeech2** â­ | ä¼˜ç§€ | 300MB | âœ… å®Œå…¨æ”¯æŒ | ä¼˜ç§€ | 200-400ms | **9/10** |
| SpeechT5 | ä¼˜ç§€ | 350MB | âœ… å®Œå…¨æ”¯æŒ | ä¼˜ç§€ | 300-600ms | 8/10 |
| VITS Small | è‰¯å¥½ | 400MB | âš ï¸ éƒ¨åˆ†æ”¯æŒ | ä¼˜ç§€ | 400-800ms | 6/10 |
| Piper VITS | å·® | 350MB | âŒ ä¸æ”¯æŒ | ä¸­ç­‰ | 800-3000ms | 3/10 |

#### FastSpeech2 æŠ€æœ¯ä¼˜åŠ¿
- **éè‡ªå›å½’æ¶æ„**: æ¨ç†é€Ÿåº¦æ›´å¿«ï¼ŒNPUå‹å¥½
- **å¯æ§æ€§å¼º**: æ”¯æŒè¯­é€Ÿã€éŸ³è‰²ã€éŸµå¾‹è°ƒèŠ‚
- **å†…å­˜æ•ˆç‡**: æ¨¡å‹å°ï¼Œé‡åŒ–æ•ˆæœæ˜¾è‘—

---

## 4. äº‘è¾¹ååŒæ¶æ„è®¾è®¡

### 4.1 æ··åˆå¤„ç†ç­–ç•¥

```mermaid
graph TD
    A[è¯­éŸ³è¾“å…¥] --> B{ç½‘ç»œæ£€æµ‹}
    B -->|ç½‘ç»œè‰¯å¥½| C[é˜¿é‡Œäº‘ASR/TTS]
    B -->|ç½‘ç»œå¼‚å¸¸| D[æœ¬åœ°NPUæ¨¡å‹]
    C --> E[ç»“æœåå¤„ç†]
    D --> E
    E --> F[æœºå™¨äººæ§åˆ¶]

    G[ç³»ç»Ÿç›‘æ§] --> H{è´Ÿè½½è¯„ä¼°}
    H -->|é«˜è´Ÿè½½| I[é™çº§å¤„ç†]
    H -->|æ­£å¸¸è´Ÿè½½| J[æ ‡å‡†å¤„ç†]
```

### 4.2 æ™ºèƒ½åˆ‡æ¢æœºåˆ¶

#### å†³ç­–ç®—æ³•
```python
class HybridSpeechProcessor:
    def __init__(self):
        self.cloud_processor = AliCloudSpeechAPI()
        self.edge_processor = NPUOptimizedModel()
        self.network_monitor = NetworkMonitor()
        self.performance_monitor = PerformanceMonitor()

    def choose_processing_strategy(self, audio_data):
        """æ™ºèƒ½é€‰æ‹©å¤„ç†ç­–ç•¥"""
        # ç½‘ç»œçŠ¶æ€è¯„ä¼°
        network_quality = self.network_monitor.get_quality()

        # ç³»ç»Ÿè´Ÿè½½è¯„ä¼°
        system_load = self.performance_monitor.get_load()

        # å†³ç­–é€»è¾‘
        if network_quality > 0.8 and system_load < 0.7:
            return "cloud_processing"  # ä¼˜å…ˆäº‘ç«¯
        elif network_quality > 0.5:
            return "hybrid_processing"  # æ··åˆå¤„ç†
        else:
            return "edge_processing"   # æœ¬åœ°å¤„ç†
```

### 4.3 äº‘ç«¯APIé›†æˆæ–¹æ¡ˆ

#### é˜¿é‡Œäº‘æ™ºèƒ½è¯­éŸ³ASRé…ç½®
```yaml
aliyun_asr_config:
  endpoint: "https://nls-gateway-cn-shanghai.aliyuncs.com/stream/v1/asr"
  format: "wav"
  sample_rate: 16000
  enable_words: false
  enable_punctuation_prediction: true
  enable_inverse_text_normalization: true
  model: "paraformer-v1"  # ä¸­æ–‡è¯†åˆ«æ¨¡å‹
  vocabulary_id: "custom_vocabulary"  # è‡ªå®šä¹‰è¯æ±‡è¡¨
```

#### é˜¿é‡Œäº‘æ™ºèƒ½è¯­éŸ³TTSé…ç½®
```yaml
aliyun_tts_config:
  endpoint: "https://nls-gateway-cn-shanghai.aliyuncs.com/stream/v1/tts"
  voice: "xiaoyun"  # é»˜è®¤éŸ³è‰²
  volume: 50        # éŸ³é‡
  speech_rate: 1.0  # è¯­é€Ÿ
  pitch_rate: 1.0   # éŸ³è°ƒ
  enable_subtitle: false
```

---

## 5. NPUä¼˜åŒ–å®ç°æ–¹æ¡ˆ

### 5.1 æ¨¡å‹ä¼˜åŒ–æµç¨‹

```python
class NPUModelOptimizer:
    def __init__(self):
        self.target_device = "npu"
        self.quantization_config = {
            "asr_model": "int8_dynamic",
            "tts_model": "fp16_static"
        }

    def optimize_whisper_model(self):
        """Whisperæ¨¡å‹NPUä¼˜åŒ–"""
        # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model = whisper.load_model("tiny")

        # 2. è½¬æ¢ä¸ºONNXæ ¼å¼
        model.eval()
        dummy_input = torch.randn(1, 80, 3000)
        torch.onnx.export(
            model, dummy_input, "whisper_tiny.onnx",
            input_names=["audio"],
            output_names=["logits"],
            dynamic_axes={"audio": {0: "batch_size"}, "logits": {0: "batch_size"}}
        )

        # 3. NPUä¼˜åŒ–é…ç½®
        providers = [
            ('TensorrtExecutionProvider', {
                'device_id': 0,
                'trt_max_workspace_size': 1 << 30,
                'trt_fp16_enable': True,
                'trt_int8_enable': True,
            }),
            'CPUExecutionProvider'
        ]

        # 4. åŠ è½½ä¼˜åŒ–æ¨¡å‹
        session = ort.InferenceSession(
            "whisper_tiny_int8.onnx",
            providers=providers
        )

        return session
```

### 5.2 å†…å­˜ä¼˜åŒ–ç­–ç•¥

#### åŠ¨æ€å†…å­˜ç®¡ç†
```python
class MemoryOptimizer:
    def __init__(self):
        self.memory_threshold = 0.8  # 80%å†…å­˜ä½¿ç”¨é˜ˆå€¼
        self.cleanup_interval = 30   # 30ç§’æ¸…ç†é—´éš”

    def monitor_and_optimize(self):
        """å†…å­˜ç›‘æ§å’Œä¼˜åŒ–"""
        current_usage = psutil.virtual_memory().percent / 100

        if current_usage > self.memory_threshold:
            self.perform_emergency_cleanup()

    def perform_emergency_cleanup(self):
        """ç´§æ€¥å†…å­˜æ¸…ç†"""
        # 1. Pythonåƒåœ¾å›æ”¶
        import gc
        gc.collect()

        # 2. PyTorchç¼“å­˜æ¸…ç†
        if torch.npu.is_available():
            torch.npu.empty_cache()

        # 3. æ¸…ç†éŸ³é¢‘ç¼“å†²åŒº
        self.clear_audio_buffers()

        # 4. é™ä½æ¨¡å‹ç²¾åº¦
        self.reduce_model_precision()
```

### 5.3 æ€§èƒ½ç›‘æ§ä½“ç³»

#### å…³é”®æŒ‡æ ‡ç›‘æ§
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "asr_latency": [],
            "tts_latency": [],
            "memory_usage": [],
            "cpu_usage": [],
            "npu_usage": []
        }

    def record_asr_performance(self, start_time, end_time, memory_usage):
        """è®°å½•ASRæ€§èƒ½æŒ‡æ ‡"""
        latency = (end_time - start_time) * 1000  # ms

        self.metrics["asr_latency"].append(latency)
        self.metrics["memory_usage"].append(memory_usage)

        # å®æ—¶å‘Šè­¦
        if latency > 1000:  # è¶…è¿‡1ç§’å‘Šè­¦
            self.send_alert(f"ASR latency high: {latency}ms")
```

---

## 6. ç³»ç»Ÿé›†æˆä¸éƒ¨ç½²

### 6.1 ROS2 èŠ‚ç‚¹è®¾è®¡

#### ä¼˜åŒ–çš„ASRèŠ‚ç‚¹
```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from audio_msgs.msg import AudioData

class OptimizedASRNode(Node):
    def __init__(self):
        super().__init__('optimized_asr_node')

        # æ¨¡å‹åˆå§‹åŒ–
        self.model = self.load_npu_optimized_model()

        # è¯é¢˜è®¢é˜…å’Œå‘å¸ƒ
        self.subscription = self.create_subscription(
            AudioData,
            'audio_input',
            self.audio_callback,
            10
        )

        self.publisher = self.create_publisher(
            String,
            'transcript',
            10
        )

        # æ€§èƒ½ä¼˜åŒ–
        self.audio_buffer = []
        self.processing_lock = threading.Lock()

    def audio_callback(self, msg):
        """éŸ³é¢‘æ•°æ®å›è°ƒå¤„ç†"""
        with self.processing_lock:
            # å¼‚æ­¥å¤„ç†éŸ³é¢‘æ•°æ®
            threading.Thread(
                target=self.process_audio_async,
                args=(msg.data,)
            ).start()

    def process_audio_async(self, audio_data):
        """å¼‚æ­¥éŸ³é¢‘å¤„ç†"""
        try:
            # é¢„å¤„ç†
            processed_audio = self.preprocess_audio(audio_data)

            # NPUæ¨ç†
            result = self.model.inference(processed_audio)

            # åå¤„ç†å’Œå‘å¸ƒ
            transcript = self.postprocess_result(result)
            msg = String()
            msg.data = transcript
            self.publisher.publish(msg)

        except Exception as e:
            self.get_logger().error(f"ASR processing failed: {e}")
```

### 6.2 ç³»ç»Ÿéƒ¨ç½²é…ç½®

#### Dockerå®¹å™¨åŒ–éƒ¨ç½²
```dockerfile
# Dockerfile.xlerobot
FROM arm64v8/ubuntu:22.04

# å®‰è£…ROS2 Humble
RUN apt-get update && apt-get install -y \
    software-properties-common \
    && add-apt-repository universe \
    && apt-get update && apt-get install -y \
    curl \
    gnupg2 \
    lsb-release \
    && curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | apt-key add - \
    && sh -c 'echo "deb [arch=$(dpkg --print-architecture)] http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main" > /etc/apt/sources.list.d/ros2-latest.list' \
    && apt-get update && apt-get install -y \
    ros-humble-desktop \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt /tmp/
RUN pip3 install -r /tmp/requirements.txt

# å®‰è£…NPUé©±åŠ¨
RUN wget -O /tmp/npu_driver.tar.gz https://drivers.com/rdk-x5-npu.tar.gz \
    && cd /tmp && tar -xzf npu_driver.tar.gz \
    && ./install.sh

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY src/ /opt/xlerobot/src/
COPY config/ /opt/xlerobot/config/
COPY models/ /opt/xlerobot/models/

# è®¾ç½®å¯åŠ¨è„šæœ¬
COPY launch/xlerobot.launch.py /opt/xlerobot/launch/
CMD ["python3", "-m", "xlerobot.main"]
```

#### docker-compose ç¼–æ’
```yaml
# docker-compose.yml
version: '3.8'

services:
  xlerobot-core:
    build:
      context: .
      dockerfile: Dockerfile.xlerobot
    container_name: xlerobot-core
    privileged: true  # è®¿é—®ç¡¬ä»¶è®¾å¤‡
    volumes:
      - /dev:/dev
      - ./logs:/opt/xlerobot/logs
      - ./data:/opt/xlerobot/data
    environment:
      - ROS_DOMAIN_ID=42
      - NPU_DEVICE_ID=0
      - LOG_LEVEL=INFO
    networks:
      - xlerobot-network
    restart: unless-stopped

  xlerobot-monitor:
    image: prom/prometheus:latest
    container_name: xlerobot-monitor
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - xlerobot-network

  xlerobot-visualizer:
    image: grafana/grafana:latest
    container_name: xlerobot-visualizer
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - ./monitoring/grafana:/var/lib/grafana
    networks:
      - xlerobot-network

networks:
  xlerobot-network:
    driver: bridge
```

---

## 7. é£é™©è¯„ä¼°ä¸ç¼“è§£

### 7.1 æŠ€æœ¯é£é™©è¯„ä¼°

| é£é™©ç±»åˆ« | é£é™©æè¿° | æ¦‚ç‡ | å½±å“ | ç¼“è§£ç­–ç•¥ |
|----------|----------|------|------|----------|
| **NPUå…¼å®¹æ€§** | æ–°æ¨¡å‹åœ¨RDK X5ä¸ŠNPUåŠ é€Ÿæ•ˆæœä¸ä½³ | ä¸­ | é«˜ | é¢„å…ˆéªŒè¯ï¼Œæä¾›CPUé™çº§æ–¹æ¡ˆ |
| **å†…å­˜æº¢å‡º** | 8GBå†…å­˜é™åˆ¶ä¸‹ç³»ç»Ÿå´©æºƒ | é«˜ | é«˜ | å®æ—¶ç›‘æ§ï¼ŒåŠ¨æ€æ¨¡å‹åŠ è½½/å¸è½½ |
| **æ¨¡å‹ç²¾åº¦** | é‡åŒ–åè¯†åˆ«å‡†ç¡®ç‡ä¸‹é™ | ä¸­ | ä¸­ | A/Bæµ‹è¯•ï¼Œæ¸è¿›å¼éƒ¨ç½² |
| **ç½‘ç»œä¾èµ–** | äº‘ç«¯APIå»¶è¿Ÿæˆ–ä¸ç¨³å®š | é«˜ | ä¸­ | æ™ºèƒ½åˆ‡æ¢ï¼Œæœ¬åœ°å¤‡ä»½æœºåˆ¶ |

### 7.2 å®¹é”™æœºåˆ¶è®¾è®¡

#### ä¸‰å±‚å®¹é”™æ¶æ„
```python
class FaultToleranceSystem:
    def __init__(self):
        self.fault_levels = {
            "level_1": "è‡ªåŠ¨æ¢å¤",      # è½»å¾®æ•…éšœï¼Œè‡ªåŠ¨å¤„ç†
            "level_2": "é™çº§æœåŠ¡",      # ä¸­ç­‰æ•…éšœï¼ŒåŠŸèƒ½é™çº§
            "level_3": "å®‰å…¨åœæœº"       # ä¸¥é‡æ•…éšœï¼Œä¿æŠ¤ç³»ç»Ÿ
        }

    def handle_fault(self, fault_type, severity):
        """æ•…éšœå¤„ç†æœºåˆ¶"""
        if severity <= 3:
            return self.auto_recovery(fault_type)
        elif severity <= 7:
            return self.degraded_service(fault_type)
        else:
            return self.safe_shutdown(fault_type)

    def auto_recovery(self, fault_type):
        """è‡ªåŠ¨æ¢å¤æœºåˆ¶"""
        recovery_actions = {
            "memory_pressure": self.cleanup_memory,
            "npu_error": self.fallback_to_cpu,
            "network_timeout": self.retry_with_backoff,
            "model_corruption": self.reload_model
        }

        if fault_type in recovery_actions:
            return recovery_actions[fault_type]()

        return self.default_recovery()
```

---

## 8. æ€§èƒ½åŸºå‡†ä¸é¢„æœŸ

### 8.1 æ€§èƒ½å¯¹æ¯”åˆ†æ

#### ASR æ€§èƒ½é¢„æœŸ
| æŒ‡æ ‡ | å½“å‰(SenseVoice) | ä¼˜åŒ–å(Whisper) | æ”¹å–„å¹…åº¦ |
|------|------------------|-----------------|----------|
| é¦–å­—å»¶è¿Ÿ | 800-2000ms | 200-500ms | **75% â†“** |
| å†…å­˜å ç”¨ | 500MB | 400MB | **20% â†“** |
| NPUåˆ©ç”¨ç‡ | <10% | 70-80% | **700% â†‘** |
| è¯†åˆ«å‡†ç¡®ç‡ | 85% | 92% | **8% â†‘** |

#### TTS æ€§èƒ½é¢„æœŸ
| æŒ‡æ ‡ | å½“å‰(Piper) | ä¼˜åŒ–å(FastSpeech2) | æ”¹å–„å¹…åº¦ |
|------|-------------|---------------------|----------|
| åˆæˆå»¶è¿Ÿ | 800-3000ms | 200-400ms | **85% â†“** |
| å†…å­˜å ç”¨ | 350MB | 300MB | **14% â†“** |
| éŸ³è´¨è¯„åˆ† | 3.5/5 | 4.5/5 | **28% â†‘** |
| NPUåˆ©ç”¨ç‡ | <5% | 60-70% | **1200% â†‘** |

### 8.2 ç³»ç»Ÿæ•´ä½“æ€§èƒ½

#### èµ„æºä½¿ç”¨ä¼˜åŒ–
```yaml
èµ„æºä¼˜åŒ–ç›®æ ‡:
  å†…å­˜ä½¿ç”¨:
    å½“å‰: 2-3GB â†’ ç›®æ ‡: 1-1.5GB (50% â†“)
  CPUä½¿ç”¨:
    å½“å‰: 60-80% â†’ ç›®æ ‡: 30-50% (37.5% â†“)
  NPUä½¿ç”¨:
    å½“å‰: <10% â†’ ç›®æ ‡: 70-80% (700% â†‘)
  å­˜å‚¨å ç”¨:
    å½“å‰: 4GB â†’ ç›®æ ‡: 2GB (50% â†“)
```

---

## 9. å®æ–½è·¯çº¿å›¾

### 9.1 åˆ†é˜¶æ®µå®æ–½è®¡åˆ’

#### Phase 1: æ ¸å¿ƒæ›¿æ¢ (Week 1-2)
```yaml
Week 1:
  - [ ] Whisper Tiny æ¨¡å‹é›†æˆå’Œæµ‹è¯•
  - [ ] FastSpeech2 æ¨¡å‹é›†æˆå’Œæµ‹è¯•
  - [ ] NPUé©±åŠ¨å’Œè¿è¡Œæ—¶é…ç½®
  - [ ] åŸºç¡€æ€§èƒ½åŸºå‡†æµ‹è¯•

Week 2:
  - [ ] æ¨¡å‹é‡åŒ–å’Œä¼˜åŒ– (INT8/FP16)
  - [ ] ROS2èŠ‚ç‚¹é‡æ„å’Œé€‚é…
  - [ ] å†…å­˜ç®¡ç†ä¼˜åŒ–å®ç°
  - [ ] åˆæ­¥é›†æˆæµ‹è¯•
```

#### Phase 2: äº‘è¾¹ååŒ (Week 3)
```yaml
Week 3:
  - [ ] é˜¿é‡Œäº‘APIé›†æˆå’Œé…ç½®
  - [ ] æ™ºèƒ½åˆ‡æ¢ç®—æ³•å®ç°
  - [ ] ç½‘ç»œç›‘æ§å’Œæ•…éšœæ£€æµ‹
  - [ ] æ··åˆæ¶æ„å‹åŠ›æµ‹è¯•
```

#### Phase 3: ç³»ç»Ÿä¼˜åŒ– (Week 4)
```yaml
Week 4:
  - [ ] æ€§èƒ½ç›‘æ§ç³»ç»Ÿé›†æˆ
  - [ ] å®¹é”™æœºåˆ¶éƒ¨ç½²å’Œæµ‹è¯•
  - [ ] é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
  - [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‡†å¤‡
```

### 9.2 å…³é”®é‡Œç¨‹ç¢‘

| é‡Œç¨‹ç¢‘ | æ—¶é—´ | éªŒæ”¶æ ‡å‡† |
|--------|------|----------|
| M1: æ¨¡å‹æ›¿æ¢å®Œæˆ | Week 2 | Whisper+FastSpeech2åœ¨RDK X5ä¸Šç¨³å®šè¿è¡Œ |
| M2: äº‘è¾¹ååŒå®Œæˆ | Week 3 | æ™ºèƒ½åˆ‡æ¢æœºåˆ¶æ­£å¸¸å·¥ä½œ |
| M3: æ€§èƒ½è¾¾æ ‡ | Week 4 | æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸç›®æ ‡ |
| M4: ç”Ÿäº§éƒ¨ç½² | Week 4 | ç³»ç»Ÿç¨³å®šè¿è¡Œï¼Œæ–‡æ¡£å®Œæ•´ |

---

## 10. æ€»ç»“ä¸å»ºè®®

### 10.1 é¡¹ç›®ä»·å€¼
1. **æŠ€æœ¯å‡çº§**: è§£å†³NPUåŠ é€Ÿé—®é¢˜ï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶æ€§èƒ½
2. **æ€§èƒ½æå‡**: ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½60-85%
3. **æˆæœ¬ä¼˜åŒ–**: å‡å°‘èµ„æºå ç”¨ï¼Œæå‡ç³»ç»Ÿæ•ˆç‡
4. **æ¶æ„ç°ä»£åŒ–**: äº‘è¾¹ååŒæ¶æ„ï¼Œæå‡ç³»ç»Ÿå¯é æ€§

### 10.2 å…³é”®æˆåŠŸå› ç´ 
- **æ¨¡å‹é€‰å‹æ­£ç¡®**: Whisperå’ŒFastSpeech2çš„NPUå‹å¥½ç‰¹æ€§
- **é‡åŒ–ç­–ç•¥æœ‰æ•ˆ**: INT8/FP16é‡åŒ–æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨
- **äº‘è¾¹ååŒå®Œå–„**: æ™ºèƒ½åˆ‡æ¢ç¡®ä¿æœåŠ¡è¿ç»­æ€§
- **ç›‘æ§ä½“ç³»å®Œå¤‡**: å®æ—¶æ€§èƒ½ç›‘æ§å’Œæ•…éšœé¢„è­¦

### 10.3 åç»­ä¼˜åŒ–æ–¹å‘
1. **æ¨¡å‹ä¼˜åŒ–**: æ¢ç´¢æ›´è½»é‡çº§çš„æ¨¡å‹æ¶æ„
2. **ç®—æ³•ä¼˜åŒ–**: å®ç°è‡ªé€‚åº”çš„åŠ¨æ€åˆ‡æ¢ç®—æ³•
3. **ç¡¬ä»¶ä¼˜åŒ–**: å……åˆ†åˆ©ç”¨RDK X5çš„ç¡¬ä»¶ç‰¹æ€§
4. **ç”Ÿæ€é›†æˆ**: ä¸æ›´å¤šROS2ç»„ä»¶æ·±åº¦é›†æˆ

### 10.4 å»ºè®®
**ç«‹å³å¼€å§‹å®æ–½** - æŠ€æœ¯æ–¹æ¡ˆæˆç†Ÿï¼Œé£é™©å¯æ§ï¼Œé¢„æœŸæ”¶ç›Šæ˜¾è‘—ã€‚å»ºè®®æŒ‰ç…§ä¸‰é˜¶æ®µè®¡åˆ’æ¨è¿›ï¼Œä¼˜å…ˆå®ç°æ ¸å¿ƒåŠŸèƒ½æ›¿æ¢ï¼Œå†å®Œå–„äº‘è¾¹ååŒæœºåˆ¶ã€‚

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å·²å®Œæˆ
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
**ä¸‹ä¸€æ­¥**: æ‰§è¡Œ product-brief å·¥ä½œæµç¨‹