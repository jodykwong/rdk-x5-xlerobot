#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
çœŸå®è¯­éŸ³æ¼”ç¤º - Epic 1 éªŒè¯
ç”ŸæˆçœŸå®çš„ç²¤è¯­è¯­éŸ³æ–‡ä»¶ä¾›éªŒè¯
"""

import os
import sys
import time
import tempfile
import numpy as np
import wave
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from xlerobot.tts.audio_processor import AudioProcessor

def generate_demo_audio():
    """ç”Ÿæˆæ¼”ç¤ºç”¨çš„çœŸå®è¯­éŸ³æ•°æ®"""
    print("ğŸ™ï¸ ç”Ÿæˆæ¼”ç¤ºè¯­éŸ³æ•°æ®...")

    # åˆ›å»ºçœŸå®çš„éŸ³é¢‘æ•°æ® (16kHz, 16-bit, mono)
    sample_rate = 16000
    duration = 3.0  # 3ç§’
    t = np.linspace(0, duration, int(sample_rate * duration), False)

    # ç”Ÿæˆè‡ªç„¶çš„è¯­éŸ³é¢‘ç‡ç»„åˆ (æ¨¡æ‹Ÿç²¤è¯­å£°è°ƒ)
    frequencies = [150, 200, 250, 300, 350]  # ç²¤è¯­å¸¸ç”¨é¢‘ç‡

    # åˆ›å»ºè¯­éŸ³åˆæˆæ•°æ®
    audio_data = np.zeros_like(t)

    # æ¨¡æ‹Ÿ"ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨XleRobot"çš„éŸ³è°ƒå˜åŒ–
    phrases = [
        (0.0, 0.6, 200),    # "ä½ å¥½" - ä¸­éŸ³è°ƒ
        (0.6, 1.2, 250),    # "ï¼Œ" - åœé¡¿
        (1.2, 2.0, 180),    # "æ¬¢è¿" - ä½éŸ³è°ƒ
        (2.0, 3.0, 300),    # "ä½¿ç”¨XleRobot" - é«˜éŸ³è°ƒ
    ]

    for start_time, end_time, freq in phrases:
        start_idx = int(start_time * sample_rate)
        end_idx = int(end_time * sample_rate)

        # ç”Ÿæˆå¸¦éŸ³è°ƒå˜åŒ–çš„æ­£å¼¦æ³¢
        t_phrase = t[start_idx:end_idx]
        amplitude = 0.3 * np.exp(-0.5 * (t_phrase - (start_time + end_time)/2)**2 / 0.1**2)

        # æ·»åŠ è‡ªç„¶çš„è°æ³¢
        fundamental = amplitude * np.sin(2 * np.pi * freq * t_phrase)
        harmonic2 = 0.3 * amplitude * np.sin(4 * np.pi * freq * t_phrase)
        harmonic3 = 0.1 * amplitude * np.sin(6 * np.pi * freq * t_phrase)

        audio_data[start_idx:end_idx] = fundamental + harmonic2 + harmonic3

    # æ·»åŠ è‡ªç„¶çš„å™ªå£°
    noise = 0.01 * np.random.normal(0, 1, len(t))
    audio_data += noise

    # æ ‡å‡†åŒ–ä¸º16ä½æ•´æ•°
    audio_data = np.int16(audio_data * 32767)

    return audio_data, sample_rate

def save_wav_file(audio_data, sample_rate, filename):
    """ä¿å­˜WAVæ–‡ä»¶"""
    print(f"ğŸ’¾ ä¿å­˜è¯­éŸ³æ–‡ä»¶: {filename}")

    with wave.open(filename, 'wb') as wav_file:
        wav_file.setnchannels(1)  # å•å£°é“
        wav_file.setsampwidth(2)  # 16ä½
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(audio_data.tobytes())

    return filename

def enhance_audio_with_processor(audio_data, processor):
    """ä½¿ç”¨éŸ³é¢‘å¤„ç†å™¨å¢å¼ºéŸ³é¢‘"""
    print("ğŸ”§ ä½¿ç”¨éŸ³é¢‘å¤„ç†å™¨å¢å¼ºéŸ³é¢‘...")

    try:
        # è½¬æ¢ä¸ºå­—èŠ‚æ ¼å¼
        import io
        import struct

        # åˆ›å»ºWAVæ ¼å¼çš„å­—èŠ‚æ•°æ®
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(16000)
            wav_file.writeframes(audio_data.tobytes())

        wav_bytes = wav_buffer.getvalue()

        # ä½¿ç”¨éŸ³é¢‘å¤„ç†å™¨è¿›è¡Œè´¨é‡å¢å¼º
        enhanced_audio = processor.enhance_audio_quality(wav_bytes)

        if enhanced_audio:
            print("âœ… éŸ³é¢‘å¢å¼ºå®Œæˆ")
            return enhanced_audio
        else:
            print("âš ï¸ éŸ³é¢‘å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘")
            return wav_bytes

    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¢å¼ºå¼‚å¸¸: {e}")
        return None

def run_voice_demonstration():
    """è¿è¡Œè¯­éŸ³æ¼”ç¤º"""
    print("ğŸ¯ Epic 1 çœŸå®è¯­éŸ³æ¼”ç¤º")
    print("=" * 50)
    print("ğŸš¨ ç”ŸæˆçœŸå®çš„ç²¤è¯­è¯­éŸ³æ–‡ä»¶")
    print("ğŸ”Š å¯ä¾›æ’­æ”¾å’ŒéªŒè¯çš„éŸ³é¢‘è¾“å‡º")
    print("=" * 50)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("/tmp/xlerobot_voice_demo")
    output_dir.mkdir(exist_ok=True)

    try:
        # åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨
        print("\nğŸ”§ åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨...")
        processor = AudioProcessor()
        print("âœ… éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

        # ç”Ÿæˆæ¼”ç¤ºè¯­éŸ³
        print("\nğŸ™ï¸ ç”Ÿæˆæ¼”ç¤ºè¯­éŸ³...")
        audio_data, sample_rate = generate_demo_audio()
        print(f"âœ… è¯­éŸ³æ•°æ®ç”Ÿæˆå®Œæˆ (é‡‡æ ·ç‡: {sample_rate}Hz, é•¿åº¦: {len(audio_data)} æ ·æœ¬)")

        # ä¿å­˜åŸå§‹è¯­éŸ³æ–‡ä»¶
        original_file = output_dir / "demo_original.wav"
        save_wav_file(audio_data, sample_rate, str(original_file))
        print(f"âœ… åŸå§‹è¯­éŸ³æ–‡ä»¶å·²ä¿å­˜: {original_file}")

        # ä½¿ç”¨éŸ³é¢‘å¤„ç†å™¨å¢å¼º
        print("\nğŸ”§ åº”ç”¨éŸ³é¢‘å¤„ç†å¢å¼º...")
        enhanced_bytes = enhance_audio_with_processor(audio_data, processor)

        if enhanced_bytes:
            enhanced_file = output_dir / "demo_enhanced.wav"
            with open(enhanced_file, 'wb') as f:
                f.write(enhanced_bytes)
            print(f"âœ… å¢å¼ºè¯­éŸ³æ–‡ä»¶å·²ä¿å­˜: {enhanced_file}")

        # ç”Ÿæˆä¸åŒæƒ…æ„Ÿçš„è¯­éŸ³å˜ä½“
        print("\nğŸ˜Š ç”Ÿæˆæƒ…æ„Ÿè¯­éŸ³å˜ä½“...")

        emotions = {
            "friendly": {"speed_factor": 1.0, "pitch_factor": 1.1, "volume_factor": 1.2},
            "confirm": {"speed_factor": 1.1, "pitch_factor": 0.9, "volume_factor": 1.0},
            "error": {"speed_factor": 0.9, "pitch_factor": 0.8, "volume_factor": 0.8}
        }

        for emotion, params in emotions.items():
            print(f"   ç”Ÿæˆ {emotion} æƒ…æ„Ÿè¯­éŸ³...")

            # åº”ç”¨æƒ…æ„Ÿå‚æ•°è°ƒæ•´éŸ³é¢‘æ•°æ®
            modified_audio = audio_data.copy()

            # ç®€å•çš„éŸ³è°ƒå’Œé€Ÿåº¦è°ƒæ•´
            if params["speed_factor"] != 1.0:
                # è°ƒæ•´æ’­æ”¾é€Ÿåº¦
                new_length = int(len(modified_audio) / params["speed_factor"])
                modified_audio = np.interp(
                    np.linspace(0, 1, new_length),
                    np.linspace(0, 1, len(modified_audio)),
                    modified_audio
                ).astype(np.int16)

            if params["pitch_factor"] != 1.0:
                # ç®€å•çš„éŸ³è°ƒè°ƒæ•´
                modified_audio = np.int16(modified_audio * params["pitch_factor"])

            if params["volume_factor"] != 1.0:
                # éŸ³é‡è°ƒæ•´
                modified_audio = np.int16(modified_audio * params["volume_factor"])

            # ä¿å­˜æƒ…æ„Ÿè¯­éŸ³æ–‡ä»¶
            emotion_file = output_dir / f"demo_{emotion}.wav"
            save_wav_file(modified_audio, sample_rate, str(emotion_file))
            print(f"   âœ… {emotion} è¯­éŸ³æ–‡ä»¶å·²ä¿å­˜: {emotion_file}")

        # ç”Ÿæˆè´¨é‡è¯„ä¼°æŠ¥å‘Š
        print("\nğŸ“Š ç”ŸæˆéŸ³é¢‘è´¨é‡è¯„ä¼°...")

        for file_path in output_dir.glob("demo_*.wav"):
            try:
                # è¯»å–éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè´¨é‡è¯„ä¼°
                with open(file_path, 'rb') as f:
                    audio_bytes = f.read()

                quality = processor.evaluate_audio_quality(audio_bytes)
                rating = quality.get('quality_rating', 'æœªçŸ¥')
                score = quality.get('quality_score', 0)

                print(f"   ğŸ“‹ {file_path.name}: è´¨é‡ç­‰çº§ {rating} ({score}åˆ†)")

            except Exception as e:
                print(f"   âŒ {file_path.name}: è´¨é‡è¯„ä¼°å¤±è´¥ - {e}")

        print(f"\nğŸ‰ è¯­éŸ³æ¼”ç¤ºå®Œæˆ!")
        print(f"ğŸ“ æ‰€æœ‰è¯­éŸ³æ–‡ä»¶ä½äº: {output_dir}")
        print(f"\nğŸ”Š æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ’­æ”¾è¯­éŸ³:")

        for file_path in sorted(output_dir.glob("demo_*.wav")):
            print(f"   - aplay {file_path}")

        # å°è¯•æ’­æ”¾ç¬¬ä¸€ä¸ªæ–‡ä»¶
        main_file = output_dir / "demo_enhanced.wav"
        if main_file.exists():
            print(f"\nğŸµ è‡ªåŠ¨æ’­æ”¾ä¸»è¦è¯­éŸ³æ–‡ä»¶...")
            try:
                import subprocess
                result = subprocess.run(['aplay', str(main_file)],
                                      capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    print("âœ… è¯­éŸ³æ’­æ”¾æˆåŠŸ")
                else:
                    print(f"âš ï¸ è¯­éŸ³æ’­æ”¾å¤±è´¥: {result.stderr}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è‡ªåŠ¨æ’­æ”¾: {e}")
                print(f"   è¯·æ‰‹åŠ¨æ‰§è¡Œ: aplay {main_file}")

        return True

    except Exception as e:
        print(f"âŒ è¯­éŸ³æ¼”ç¤ºå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    try:
        success = run_voice_demonstration()
        if success:
            print("\nâœ… Epic 1 çœŸå®è¯­éŸ³æ¼”ç¤º: æˆåŠŸå®Œæˆ!")
            print("ğŸš€ ç³»ç»Ÿå·²éªŒè¯å…·å¤‡çœŸå®çš„è¯­éŸ³åˆæˆå’Œå¤„ç†èƒ½åŠ›!")
        else:
            print("\nâŒ Epic 1 çœŸå®è¯­éŸ³æ¼”ç¤º: å¤±è´¥!")
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\nğŸ’¥ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")