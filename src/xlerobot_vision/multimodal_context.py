#!/usr/bin/env python3.10
"""
å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¤„ç†å™¨ - éŸ³è§†é¢‘ä¸Šä¸‹æ–‡èåˆç®¡ç†
Story 1.6: è§†è§‰ç†è§£é›†æˆå¼€å‘ - Day 12-14

åŠŸèƒ½ç‰¹æ€§:
- å¤šæ¨¡æ€ä¸Šä¸‹æ–‡æ•°æ®ç»“æ„ç®¡ç†
- éŸ³è§†é¢‘è¾“å…¥èåˆç®—æ³•
- å¯¹è¯çŠ¶æ€ç®¡ç†
- ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¿è¯
- ç²¤è¯­å¤šæ¨¡æ€å¯¹è¯ä¼˜åŒ–
- Brownfield Level 4ä¼ä¸šçº§æ ‡å‡†
"""

import time
import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import uuid


@dataclass
class MultimodalInput:
    """å¤šæ¨¡æ€è¾“å…¥æ•°æ®ç»“æ„"""
    input_id: str
    timestamp: float
    input_type: str  # 'text', 'audio', 'image'
    content: Any
    metadata: Dict[str, Any] = field(default_factory=dict)
    session_id: str = ""


@dataclass
class ContextEntry:
    """ä¸Šä¸‹æ–‡æ¡ç›®"""
    entry_id: str
    session_id: str
    inputs: List[MultimodalInput]
    response: Optional[str] = None
    context_type: str = "multimodal"  # 'text_only', 'visual', 'multimodal'
    created_at: float = field(default_factory=time.time)
    relevance_score: float = 1.0
    tags: List[str] = field(default_factory=list)


@dataclass
class SessionContext:
    """ä¼šè¯ä¸Šä¸‹æ–‡"""
    session_id: str
    created_at: float = field(default_factory=time.time)
    last_active: float = field(default_factory=time.time)
    entries: List[ContextEntry] = field(default_factory=list)
    user_profile: Dict[str, Any] = field(default_factory=dict)
    context_state: Dict[str, Any] = field(default_factory=dict)
    total_interactions: int = 0


class CantoneseContextOptimizer:
    """ç²¤è¯­ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨"""

    def __init__(self):
        # ç²¤è¯­å¯¹è¯æ¨¡å¼
        self.conversation_patterns = {
            'greeting': ['ä½ å¥½', 'æ—©æ™¨', 'æ‚¨å¥½', 'Hi', 'Hello'],
            'farewell': ['æ‹œæ‹œ', 'å†è¦‹', 'å†è§', 'Goodbye'],
            'question': ['ä¹œå˜¢', 'ä»€ä¹ˆ', 'é»è§£', 'ä¸ºä»€ä¹ˆ', 'é‚Šå€‹', 'å“ªä¸ª'],
            'visual_query': ['ç‡ä¸‹', 'ç‡ç‡', 'ç‡', 'çœ‹ä¸‹', 'çœ‹çœ‹', 'çœ‹'],
            'gratitude': ['å””è©²', 'å¤šè¬', 'è°¢è°¢', 'Thank you'],
            'acknowledgment': ['å¥½', 'å¾—', 'OK', 'æ˜ç™½', 'çŸ¥é“']
        }

        # ç²¤è¯­è§†è§‰ç›¸å…³è¯æ±‡
        self.visual_terms = {
            'é¢œè‰²': ['ç´…è‰²', 'è—è‰²', 'ç¶ è‰²', 'é»ƒè‰²', 'é»‘è‰²', 'ç™½è‰²'],
            'å½¢çŠ¶': ['åœ“å½¢', 'æ–¹å½¢', 'ä¸‰è§’å½¢', 'é•·æ–¹å½¢'],
            'ä½ç½®': ['ä¸Šé¢', 'ä¸‹é¢', 'å·¦é‚Š', 'å³é‚Š', 'ä¸­é–“', 'æ—é‚Š'],
            'æ•°é‡': ['ä¸€å€‹', 'å…©å€‹', 'ä¸‰å€‹', 'å¥½å¤š', 'å°‘å°‘'],
            'å¤§å°': ['å¤§', 'ç´°', 'ä¸­ç­‰', 'å¥½å¤§', 'å¥½ç´°']
        }

    def analyze_text_intent(self, text: str) -> Dict[str, Any]:
        """åˆ†ææ–‡æœ¬æ„å›¾"""
        text_lower = text.lower()
        intent_analysis = {
            'intent_type': 'general',
            'is_cantonese': False,
            'visual_query': False,
            'confidence': 0.0
        }

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç²¤è¯­è¯æ±‡
        cantonese_detected = False
        for pattern_type, patterns in self.conversation_patterns.items():
            for pattern in patterns:
                if pattern in text_lower:
                    cantonese_detected = True
                    intent_analysis['intent_type'] = pattern_type
                    intent_analysis['confidence'] = 0.8
                    break

        # æ£€æŸ¥è§†è§‰æŸ¥è¯¢
        visual_keywords = ['ç‡', 'çœ‹', 'åœ–', 'åœ–ç‰‡', 'ç›¸', 'ç…§ç‰‡']
        if any(keyword in text_lower for keyword in visual_keywords):
            intent_analysis['visual_query'] = True
            intent_analysis['confidence'] = max(intent_analysis['confidence'], 0.7)

        intent_analysis['is_cantonese'] = cantonese_detected
        return intent_analysis

    def optimize_context_prompt(self, context: List[ContextEntry], current_input: str) -> str:
        """ä¼˜åŒ–ä¸Šä¸‹æ–‡æç¤ºè¯"""
        # åŸºç¡€æç¤ºè¯
        base_prompt = "è«‹æ ¹æ“šä»¥ä¸‹å¤šæ¨¡æ…‹å°è©±ä¸Šä¸‹æ–‡ï¼Œç”¨ç²µèªå›ç­”å•é¡Œï¼š\n\n"

        # æ·»åŠ å†å²ä¸Šä¸‹æ–‡
        if context:
            base_prompt += "å°è©±æ­·å²ï¼š\n"
            for i, entry in enumerate(context[-3:]):  # åªä¿ç•™æœ€è¿‘3æ¡
                if entry.inputs:
                    for input_item in entry.inputs:
                        if input_item.input_type == 'text':
                            base_prompt += f"ç”¨æˆ¶ï¼š{input_item.content}\n"
                    if entry.response:
                        base_prompt += f"åŠ©æ‰‹ï¼š{entry.response}\n"
                base_prompt += "\n"

        # æ·»åŠ å½“å‰é—®é¢˜
        base_prompt += f"ç•¶å‰å•é¡Œï¼š{current_input}\n\n"
        base_prompt += "è«‹åŸºæ–¼ä¸Šä¸‹æ–‡å’Œåœ–åƒä¿¡æ¯ï¼Œç”¨è‡ªç„¶å˜…ç²µèªå›ç­”ã€‚"

        return base_prompt


class ContextFusionEngine:
    """ä¸Šä¸‹æ–‡èåˆå¼•æ“"""

    def __init__(self):
        self.fusion_weights = {
            'text': 0.4,
            'audio': 0.3,
            'image': 0.3
        }
        self.temporal_decay = 0.9  # æ—¶é—´è¡°å‡å› å­

    def calculate_relevance_score(self, entry: ContextEntry, current_time: float) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡æ¡ç›®çš„ç›¸å…³æ€§åˆ†æ•°"""
        # æ—¶é—´è¡°å‡
        time_diff = current_time - entry.created_at
        temporal_score = self.temporal_decay ** (time_diff / 60.0)  # æ¯åˆ†é’Ÿè¡°å‡

        # è¾“å…¥ç±»å‹æƒé‡
        input_weights = 0.0
        for input_item in entry.inputs:
            weight = self.fusion_weights.get(input_item.input_type, 0.1)
            input_weights += weight

        if entry.inputs:
            input_weights /= len(entry.inputs)

        # ç»¼åˆè¯„åˆ†
        relevance_score = temporal_score * input_weights * entry.relevance_score
        return min(max(relevance_score, 0.0), 1.0)

    def fuse_multimodal_inputs(self, inputs: List[MultimodalInput]) -> Dict[str, Any]:
        """èåˆå¤šæ¨¡æ€è¾“å…¥"""
        fusion_result = {
            'fused_text': '',
            'has_visual': False,
            'has_audio': False,
            'dominant_modality': 'text',
            'confidence': 0.0
        }

        if not inputs:
            return fusion_result

        # åˆ†ç±»è¾“å…¥
        text_inputs = [inp for inp in inputs if inp.input_type == 'text']
        audio_inputs = [inp for inp in inputs if inp.input_type == 'audio']
        image_inputs = [inp for inp in inputs if inp.input_type == 'image']

        fusion_result['has_visual'] = len(image_inputs) > 0
        fusion_result['has_audio'] = len(audio_inputs) > 0

        # èåˆæ–‡æœ¬å†…å®¹
        if text_inputs:
            fusion_result['fused_text'] = ' '.join([inp.content for inp in text_inputs])

        # ç¡®å®šä¸»å¯¼æ¨¡æ€
        modality_scores = {
            'text': len(text_inputs) * self.fusion_weights['text'],
            'audio': len(audio_inputs) * self.fusion_weights['audio'],
            'visual': len(image_inputs) * self.fusion_weights['image']
        }

        fusion_result['dominant_modality'] = max(modality_scores, key=modality_scores.get)
        fusion_result['confidence'] = max(modality_scores.values()) / max(len(inputs), 1)

        return fusion_result


class MultimodalContextProcessor:
    """å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¤„ç†å™¨ä¸»ç±»"""

    def __init__(self, max_context_entries: int = 10, session_timeout: int = 1800):
        self.max_context_entries = max_context_entries
        self.session_timeout = session_timeout  # 30åˆ†é’Ÿ
        self.sessions: Dict[str, SessionContext] = {}
        self.fusion_engine = ContextFusionEngine()
        self.cantonese_optimizer = CantoneseContextOptimizer()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_sessions': 0,
            'total_interactions': 0,
            'multimodal_interactions': 0,
            'cantonese_interactions': 0
        }

    def get_or_create_session(self, session_id: str = None) -> SessionContext:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id is None:
            session_id = str(uuid.uuid4())

        if session_id not in self.sessions:
            self.sessions[session_id] = SessionContext(session_id=session_id)
            self.stats['total_sessions'] += 1

        session = self.sessions[session_id]
        session.last_active = time.time()
        return session

    def add_multimodal_input(self, session_id: str, input_type: str, content: Any,
                           metadata: Dict[str, Any] = None) -> str:
        """æ·»åŠ å¤šæ¨¡æ€è¾“å…¥"""
        session = self.get_or_create_session(session_id)

        # åˆ›å»ºè¾“å…¥å¯¹è±¡
        multimodal_input = MultimodalInput(
            input_id=str(uuid.uuid4()),
            timestamp=time.time(),
            input_type=input_type,
            content=content,
            metadata=metadata or {},
            session_id=session_id
        )

        # åˆ›å»ºæ–°çš„ä¸Šä¸‹æ–‡æ¡ç›®
        context_entry = ContextEntry(
            entry_id=str(uuid.uuid4()),
            session_id=session_id,
            inputs=[multimodal_input]
        )

        # ç¡®å®šä¸Šä¸‹æ–‡ç±»å‹
        if input_type == 'image' or any(inp.input_type == 'image' for inp in session.entries[-3:]):
            context_entry.context_type = 'visual'
        elif input_type == 'audio':
            context_entry.context_type = 'multimodal'
        else:
            context_entry.context_type = 'text_only'

        # æ·»åŠ åˆ°ä¼šè¯
        session.entries.append(context_entry)
        session.total_interactions += 1
        self.stats['total_interactions'] += 1

        # æ›´æ–°ç»Ÿè®¡
        if context_entry.context_type in ['visual', 'multimodal']:
            self.stats['multimodal_interactions'] += 1

        # æ¸…ç†æ—§ä¸Šä¸‹æ–‡
        self._cleanup_old_entries(session)

        return context_entry.entry_id

    def process_current_context(self, session_id: str, current_input: str,
                              images: List[str] = None) -> Dict[str, Any]:
        """å¤„ç†å½“å‰ä¸Šä¸‹æ–‡"""
        session = self.get_or_create_session(session_id)

        # åˆ†æå½“å‰è¾“å…¥æ„å›¾
        intent_analysis = self.cantonese_optimizer.analyze_text_intent(current_input)

        # è·å–ç›¸å…³ä¸Šä¸‹æ–‡
        current_time = time.time()
        relevant_context = self._get_relevant_context(session, current_time)

        # èåˆå¤šæ¨¡æ€è¾“å…¥
        fusion_result = self.fusion_engine.fuse_multimodal_inputs(
            [inp for entry in relevant_context for inp in entry.inputs] +
            ([MultimodalInput("", current_time, 'text', current_input)] if current_input else [])
        )

        # ä¼˜åŒ–æç¤ºè¯
        if intent_analysis['is_cantonese']:
            self.stats['cantonese_interactions'] += 1
            optimized_prompt = self.cantonese_optimizer.optimize_context_prompt(
                relevant_context, current_input)
        else:
            optimized_prompt = current_input

        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = {
            'session_id': session_id,
            'current_input': current_input,
            'images': images or [],
            'relevant_context': relevant_context,
            'fusion_result': fusion_result,
            'intent_analysis': intent_analysis,
            'optimized_prompt': optimized_prompt,
            'context_confidence': self._calculate_context_confidence(relevant_context, fusion_result),
            'suggested_max_tokens': self._suggest_max_tokens(intent_analysis, fusion_result)
        }

        return context_info

    def store_response(self, session_id: str, entry_id: str, response: str):
        """å­˜å‚¨å“åº”"""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            for entry in session.entries:
                if entry.entry_id == entry_id:
                    entry.response = response
                    break

    def _get_relevant_context(self, session: SessionContext, current_time: float) -> List[ContextEntry]:
        """è·å–ç›¸å…³ä¸Šä¸‹æ–‡"""
        # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶æ’åº
        scored_entries = []
        for entry in session.entries:
            relevance_score = self.fusion_engine.calculate_relevance_score(entry, current_time)
            if relevance_score > 0.1:  # è¿‡æ»¤ä½ç›¸å…³æ€§æ¡ç›®
                scored_entries.append((entry, relevance_score))

        # æŒ‰ç›¸å…³æ€§æ’åºï¼Œå–å‰Næ¡
        scored_entries.sort(key=lambda x: x[1], reverse=True)
        return [entry for entry, _ in scored_entries[:self.max_context_entries]]

    def _calculate_context_confidence(self, context: List[ContextEntry],
                                   fusion_result: Dict[str, Any]) -> float:
        """è®¡ç®—ä¸Šä¸‹æ–‡ç½®ä¿¡åº¦"""
        if not context:
            return 0.0

        # åŸºäºä¸Šä¸‹æ–‡æ¡ç›®æ•°é‡å’Œèåˆç»“æœè®¡ç®—ç½®ä¿¡åº¦
        context_score = min(len(context) / 5.0, 1.0) * 0.6  # ä¸Šä¸‹æ–‡ä¸°å¯Œåº¦
        fusion_score = fusion_result.get('confidence', 0.0) * 0.4  # èåˆç½®ä¿¡åº¦

        return context_score + fusion_score

    def _suggest_max_tokens(self, intent_analysis: Dict[str, Any],
                          fusion_result: Dict[str, Any]) -> int:
        """å»ºè®®æœ€å¤§tokenæ•°"""
        base_tokens = 200

        # æ ¹æ®æ„å›¾ç±»å‹è°ƒæ•´
        if intent_analysis['visual_query']:
            base_tokens += 100  # è§†è§‰æŸ¥è¯¢éœ€è¦æ›´å¤štoken

        # æ ¹æ®æ¨¡æ€å¤æ‚åº¦è°ƒæ•´
        if fusion_result['has_visual']:
            base_tokens += 150  # æœ‰å›¾åƒæ—¶å¢åŠ 

        if fusion_result['dominant_modality'] == 'multimodal':
            base_tokens += 100  # å¤šæ¨¡æ€æ—¶å¢åŠ 

        return min(base_tokens, 800)  # æœ€å¤§ä¸è¶…è¿‡800

    def _cleanup_old_entries(self, session: SessionContext):
        """æ¸…ç†æ—§ä¸Šä¸‹æ–‡æ¡ç›®"""
        current_time = time.time()
        cutoff_time = current_time - self.session_timeout

        # ç§»é™¤è¶…æ—¶çš„æ¡ç›®
        session.entries = [
            entry for entry in session.entries
            if entry.created_at > cutoff_time
        ]

        # å¦‚æœä»ç„¶å¤ªå¤šï¼Œä¿ç•™æœ€è¿‘çš„
        if len(session.entries) > self.max_context_entries:
            session.entries = session.entries[-self.max_context_entries:]

    def get_session_summary(self, session_id: str) -> Dict[str, Any]:
        """è·å–ä¼šè¯æ‘˜è¦"""
        if session_id not in self.sessions:
            return {'error': 'Session not found'}

        session = self.sessions[session_id]
        return {
            'session_id': session_id,
            'created_at': session.created_at,
            'last_active': session.last_active,
            'total_interactions': session.total_interactions,
            'context_entries': len(session.entries),
            'session_duration': time.time() - session.created_at,
            'multimodal_ratio': (
                len([e for e in session.entries if e.context_type in ['visual', 'multimodal']]) /
                max(len(session.entries), 1)
            )
        }

    def get_processor_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        active_sessions = len([
            s for s in self.sessions.values()
            if time.time() - s.last_active < self.session_timeout
        ])

        return {
            **self.stats,
            'active_sessions': active_sessions,
            'total_sessions_created': len(self.sessions),
            'average_session_length': (
                sum(s.total_interactions for s in self.sessions.values()) /
                max(len(self.sessions), 1)
            ),
            'multimodal_interaction_ratio': (
                self.stats['multimodal_interactions'] /
                max(self.stats['total_interactions'], 1)
            ),
            'cantonese_interaction_ratio': (
                self.stats['cantonese_interactions'] /
                max(self.stats['total_interactions'], 1)
            )
        }


def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ§  å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¤„ç†å™¨æµ‹è¯•")
    print("=" * 50)

    try:
        # åˆ›å»ºå¤„ç†å™¨
        processor = MultimodalContextProcessor()
        print("âœ… å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

        # åˆ›å»ºæµ‹è¯•ä¼šè¯
        session_id = "test_session_001"
        print(f"ğŸ†” åˆ›å»ºä¼šè¯: {session_id}")

        # æ·»åŠ æ–‡æœ¬è¾“å…¥
        entry_id_1 = processor.add_multimodal_input(
            session_id, 'text', 'ä½ å¥½ï¼Œæˆ‘æƒ³å•é—œæ–¼å‘¢å¼µåœ–å˜…å•é¡Œ')
        print("âœ… æ·»åŠ æ–‡æœ¬è¾“å…¥")

        # æ·»åŠ å›¾åƒè¾“å…¥ï¼ˆæ¨¡æ‹Ÿï¼‰
        entry_id_2 = processor.add_multimodal_input(
            session_id, 'image', '/path/to/test_image.jpg',
            {'format': 'jpeg', 'size': '640x480'})
        print("âœ… æ·»åŠ å›¾åƒè¾“å…¥")

        # å¤„ç†å½“å‰ä¸Šä¸‹æ–‡
        context_info = processor.process_current_context(
            session_id, 'å‘¢å¼µåœ–ç•«ç·Šä¹œï¼Ÿ', ['/path/to/test_image.jpg'])

        print(f"ğŸ“Š ä¸Šä¸‹æ–‡ç½®ä¿¡åº¦: {context_info['context_confidence']:.2f}")
        print(f"ğŸ¯ æ„å›¾ç±»å‹: {context_info['intent_analysis']['intent_type']}")
        print(f"ğŸ—£ï¸ ç²¤è¯­æ£€æµ‹: {context_info['intent_analysis']['is_cantonese']}")
        print(f"ğŸ‘€ è§†è§‰æŸ¥è¯¢: {context_info['intent_analysis']['visual_query']}")
        print(f"ğŸ“ å»ºè®®tokenæ•°: {context_info['suggested_max_tokens']}")

        # å­˜å‚¨å“åº”
        processor.store_response(session_id, entry_id_2, "å‘¢å¼µåœ–é¡¯ç¤ºä¸€å€‹ç´…è‰²åœ“å½¢")
        print("âœ… å­˜å‚¨å“åº”")

        # è·å–ä¼šè¯æ‘˜è¦
        summary = processor.get_session_summary(session_id)
        print(f"ğŸ“‹ ä¼šè¯äº¤äº’æ¬¡æ•°: {summary['total_interactions']}")
        print(f"ğŸ“Š å¤šæ¨¡æ€æ¯”ä¾‹: {summary['multimodal_ratio']:.2%}")

        # è·å–å¤„ç†å™¨ç»Ÿè®¡
        stats = processor.get_processor_stats()
        print(f"ğŸ“ˆ æ€»äº¤äº’æ¬¡æ•°: {stats['total_interactions']}")
        print(f"ğŸŒ å¤šæ¨¡æ€äº¤äº’æ¯”ä¾‹: {stats['multimodal_interaction_ratio']:.2%}")
        print(f"ğŸ—£ï¸ ç²¤è¯­äº¤äº’æ¯”ä¾‹: {stats['cantonese_interaction_ratio']:.2%}")

        print("\nâœ… å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¤„ç†å™¨æµ‹è¯•å®Œæˆ")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()