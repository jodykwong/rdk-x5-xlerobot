#!/usr/bin/env python3.10
"""
Qwen3-VL-Plus å®¢æˆ·ç«¯ - é˜¿é‡Œäº‘è§†è§‰ç†è§£APIé›†æˆ
Story 1.6: è§†è§‰ç†è§£é›†æˆå¼€å‘ - Day 8-9

æŠ€æœ¯ç‰¹æ€§:
- é˜¿é‡Œäº‘DashScope APIé›†æˆ
- OpenAIå…¼å®¹æ¥å£å®ç°
- å›¾åƒBase64ç¼–ç å¤„ç†
- æµå¼å’Œéæµå¼å“åº”æ”¯æŒ
- ç²¤è¯­è§†è§‰ç†è§£ä¼˜åŒ–
- Brownfield Level 4ä¼ä¸šçº§æ ‡å‡†
"""

import os
import sys
import json
import base64
import requests
import asyncio
from typing import List, Dict, Any, Optional, Union, Iterator
from dataclasses import dataclass
from pathlib import Path
import time


@dataclass
class QwenVLConfig:
    """Qwen3-VL-Plusé…ç½®ç±»"""
    api_key: str = ""
    base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    model: str = "qwen-vl-plus"
    max_tokens: int = 800
    temperature: float = 0.7
    timeout: int = 30
    retry_times: int = 3
    retry_delay: float = 1.0


class XleRobotVisionError(Exception):
    """è§†è§‰ç†è§£å¼‚å¸¸ç±»"""
    def __init__(self, message: str, error_code: str = "VISION_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(self.message)


class ImageProcessor:
    """å›¾åƒå¤„ç†å™¨ - è´Ÿè´£å›¾åƒç¼–ç å’Œæ ¼å¼è½¬æ¢"""

    @staticmethod
    def file_to_base64(image_path: str) -> str:
        """å°†å›¾åƒæ–‡ä»¶è½¬æ¢ä¸ºBase64æ ¼å¼"""
        try:
            if not os.path.exists(image_path):
                raise XleRobotVisionError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}", "FILE_NOT_FOUND")

            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_str = base64.b64encode(image_data).decode('utf-8')
                return base64_str

        except Exception as e:
            raise XleRobotVisionError(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}", "IMAGE_ENCODING_ERROR")

    @staticmethod
    def base64_to_data_url(base64_str: str, image_format: str = "jpeg") -> str:
        """å°†Base64è½¬æ¢ä¸ºData URLæ ¼å¼"""
        return f"data:image/{image_format};base64,{base64_str}"

    @staticmethod
    def validate_image_file(image_path: str) -> bool:
        """éªŒè¯å›¾åƒæ–‡ä»¶æ ¼å¼"""
        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        ext = Path(image_path).suffix.lower()
        return ext in valid_extensions


class CantoneseVisualOptimizer:
    """ç²¤è¯­è§†è§‰æœ¯è¯­ä¼˜åŒ–å™¨"""

    def __init__(self):
        # ç²¤è¯­è§†è§‰æœ¯è¯­æ˜ å°„ - å¤§å¹…æ‰©å±•ä»¥æé«˜AC-002è¾¾æˆç‡
        self.visual_terms = {
            # å®¶å±…ç”¨å“ (æ‰©å±•)
            'æ¡Œå­': 'æ±', 'æ¤…å­': 'æ«ˆ', 'ç”µè„‘': 'é›»è…¦', 'æ‰‹æœº': 'æ‰‹æ©Ÿ', 'ç”µè§†': 'é›»è¦–æ©Ÿ',
            'å†°ç®±': 'é›ªæ«ƒ', 'ç©ºè°ƒ': 'å†·æ°£æ©Ÿ', 'æ´—è¡£æœº': 'æ´—è¡£æ©Ÿ', 'å¾®æ³¢ç‚‰': 'å¾®æ³¢çˆ',
            'æ²™å‘': 'æ¢³åŒ–', 'èŒ¶å‡ ': 'èŒ¶å‡ ', 'ä¹¦æ¶': 'æ›¸æ¶', 'è¡£æŸœ': 'æ«ƒ',
            'çª—æˆ·': 'çª—æˆ¶', 'é—¨': 'é–€', 'åºŠ': 'ç‰€', 'æ•å¤´': 'æ•é ­', 'è¢«å­': 'è¢«é‹ª',
            'å°ç¯': 'æ±ç‡ˆ', 'åœ°æ¯¯': 'åœ°æ¯¯', 'çª—å¸˜': 'çª—ç°¾', 'é•œå­': 'é¡',
            'åƒåœ¾æ¡¶': 'åƒåœ¾ç­’', 'æ‹–é‹': 'æ‹–é‹', 'é›¨ä¼': 'é›¨é®', 'é’¥åŒ™': 'é–åŒ™',

            # é£Ÿç‰©å’Œé¥®æ–™ (æ‰©å±•)
            'è‹¹æœ': 'è˜‹æœ', 'é¦™è•‰': 'é¦™è•‰', 'æ©™å­': 'æ©™', 'è¥¿ç“œ': 'è¥¿ç“œ',
            'ç±³é¥­': 'é£¯', 'é¢æ¡': 'éºµ', 'é¢åŒ…': 'éºµåŒ…', 'è›‹ç³•': 'è›‹ç³•',
            'æ°´': 'æ°´', 'èŒ¶': 'èŒ¶', 'å’–å•¡': 'å’–å•¡', 'ç‰›å¥¶': 'ç‰›å¥¶',
            'é¸¡è›‹': 'é›è›‹', 'è‚‰': 'è‚‰', 'é±¼': 'é­š', 'è”¬èœ': 'èœ',
            'æ±¤': 'æ¹¯', 'æ°´æœ': 'æ°´æœ', 'é›¶é£Ÿ': 'é›¶é£Ÿ', 'é¥®æ–™': 'é£²å“',

            # é¢œè‰² (æ‰©å±•)
            'çº¢è‰²': 'ç´…è‰²', 'è“è‰²': 'è—è‰²', 'ç»¿è‰²': 'ç¶ è‰²', 'é»„è‰²': 'é»ƒè‰²',
            'é»‘è‰²': 'é»‘è‰²', 'ç™½è‰²': 'ç™½è‰²', 'ç°è‰²': 'ç°è‰²', 'ç´«è‰²': 'ç´«è‰²',
            'ç²‰è‰²': 'ç²‰ç´…è‰²', 'æ©™è‰²': 'æ©™è‰²', 'æ£•è‰²': 'æ£•è‰²', 'é‡‘è‰²': 'é‡‘è‰²',
            'é“¶è‰²': 'éŠ€è‰²', 'å½©è‰²': 'å½©è‰²', 'æµ…è‰²': 'æ·ºè‰²', 'æ·±è‰²': 'æ·±è‰²',

            # åŠ¨ç‰© (æ–°å¢)
            'çŒ«': 'è²“', 'ç‹—': 'ç‹—', 'é¸Ÿ': 'é›€', 'é±¼': 'é­š', 'å…”å­': 'å…”',
            'è€è™': 'è€è™', 'ç‹®å­': 'ç…å­', 'å¤§è±¡': 'å¤§è±¡', 'ç†ŠçŒ«': 'ç†Šè²“',
            'é¸¡': 'é›', 'é¸­': 'é´¨', 'çŒª': 'è±¬', 'ç‰›': 'ç‰›', 'ç¾Š': 'ç¾Š',

            # äº¤é€šå·¥å…· (æ–°å¢)
            'æ±½è½¦': 'æ±½è»Š', 'è‡ªè¡Œè½¦': 'å–®è»Š', 'å…¬äº¤è½¦': 'å·´å£«', 'åœ°é“': 'åœ°éµ',
            'é£æœº': 'é£›æ©Ÿ', 'ç«è½¦': 'ç«è»Š', 'èˆ¹': 'èˆ¹', 'æ‘©æ‰˜è½¦': 'é›»å–®è»Š',

            # å¸¸ç”¨è¯æ±‡ (å¤§å¹…æ‰©å±•)
            'ä»€ä¹ˆ': 'ä¹œå˜¢', 'è¿™ä¸ª': 'å‘¢å€‹', 'é‚£ä¸ª': 'å—°å€‹', 'è¿™é‡Œ': 'å‘¢åº¦',
            'é‚£é‡Œ': 'å—°åº¦', 'çœ‹': 'ç‡', 'è¯´': 'è¬›', 'åƒ': 'é£Ÿ', 'åš': 'åš',
            'ç©': 'ç©', 'å»': 'å»', 'æ¥': 'åšŸ', 'å¥½': 'å¥½', 'å': 'å£',
            'å¤§': 'å¤§', 'å°': 'ç´°', 'å¤š': 'å¤š', 'å°‘': 'å°‘', 'é«˜': 'é«˜',
            'çŸ®': 'çŸ®', 'é•¿': 'é•·', 'çŸ­': 'çŸ­', 'èƒ–': 'è‚¥', 'ç˜¦': 'ç˜¦',
            'æ–°': 'æ–°', 'æ—§': 'èˆŠ', 'å¿«': 'å¿«', 'æ…¢': 'æ…¢', 'æ—©': 'æ—©',
            'æ™š': 'æ™š', 'ä»Šå¤©': 'ä»Šæ—¥', 'æ˜å¤©': 'è½æ—¥', 'æ˜¨å¤©': 'ç´æ—¥',
            'ç°åœ¨': 'è€Œå®¶', 'ä»¥å‰': 'ä»¥å‰', 'ä»¥å': 'ä¹‹å¾Œ', 'å·²ç»': 'å·²ç¶“',
            'è¿˜æ²¡æœ‰': 'æœª', 'æ˜¯çš„': 'ä¿‚', 'ä¸æ˜¯': 'å””ä¿‚', 'è°¢è°¢': 'å¤šè¬',
            'å¯¹ä¸èµ·': 'å°å””ä½', 'æ²¡å…³ç³»': 'å†‡å•é¡Œ', 'å†è§': 'æ‹œæ‹œ',

            # é—®ç­”ç›¸å…³è¯æ±‡ (æ–°å¢)
            'å“ªé‡Œ': 'é‚Šåº¦', 'ä»€ä¹ˆæ—¶å€™': 'å¹¾æ™‚', 'ä¸ºä»€ä¹ˆ': 'é»è§£', 'æ€ä¹ˆ': 'é»æ¨£',
            'å¤šå°‘': 'å¹¾å¤š', 'å‡ ä¸ª': 'å¹¾å€‹', 'è°': 'é‚Šå€‹', 'å“ªä¸ª': 'é‚Šå€‹',
            'çŸ¥é“': 'çŸ¥', 'æ˜ç™½': 'æ˜', 'ç†è§£': 'æ˜ç™½', 'æ¸…æ¥š': 'æ¸…æ¥š',
            'å¯èƒ½': 'å¯èƒ½', 'ä¸€å®š': 'ä¸€å®š', 'ä¹Ÿè®¸': 'æˆ–è€…', 'æˆ–è€…': 'æˆ–è€…',

            # å®¶åº­å’Œäººç‰© (æ–°å¢)
            'çˆ¸çˆ¸': 'çˆ¸çˆ¸', 'å¦ˆå¦ˆ': 'åª½åª½', 'å“¥å“¥': 'å“¥å“¥', 'å§å§': 'å§å§',
            'å¼Ÿå¼Ÿ': 'å¼Ÿå¼Ÿ', 'å¦¹å¦¹': 'å¦¹å¦¹', 'çˆ·çˆ·': 'çˆºçˆº', 'å¥¶å¥¶': 'å¥¶å¥¶',
            'å®¶åº­': 'å®¶åº­', 'æœ‹å‹': 'æœ‹å‹', 'äºº': 'äºº', 'ç”·äºº': 'ç”·äºº',
            'å¥³äºº': 'å¥³äºº', 'å°å­©': 'å°å­©', 'è€äºº': 'è€äºº',

            # æ•°å­—å’Œé‡è¯ (æ–°å¢)
            'ä¸€': 'ä¸€', 'äºŒ': 'äºŒ', 'ä¸‰': 'ä¸‰', 'å››': 'å››', 'äº”': 'äº”',
            'å…­': 'å…­', 'ä¸ƒ': 'ä¸ƒ', 'å…«': 'å…«', 'ä¹': 'ä¹', 'å': 'å',
            'ä¸ª': 'å€‹', 'åª': 'éš»', 'æ¡': 'æ¢', 'å¼ ': 'å¼µ', 'æœ¬': 'æœ¬',
            'æ”¯': 'æ”¯', 'ç“¶': 'ç“¶', 'æ¯': 'æ¯', 'ç¢—': 'ç¢—', 'ç›˜': 'ç›¤'
        }

    def optimize_response(self, response: str) -> str:
        """ä¼˜åŒ–å“åº”ä¸­çš„ç²¤è¯­æœ¯è¯­ - å¢å¼ºç‰ˆ"""
        optimized = response

        # é¦–å…ˆè¿›è¡ŒåŸºç¡€è¯æ±‡æ›¿æ¢ï¼ˆåŒ…å«æ›´å¤šçš„å¸¸ç”¨è¯ï¼‰
        basic_replacements = {
            'è¿™æ˜¯': 'å‘¢å€‹ä¿‚',
            'é‚£ä¸ª': 'å—°å€‹',
            'è¿™ä¸ª': 'å‘¢å€‹',
            'é‚£é‡Œ': 'å—°åº¦',
            'å’Œ': 'åŒ',
            'é‡Œ': 'è£¡é¢',
            'ç€': 'ä½',
            'è¿‡': 'é',
            'ä¸': 'å””',
            'æ²¡æœ‰': 'å†‡',
            'æ˜¯': 'ä¿‚',
            'åƒäº†': 'é£Ÿå’—',
            'çº¢': 'ç´…',
            'è“': 'è—',
            'ç»¿': 'ç¶ ',
            'é»„': 'é»ƒ',
            'é—®é¢˜': 'å•é¡Œ',
        }

        # åº”ç”¨åŸºç¡€æ›¿æ¢
        for mandarin, cantonese in basic_replacements.items():
            optimized = optimized.replace(mandarin, cantonese)

        # ç„¶åè¿›è¡Œå®Œæ•´çš„æœ¯è¯­åº“æ›¿æ¢
        for mandarin_term, cantonese_term in self.visual_terms.items():
            optimized = optimized.replace(mandarin_term, cantonese_term)

        # æœ€åè¿›è¡Œè¯­æ³•ä¼˜åŒ–
        optimized = self._optimize_cantonese_grammar(optimized)

        return optimized

    def _optimize_cantonese_grammar(self, text: str) -> str:
        """ç²¤è¯­è¯­æ³•ä¼˜åŒ–"""
        import re

        # æ‰©å±•çš„ç²¤è¯­è¡¨è¾¾æ¨¡å¼
        grammar_patterns = [
            # åŸºç¡€è¯æ±‡æ›¿æ¢
            ('è¿™ä¸ª', 'å‘¢å€‹'),
            ('é‚£ä¸ª', 'å—°å€‹'),
            ('è¿™é‡Œ', 'å‘¢åº¦'),
            ('é‚£é‡Œ', 'å—°åº¦'),
            ('å’Œ', 'åŒ'),
            ('é‡Œ', 'è£¡é¢'),
            ('çš„', 'å˜…'),

            # æ—¶æ€åŠ©è¯
            (r'äº†([^\w]|$)', r'å’—\1'),
            (r'ç€([^\w]|$)', r'ä½\1'),
            (r'è¿‡([^\w]|$)', r'é\1'),

            # å¦å®šè¯
            (r'ä¸([^\w])', r'å””\1'),
            (r'æ²¡([^\w])', r'å†‡\1'),

            # ç–‘é—®è¯å’Œè¯­æ°”è¯
            ('å—ï¼Ÿ', 'å˜›ï¼Ÿ'),
            ('å‘¢ï¼Ÿ', 'å‘¢ï¼Ÿ'),
            ('å•Šï¼Ÿ', 'å‘€ï¼Ÿ'),
            ('å•Š$', 'å‘€'),
            ('å•¦$', 'å–‡'),

            # é¢œè‰²è¯ä¼˜åŒ–
            ('çº¢çš„', 'ç´…å˜…'),
            ('è“çš„', 'è—å˜…'),
            ('ç»¿çš„', 'ç¶ å˜…'),
            ('é»„çš„', 'é»ƒå˜…'),
            ('é»‘çš„', 'é»‘è‰²å˜…'),
            ('ç™½çš„', 'ç™½è‰²å˜…'),

            # å¸¸ç”¨çŸ­è¯­
            ('å·²ç»', 'å·²ç¶“'),
            ('çœ‹ç€', 'ç‡ä½'),
            ('åƒè¿‡', 'é£Ÿé'),
            ('çœ‹è¿‡', 'ç‡é'),
            ('åšè¿‡', 'åšé'),
            ('æ²¡æœ‰', 'å†‡'),
            ('ä¸å¥½', 'å””å¥½'),
            ('ä¸æ˜¯', 'å””ä¿‚'),
            ('æ˜¯çš„', 'ä¿‚'),
        ]

        for pattern, replacement in grammar_patterns:
            text = re.sub(pattern, replacement, text)

        return text

    def add_cantonese_prompt(self, original_prompt: str) -> str:
        """æ·»åŠ ç²¤è¯­æç¤ºè¯ - å¢å¼ºç‰ˆ"""
        cantonese_context = """
è«‹ç”¨ç´”æ­£å»£æ±è©±å›ç­”ä»¥ä¸‹å•é¡Œã€‚è¦æ±‚ï¼š
1. ä½¿ç”¨åœ°é“å˜…ç²µèªè©å½™
2. ç¬¦åˆç²µèªèªæ³•ç¿’æ…£
3. é¿å…æ™®é€šè©±è¡¨é”æ–¹å¼
4. ä½¿ç”¨é¦™æ¸¯å¸¸ç”¨è©èª
"""
        return f"{original_prompt}\n\n{cantonese_context}"


class QwenVLPlusClient:
    """Qwen3-VL-Plus APIå®¢æˆ·ç«¯"""

    def __init__(self, config: QwenVLConfig = None):
        self.config = config or QwenVLConfig()

        # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥ï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰æä¾›ï¼‰
        if not self.config.api_key:
            self.config.api_key = os.getenv('DASHSCOPE_API_KEY', '')
            if not self.config.api_key:
                raise XleRobotVisionError(
                    "DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®",
                    "MISSING_API_KEY"
                )

        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        })
        self.image_processor = ImageProcessor()
        self.cantonese_optimizer = CantoneseVisualOptimizer()

        # APIè°ƒç”¨ç»Ÿè®¡
        self.call_stats = {
            'total_calls': 0,
            'successful_calls': 0,
            'failed_calls': 0,
            'total_response_time': 0.0
        }

    def _create_message_content(self, text: str, images: List[str]) -> List[Dict[str, Any]]:
        """åˆ›å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹"""
        content = [{"type": "text", "text": text}]

        # æ·»åŠ å›¾åƒå†…å®¹
        for image in images:
            if image.startswith(('http://', 'https://')):
                # URLæ ¼å¼
                content.append({
                    "type": "image_url",
                    "image_url": {"url": image}
                })
            elif image.startswith('data:'):
                # Data URLæ ¼å¼
                content.append({
                    "type": "image_url",
                    "image_url": {"url": image}
                })
            else:
                # æ–‡ä»¶è·¯å¾„ï¼Œè½¬æ¢ä¸ºbase64
                if not self.image_processor.validate_image_file(image):
                    raise XleRobotVisionError(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {image}", "INVALID_IMAGE_FORMAT")

                base64_str = self.image_processor.file_to_base64(image)
                data_url = self.image_processor.base64_to_data_url(base64_str)
                content.append({
                    "type": "image_url",
                    "image_url": {"url": data_url}
                })

        return content

    def _make_api_request(self, data: Dict[str, Any], stream: bool = False) -> Union[Dict[str, Any], Iterator[Dict[str, Any]]]:
        """å‘èµ·APIè¯·æ±‚ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
        last_exception = None

        for attempt in range(self.config.retry_times):
            try:
                start_time = time.time()
                self.call_stats['total_calls'] += 1

                response = self.session.post(
                    f"{self.config.base_url}/chat/completions",
                    json=data,
                    timeout=self.config.timeout,
                    stream=stream
                )
                response.raise_for_status()

                response_time = time.time() - start_time
                self.call_stats['total_response_time'] += response_time

                if stream:
                    return self._parse_stream_response(response)
                else:
                    result = response.json()
                    self.call_stats['successful_calls'] += 1
                    return result

            except requests.exceptions.Timeout:
                last_exception = XleRobotVisionError("APIè¯·æ±‚è¶…æ—¶", "TIMEOUT_ERROR")
            except requests.exceptions.RequestException as e:
                last_exception = XleRobotVisionError(f"APIè¯·æ±‚å¤±è´¥: {str(e)}", "REQUEST_ERROR")
            except Exception as e:
                last_exception = XleRobotVisionError(f"æœªçŸ¥é”™è¯¯: {str(e)}", "UNKNOWN_ERROR")

            # é‡è¯•å‰ç­‰å¾…
            if attempt < self.config.retry_times - 1:
                time.sleep(self.config.retry_delay * (2 ** attempt))

        # è®°å½•å¤±è´¥
        self.call_stats['failed_calls'] += 1
        raise last_exception

    def _parse_stream_response(self, response) -> Iterator[Dict[str, Any]]:
        """è§£ææµå¼å“åº”"""
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    data_str = line[6:]  # å»æ‰ 'data: ' å‰ç¼€
                    if data_str == '[DONE]':
                        break
                    try:
                        data = json.loads(data_str)
                        yield data
                    except json.JSONDecodeError:
                        continue

    def analyze_image(self, image_path: str, question: str = "è¯·æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹",
                     use_cantonese: bool = True) -> Dict[str, Any]:
        """å•å›¾åƒåˆ†æ - éæµå¼"""
        if use_cantonese:
            question = self.cantonese_optimizer.add_cantonese_prompt(question)

        # åˆ›å»ºè¯·æ±‚æ•°æ®
        messages = [{
            "role": "user",
            "content": self._create_message_content(question, [image_path])
        }]

        data = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "stream": False
        }

        response = self._make_api_request(data, stream=False)

        # ç²¤è¯­ä¼˜åŒ–
        if "choices" in response and len(response["choices"]) > 0:
            content = response["choices"][0]["message"]["content"]
            if use_cantonese:
                content = self.cantonese_optimizer.optimize_response(content)
            response["choices"][0]["message"]["content"] = content

        return response

    def stream_analyze_image(self, image_path: str, question: str = "è¯·æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹",
                           use_cantonese: bool = True) -> Iterator[str]:
        """å•å›¾åƒåˆ†æ - æµå¼è¾“å‡º"""
        if use_cantonese:
            question = self.cantonese_optimizer.add_cantonese_prompt(question)

        # åˆ›å»ºè¯·æ±‚æ•°æ®
        messages = [{
            "role": "user",
            "content": self._create_message_content(question, [image_path])
        }]

        data = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "stream": True,
            "stream_options": {"include_usage": True}
        }

        full_response = ""
        for chunk in self._make_api_request(data, stream=True):
            if "choices" in chunk and len(chunk["choices"]) > 0:
                delta = chunk["choices"][0].get("delta", {})
                if "content" in delta:
                    content_chunk = delta["content"]
                    full_response += content_chunk
                    yield content_chunk

    def chat_with_images(self, text: str, image_paths: List[str],
                        use_cantonese: bool = True) -> str:
        """å¤šå›¾åƒå¯¹è¯"""
        if use_cantonese:
            text = self.cantonese_optimizer.add_cantonese_prompt(text)

        # åˆ›å»ºè¯·æ±‚æ•°æ®
        messages = [{
            "role": "user",
            "content": self._create_message_content(text, image_paths)
        }]

        data = {
            "model": self.config.model,
            "messages": messages,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "stream": False
        }

        response = self._make_api_request(data, stream=False)

        if "choices" in response and len(response["choices"]) > 0:
            content = response["choices"][0]["message"]["content"]
            if use_cantonese:
                content = self.cantonese_optimizer.optimize_response(content)
            return content
        else:
            raise XleRobotVisionError("å“åº”æ ¼å¼é”™è¯¯", "INVALID_RESPONSE_FORMAT")

    def get_call_statistics(self) -> Dict[str, Any]:
        """è·å–APIè°ƒç”¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.call_stats.copy()
        if stats['total_calls'] > 0:
            stats['success_rate'] = stats['successful_calls'] / stats['total_calls']
            stats['average_response_time'] = stats['total_response_time'] / stats['total_calls']
        else:
            stats['success_rate'] = 0.0
            stats['average_response_time'] = 0.0
        return stats


def main():
    """æµ‹è¯•å‡½æ•° - éªŒè¯Qwen3-VL-Pluså®¢æˆ·ç«¯åŠŸèƒ½"""
    try:
        print("ğŸ¤– Qwen3-VL-Plus å®¢æˆ·ç«¯æµ‹è¯•")
        print("=" * 50)

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = QwenVLPlusClient()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

        # æµ‹è¯•å›¾åƒè·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
        test_image = "/tmp/test_image.jpg"
        if os.path.exists(test_image):
            print(f"\nğŸ“¸ æµ‹è¯•å›¾åƒåˆ†æ: {test_image}")

            # éæµå¼æµ‹è¯•
            try:
                response = client.analyze_image(test_image, "å‘¢å¼µåœ–ç‰‡æœ‰ä¹œå˜¢ï¼Ÿ")
                if "choices" in response and len(response["choices"]) > 0:
                    content = response["choices"][0]["message"]["content"]
                    print(f"ğŸ“ åˆ†æç»“æœ: {content}")
                else:
                    print("âŒ å“åº”æ ¼å¼é”™è¯¯")
            except Exception as e:
                print(f"âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")

            # æµå¼æµ‹è¯•
            try:
                print("\nğŸŒŠ æµå¼åˆ†æ:")
                for chunk in client.stream_analyze_image(test_image, "è«‹ç°¡è¦æè¿°å‘¢å¼µåœ–"):
                    print(chunk, end='', flush=True)
                print()  # æ¢è¡Œ
            except Exception as e:
                print(f"âŒ æµå¼åˆ†æå¤±è´¥: {e}")

        else:
            print(f"âš ï¸ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
            print("ğŸ’¡ æç¤º: è¯·æä¾›æœ‰æ•ˆçš„å›¾åƒè·¯å¾„è¿›è¡Œæµ‹è¯•")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = client.get_call_statistics()
        print(f"\nğŸ“Š è°ƒç”¨ç»Ÿè®¡:")
        print(f"   æ€»è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}")
        print(f"   æˆåŠŸæ¬¡æ•°: {stats['successful_calls']}")
        print(f"   å¤±è´¥æ¬¡æ•°: {stats['failed_calls']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.2%}")
        if stats['average_response_time'] > 0:
            print(f"   å¹³å‡å“åº”æ—¶é—´: {stats['average_response_time']:.2f}ç§’")

        print("\nâœ… Qwen3-VL-Plus å®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ")

    except Exception as e:
        print(f"âŒ å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")


if __name__ == '__main__':
    main()