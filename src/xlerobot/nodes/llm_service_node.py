#!/usr/bin/env python3.10
# -*- coding: utf-8 -*-
"""
LLMæœåŠ¡èŠ‚ç‚¹ - ROS2èŠ‚ç‚¹å®ç°

è´Ÿè´£æ¥æ”¶ASRè¯†åˆ«ç»“æœï¼Œè°ƒç”¨LLMç”Ÿæˆå“åº”ï¼Œå¹¶å‘å¸ƒLLMå“åº”æ¶ˆæ¯ã€‚
å®ç°å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å’Œé”™è¯¯å¤„ç†æœºåˆ¶ã€‚

ä½œè€…: Claude Code
æ•…äº‹ID: Epic 1 ASRâ†’LLMâ†’TTSä¸²è”ä¿®å¤
"""

import os
import sys
import time
import asyncio
import logging
import traceback
from typing import Optional, Dict, Any
from dataclasses import dataclass

# ROS2ç›¸å…³å¯¼å…¥
import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile
from std_msgs.msg import Header, String
from audio_msg.msg import ASRResult, LLMResponse, LLMStatus

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥ç°æœ‰LLMæ¨¡å—
try:
    from modules.llm.qwen_client import QwenAPIClient
    from modules.asr.siqiang_intelligent_dialogue import SiQiangIntelligentDialogue
    from modules.llm.dialogue_context import DialogueContext
except ImportError as e:
    print(f"âŒ å¯¼å…¥LLMæ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿PYTHONPATHè®¾ç½®æ­£ç¡®")
    sys.exit(1)


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class LLMNodeConfig:
    """LLMèŠ‚ç‚¹é…ç½®"""
    qwen_api_key: str = ""
    model_name: str = "qwen-turbo"
    max_tokens: int = 2000
    temperature: float = 0.7
    session_timeout: int = 300  # 5åˆ†é’Ÿä¼šè¯è¶…æ—¶
    request_timeout: float = 15.0  # 15ç§’è¯·æ±‚è¶…æ—¶


class LLMServiceNode(Node):
    """LLMæœåŠ¡èŠ‚ç‚¹"""

    def __init__(self):
        super().__init__('llm_service_node')

        # é…ç½®
        self.config = LLMNodeConfig(
            qwen_api_key=os.getenv('QWEN_API_KEY', ''),
            model_name=os.getenv('QWEN_MODEL', 'qwen-turbo')
        )

        # çŠ¶æ€ç®¡ç†
        self.current_state = 0  # 0=idle, 1=processing, 2=error
        self.session_contexts: Dict[str, DialogueContext] = {}
        self.start_time = time.time()

        # æ€§èƒ½ç»Ÿè®¡
        self.total_requests = 0
        self.failed_requests = 0
        self.response_times = []

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        try:
            self.qwen_client = QwenAPIClient()
            self.dialogue_engine = SiQiangIntelligentDialogue()
            self.get_logger().info("âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.get_logger().error(f"âŒ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.current_state = 2
            return

        # åˆ›å»ºè®¢é˜…è€… - è®¢é˜…è¯­éŸ³å‘½ä»¤
        qos = QoSProfile(depth=10)
        self.voice_command_subscription = self.create_subscription(
            ASRResult,
            '/xlerobot/asr/result',
            self.voice_command_callback,
            qos
        )

        # åˆ›å»ºè®¢é˜…è€… - è®¢é˜…LLMè¯·æ±‚ï¼ˆæ¥è‡ªåè°ƒå™¨ï¼‰
        self.llm_request_subscription = self.create_subscription(
            Header,  # ä½¿ç”¨Headerä½œä¸ºç®€å•è¯·æ±‚æ¶ˆæ¯
            '/xlerobot/llm/request',
            self.llm_request_callback,
            qos
        )

        # åˆ›å»ºå‘å¸ƒè€… - å‘å¸ƒLLMå“åº”
        self.llm_publisher = self.create_publisher(
            LLMResponse,
            '/xlerobot/llm/response',
            qos
        )

        # å…¼å®¹æ€§Stringå‘å¸ƒè€…ï¼ˆç”¨äºstd_msgsé€šä¿¡ï¼‰
        self.llm_response_string_publisher = self.create_publisher(
            String,
            '/xlerobot/llm/response_string',
            qos
        )

        # åˆ›å»ºçŠ¶æ€å‘å¸ƒè€…
        self.status_publisher = self.create_publisher(
            LLMStatus,
            '/xlerobot/llm/status',
            qos
        )

        # åˆ›å»ºçŠ¶æ€å®šæ—¶å™¨ - å®šæœŸå‘å¸ƒçŠ¶æ€
        self.status_timer = self.create_timer(
            1.0,  # æ¯ç§’å‘å¸ƒä¸€æ¬¡çŠ¶æ€
            self.publish_status
        )

        self.get_logger().info("ğŸš€ LLMæœåŠ¡èŠ‚ç‚¹å¯åŠ¨å®Œæˆ")

    def voice_command_callback(self, msg: ASRResult):
        """å¤„ç†è¯­éŸ³å‘½ä»¤"""
        self.get_logger().info(f"ğŸ¤ æ”¶åˆ°è¯­éŸ³å‘½ä»¤: {msg.text} (ç½®ä¿¡åº¦: {msg.confidence:.2f})")

        # æ£€æŸ¥ASRæ˜¯å¦æˆåŠŸ
        if not msg.text.strip():
            self.get_logger().warning("âš ï¸ ASRç»“æœä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
            return

        # ğŸ”§ ä¿®å¤ï¼šé˜¿é‡Œäº‘ASR APIä¸è¿”å›ç½®ä¿¡åº¦å­—æ®µï¼Œç§»é™¤ç½®ä¿¡åº¦æ£€æŸ¥
        # å¦‚æœè¯†åˆ«åˆ°æ–‡æœ¬å†…å®¹ï¼Œç›´æ¥å¤„ç†ï¼ˆç½®ä¿¡åº¦é—®é¢˜å·²åœ¨ASRæœåŠ¡å±‚å¤„ç†ï¼‰
        self.get_logger().info(f"âœ… ASRè¯†åˆ«æˆåŠŸ: {msg.text} (ç½®ä¿¡åº¦: {msg.confidence:.2f})")

        # æ›´æ–°çŠ¶æ€
        self.current_state = 1  # processing
        self.total_requests += 1

        # å¼‚æ­¥å¤„ç†LLMè¯·æ±‚ - ä½¿ç”¨çº¿ç¨‹é¿å…asyncioäº‹ä»¶å¾ªç¯é—®é¢˜
        import concurrent.futures
        if not hasattr(self, '_executor'):
            self._executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)
        self._executor.submit(self._run_llm_request_sync, msg)

    def llm_request_callback(self, msg: Header):
        """å¤„ç†LLMè¯·æ±‚ï¼ˆæ¥è‡ªåè°ƒå™¨ï¼‰"""
        self.get_logger().info(f"ğŸ“¨ æ”¶åˆ°LLMè¯·æ±‚: {msg.frame_id}")

        # ä»frame_idæå–è¯·æ±‚æ–‡æœ¬
        request_text = msg.frame_id if msg.frame_id else "ä½ å¥½"

        # åˆ›å»ºæ¨¡æ‹ŸASRç»“æœ
        mock_asr_result = ASRResult()
        mock_asr_result.header = msg
        mock_asr_result.text = request_text
        mock_asr_result.confidence = 1.0
        mock_asr_result.status_code = 0

        # æ›´æ–°çŠ¶æ€
        self.current_state = 1  # processing
        self.total_requests += 1

        # å¼‚æ­¥å¤„ç†LLMè¯·æ±‚ - ä½¿ç”¨çº¿ç¨‹é¿å…asyncioäº‹ä»¶å¾ªç¯é—®é¢˜
        import concurrent.futures
        if not hasattr(self, '_executor'):
            self._executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)
        self._executor.submit(self._run_llm_request_sync, mock_asr_result)

    def _run_llm_request_sync(self, asr_msg: ASRResult):
        """åœ¨çº¿ç¨‹ä¸­è¿è¡ŒLLMè¯·æ±‚"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(self.process_llm_request(asr_msg))
        except Exception as e:
            self.get_logger().error(f"âŒ LLMè¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        finally:
            loop.close()

    async def process_llm_request(self, asr_msg: ASRResult):
        """å¼‚æ­¥å¤„ç†LLMè¯·æ±‚"""
        start_time = time.time()
        session_id = self.get_session_id(asr_msg.header)

        try:
            # è·å–æˆ–åˆ›å»ºä¼šè¯ä¸Šä¸‹æ–‡
            if session_id not in self.session_contexts:
                self.session_contexts[session_id] = DialogueContext()
                self.get_logger().info(f"ğŸ†• åˆ›å»ºæ–°ä¼šè¯: {session_id}")

            context = self.session_contexts[session_id]

            # æ„å»ºLLMè¯·æ±‚
            user_input = asr_msg.text.strip()

            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°ä¸Šä¸‹æ–‡
            context.add_user_message(user_input)

            # è°ƒç”¨LLMç”Ÿæˆå“åº”ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            try:
                response_text = await asyncio.wait_for(
                    self.generate_llm_response(user_input, context),
                    timeout=self.config.request_timeout
                )
            except asyncio.TimeoutError:
                self.get_logger().error(f"âŒ LLMå“åº”è¶…æ—¶ï¼ˆ{self.config.request_timeout}ç§’ï¼‰")
                self.failed_requests += 1
                self.current_state = 2  # error

                # åˆ›å»ºä¸´æ—¶ASRæ¶ˆæ¯ç”¨äºé”™è¯¯å“åº”
                temp_asr = ASRResult()
                temp_asr.header = Header()
                temp_asr.header.stamp = self.get_clock().now().to_msg()
                temp_asr.text = f"LLMå“åº”è¶…æ—¶ï¼ˆ{self.config.request_timeout}ç§’ï¼‰ï¼Œè¯·é‡è¯•"
                temp_asr.confidence = 0.0

                # å‘å¸ƒè¶…æ—¶é”™è¯¯å“åº”
                await self.publish_error_response(
                    session_id=session_id,
                    error_message=f"LLMå“åº”è¶…æ—¶ï¼ˆ{self.config.request_timeout}ç§’ï¼‰ï¼Œè¯·é‡è¯•",
                    original_asr=temp_asr
                )
                return

            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°ä¸Šä¸‹æ–‡
            context.add_assistant_message(response_text)

            # è®¡ç®—å“åº”æ—¶é—´
            response_time = time.time() - start_time
            self.response_times.append(response_time)

            # å‘å¸ƒLLMå“åº”
            await self.publish_llm_response(
                text=response_text,
                session_id=session_id,
                user_input=user_input,
                response_time=response_time,
                original_asr=asr_msg
            )

            self.get_logger().info(f"âœ… LLMå“åº”ç”Ÿæˆå®Œæˆ: {response_text[:50]}...")
            self.current_state = 0  # idle

        except Exception as e:
            self.get_logger().error(f"âŒ LLMå¤„ç†å¤±è´¥: {e}")
            self.get_logger().error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            self.failed_requests += 1
            self.current_state = 2  # error

            # å‘å¸ƒé”™è¯¯å“åº”
            await self.publish_error_response(
                session_id=session_id,
                error_message=str(e),
                original_asr=asr_msg
            )

    async def generate_llm_response(self, user_input: str, context: DialogueContext) -> str:
        """ç”ŸæˆLLMå“åº”"""
        try:
            # ä½¿ç”¨å¯¹è¯å¼•æ“ç”Ÿæˆå“åº”
            response = await self.dialogue_engine.generate_response_async(
                user_input=user_input,
                context=context.get_conversation_history()
            )

            # å¦‚æœå“åº”ä¸ºç©ºï¼Œä½¿ç”¨å¤‡ç”¨å“åº”
            if not response or response.strip() == "":
                response = "ä¸å¥½æ„æ€ï¼Œæˆ‘æš‚æ—¶æ— æ³•ç†è§£ä½ çš„æ„æ€ï¼Œå¯ä»¥å†è¯•ä¸€æ¬¡å—ï¼Ÿ"

            return response.strip()

        except Exception as e:
            self.get_logger().error(f"âŒ LLMç”Ÿæˆå“åº”å¤±è´¥: {e}")
            # é™çº§å¤„ç†ï¼šè¿”å›é»˜è®¤å“åº”
            return "ç³»ç»Ÿæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def publish_llm_response(self, text: str, session_id: str,
                                 user_input: str, response_time: float,
                                 original_asr: ASRResult):
        """å‘å¸ƒLLMå“åº”æ¶ˆæ¯"""
        msg = LLMResponse()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()

        msg.text = text
        msg.session_id = session_id
        msg.confidence = 0.8  # å›ºå®šç½®ä¿¡åº¦
        msg.status_code = 0  # æˆåŠŸ
        msg.error_message = ""

        msg.user_input = user_input
        msg.response_time = float(response_time)
        msg.model_name = self.config.model_name

        self.llm_publisher.publish(msg)

        # åŒæ—¶å‘å¸ƒStringæ ¼å¼æ¶ˆæ¯ï¼ˆå…¼å®¹æ€§ï¼‰
        string_msg = String()
        string_msg.data = text
        self.llm_response_string_publisher.publish(string_msg)

        self.get_logger().debug(f"ğŸ“¤ å‘å¸ƒLLMå“åº”: {text[:30]}...")

    async def publish_error_response(self, session_id: str, error_message: str,
                                   original_asr: ASRResult):
        """å‘å¸ƒé”™è¯¯å“åº”æ¶ˆæ¯"""
        msg = LLMResponse()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()

        msg.text = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
        msg.session_id = session_id
        msg.confidence = 0.0
        msg.status_code = 1  # é”™è¯¯
        msg.error_message = error_message

        msg.user_input = original_asr.text
        msg.response_time = 0.0
        msg.model_name = ""

        self.llm_publisher.publish(msg)

        # åŒæ—¶å‘å¸ƒStringæ ¼å¼æ¶ˆæ¯ï¼ˆå…¼å®¹æ€§ï¼‰
        string_msg = String()
        string_msg.data = msg.text  # é”™è¯¯å“åº”æ–‡æœ¬
        self.llm_response_string_publisher.publish(string_msg)

    def publish_status(self):
        """å‘å¸ƒèŠ‚ç‚¹çŠ¶æ€"""
        msg = LLMStatus()
        msg.header = Header()
        msg.header.stamp = self.get_clock().now().to_msg()

        msg.node_name = self.get_name()
        msg.state = self.current_state
        msg.avg_response_time = sum(self.response_times) / len(self.response_times) if self.response_times else 0.0
        msg.total_requests = self.total_requests
        msg.failed_requests = self.failed_requests
        msg.cpu_usage = 0.0  # TODO: å®ç°CPUä½¿ç”¨ç‡ç›‘æ§
        msg.memory_usage = 0.0  # TODO: å®ç°å†…å­˜ä½¿ç”¨ç‡ç›‘æ§
        msg.last_error = ""

        self.status_publisher.publish(msg)

    def get_session_id(self, header: Header) -> str:
        """è·å–æˆ–ç”Ÿæˆä¼šè¯ID"""
        # å¦‚æœASRæ¶ˆæ¯æœ‰session_idï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ç”ŸæˆåŸºäºæ—¶é—´çš„ID
        if hasattr(header, 'frame_id') and header.frame_id:
            return header.frame_id
        else:
            return f"session_{int(time.time())}"

    def cleanup_sessions(self):
        """æ¸…ç†è¶…æ—¶çš„ä¼šè¯"""
        current_time = time.time()
        timeout_sessions = []

        for session_id, context in self.session_contexts.items():
            if current_time - context.last_activity > self.config.session_timeout:
                timeout_sessions.append(session_id)

        for session_id in timeout_sessions:
            del self.session_contexts[session_id]
            self.get_logger().info(f"ğŸ—‘ï¸ æ¸…ç†è¶…æ—¶ä¼šè¯: {session_id}")


def main(args=None):
    """ä¸»å‡½æ•°"""
    try:
        # åˆå§‹åŒ–ROS2ï¼ˆå…ˆåˆå§‹åŒ–æ‰èƒ½ä½¿ç”¨loggerï¼‰
        rclpy.init(args=args)

        # åˆ›å»ºLLMæœåŠ¡èŠ‚ç‚¹
        node = LLMServiceNode()

        # æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆæ”¹ä¸ºè­¦å‘Šè€Œéå¼ºåˆ¶é€€å‡ºï¼‰
        qwen_api_key = os.getenv('QWEN_API_KEY')
        if not qwen_api_key:
            node.get_logger().warning("âš ï¸ QWEN_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
            node.get_logger().warning("ğŸ’¡ LLMåŠŸèƒ½å°†å—é™ï¼Œç³»ç»Ÿå°†ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
            node.get_logger().warning("   è®¾ç½®æ–¹æ³•: export QWEN_API_KEY='your_api_key_here'")

            # è°ƒè¯•ä¿¡æ¯
            env_debug = {k: v for k, v in os.environ.items() if 'QWEN' in k or 'API' in k}
            node.get_logger().debug(f"ğŸ” ç›¸å…³ç¯å¢ƒå˜é‡: {env_debug}")
        else:
            node.get_logger().info(f"âœ… QWEN_API_KEYå·²è®¾ç½®: {qwen_api_key[:10]}...")

        # æ¸…ç†ä¼šè¯å®šæ—¶å™¨
        session_cleanup_timer = node.create_timer(
            60.0,  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            node.cleanup_sessions
        )

        # è¿è¡ŒèŠ‚ç‚¹
        try:
            rclpy.spin(node)
        except KeyboardInterrupt:
            node.get_logger().info("ğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­èŠ‚ç‚¹...")
        finally:
            # æ¸…ç†èµ„æº
            node.destroy_node()
            rclpy.shutdown()

    except Exception as e:
        print(f"âŒ èŠ‚ç‚¹å¯åŠ¨å¤±è´¥: {e}")
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        sys.exit(1)


if __name__ == '__main__':
    main()