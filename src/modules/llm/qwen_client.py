#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Story 2.1: é€šä¹‰åƒé—®APIé›†æˆ - APIå®¢æˆ·ç«¯å®ç°

é€šä¹‰åƒé—®APIå®¢æˆ·ç«¯å®ç°ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è°ƒç”¨æ–¹å¼ã€‚
é›†æˆqwen3-vl-plusæ¨¡å‹ï¼Œæ”¯æŒ4000 tokensä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå“åº”æ—¶é—´<3ç§’ã€‚

ä½œè€…: Dev Agent
æ•…äº‹ID: Story 2.1
Epic: 2 - æ™ºèƒ½å¯¹è¯æ¨¡å—
"""

import os
import json
import logging
import asyncio
from typing import Dict, Any, Optional, List, Union, AsyncGenerator
from dataclasses import dataclass, field
import aiohttp
from aiohttp import ClientTimeout, ClientSession, ClientError
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# åŠ¨æ€å¯¼å…¥ROS2æ¨¡å—
try:
    import rclpy
    from rclpy.node import Node
    from std_msgs.msg import String
    from geometry_msgs.msg import Pose2D
    ROS2_AVAILABLE = True
except ImportError as e:
    ROS2_AVAILABLE = False
    print(f"âš ï¸ ROS2ç¯å¢ƒä¸å¯ç”¨ï¼Œé™çº§ä¸ºçº¯Pythonæ¨¡å¼: {e}")
    # åˆ›å»ºè™šæ‹Ÿç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
    class Node:
        pass
    class String:
        pass
    class Pose2D:
        pass


# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


@dataclass
class QwenConfig:
    """é€šä¹‰åƒé—®APIé…ç½® - qwen3-vl-plusè§†è§‰å¤šæ¨¡æ€æ¨¡å‹"""
    api_key: str = field(default_factory=lambda: os.getenv('QWEN_API_KEY', ''))
    api_base_url: str = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
    model_name: str = "qwen3-vl-plus"
    max_tokens: int = 4000
    temperature: float = 0.7
    top_p: float = 0.8
    timeout: int = 30
    max_retries: int = 3
    request_interval: float = 0.1  # è¯·æ±‚é—´éš”ï¼Œæ”¯æŒé™æµ


@dataclass
class QwenRequest:
    """é€šä¹‰åƒé—®è¯·æ±‚å¯¹è±¡"""
    messages: List[Dict[str, str]]
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    stream: bool = False


@dataclass
class QwenResponse:
    """é€šä¹‰åƒé—®å“åº”å¯¹è±¡"""
    text: str
    model: str
    usage: Dict[str, int]
    finish_reason: str
    request_id: str
    confidence: float = 1.0


class QwenAPIClient:
    """
    é€šä¹‰åƒé—®APIå®¢æˆ·ç«¯

    åŠŸèƒ½ç‰¹æ€§:
    - æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è°ƒç”¨
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶
    - é™æµä¿æŠ¤
    - é”™è¯¯å¤„ç†
    - è¯·æ±‚/å“åº”æ—¥å¿—
    - ROS2èŠ‚ç‚¹é›†æˆ
    """

    def __init__(self, config: Optional[QwenConfig] = None, node: Optional[Node] = None):
        """
        åˆå§‹åŒ–é€šä¹‰åƒé—®APIå®¢æˆ·ç«¯

        Args:
            config: APIé…ç½®å¯¹è±¡
            node: ROS2èŠ‚ç‚¹å®ä¾‹
        """
        self.config = config or QwenConfig()
        self.node = node
        self.session: Optional[ClientSession] = None
        self._rate_limiter = asyncio.Semaphore(10)  # é™åˆ¶å¹¶å‘æ•°
        self._last_request_time = 0
        self._request_count = 0
        self._error_count = 0

        # éªŒè¯API Key
        if not self.config.api_key:
            logger.warning("âš ï¸ é€šä¹‰åƒé—®API Keyæœªè®¾ç½®ï¼Œè¯·è®¾ç½®QWEN_API_KEYç¯å¢ƒå˜é‡")

        logger.info(f"âœ… é€šä¹‰åƒé—®APIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - æ¨¡å‹: {self.config.model_name}")
        logger.info(f"   - æœ€å¤§tokens: {self.config.max_tokens}")
        logger.info(f"   - æ¸©åº¦: {self.config.temperature}")
        logger.info(f"   - å¹¶å‘é™åˆ¶: 10")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self._init_session()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close()

    async def _init_session(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        timeout = ClientTimeout(total=self.config.timeout)
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=10,
            ttl_dns_cache=300,
            use_dns_cache=True
        )
        self.session = ClientSession(
            timeout=timeout,
            connector=connector,
            headers={
                'Authorization': f'Bearer {self.config.api_key}',
                'Content-Type': 'application/json'
            }
        )
        logger.info("âœ… HTTPä¼šè¯åˆå§‹åŒ–å®Œæˆ")

    async def close(self):
        """å…³é—­HTTPä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None
            logger.info("âœ… HTTPä¼šè¯å·²å…³é—­")

    def _build_request_payload(self, request: QwenRequest) -> Dict[str, Any]:
        """æ„å»ºè¯·æ±‚è½½è·"""
        payload = {
            "model": self.config.model_name,
            "input": {
                "messages": request.messages
            },
            "parameters": {
                "max_tokens": request.max_tokens or self.config.max_tokens,
                "temperature": request.temperature or self.config.temperature,
                "top_p": request.top_p or self.config.top_p,
                "incremental_output": request.stream
            }
        }
        return payload

    def _parse_response(self, response_data: Dict[str, Any]) -> QwenResponse:
        """è§£æAPIå“åº”"""
        try:
            output = response_data.get('output', {})
            choices = output.get('choices', [])
            text = ''

            # è§£æä¸åŒæ ¼å¼çš„å“åº”
            if choices:
                message = choices[0].get('message', {})
                content = message.get('content', [])

                if content and isinstance(content, list) and len(content) > 0:
                    # æ–°æ ¼å¼: contentæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ çš„textå­—æ®µ
                    text = content[0].get('text', '')
                elif isinstance(content, str):
                    # æ—§æ ¼å¼: contentç›´æ¥æ˜¯å­—ç¬¦ä¸²
                    text = content
                else:
                    # å…¶ä»–æ ¼å¼ï¼Œå°è¯•ä»messageç›´æ¥è·å–text
                    text = message.get('text', '')

            finish_reason = choices[0].get('finish_reason', 'stop') if choices else 'stop'

            usage = response_data.get('usage', {})
            request_id = response_data.get('request_id', '')

            return QwenResponse(
                text=text,
                model=self.config.model_name,
                usage=usage,
                finish_reason=finish_reason,
                request_id=request_id
            )
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            logger.error(f"å“åº”æ•°æ®: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
            raise ValueError(f"æ— æ³•è§£æAPIå“åº”: {e}")

    async def _rate_limit(self):
        """é™æµæ§åˆ¶"""
        current_time = asyncio.get_event_loop().time()
        time_since_last = current_time - self._last_request_time

        if time_since_last < self.config.request_interval:
            await asyncio.sleep(self.config.request_interval - time_since_last)

        self._last_request_time = asyncio.get_event_loop().time()
        self._request_count += 1

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((ClientError, asyncio.TimeoutError))
    )
    async def chat_async(
        self,
        messages: List[Dict[str, str]],
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        stream: bool = False
    ) -> QwenResponse:
        """
        å¼‚æ­¥èŠå¤©å¯¹è¯

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            max_tokens: æœ€å¤§è¾“å‡ºtokens
            temperature: é‡‡æ ·æ¸©åº¦
            stream: æ˜¯å¦æµå¼è¾“å‡º

        Returns:
            QwenResponse: å“åº”å¯¹è±¡
        """
        if not self.session:
            await self._init_session()

        async with self._rate_limiter:
            await self._rate_limit()

            request = QwenRequest(
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                stream=stream
            )

            payload = self._build_request_payload(request)

            try:
                logger.info(f"ğŸ“¤ å‘é€è¯·æ±‚: {len(messages)}æ¡æ¶ˆæ¯")
                logger.debug(f"ğŸ“¤ è¯·æ±‚è½½è·: {json.dumps(payload, ensure_ascii=False, indent=2)}")

                async with self.session.post(
                    self.config.api_base_url,
                    json=payload
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status}")
                        logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {error_text}")
                        raise ClientError(f"APIè¯·æ±‚å¤±è´¥: {response.status}")

                    response_data = await response.json()
                    logger.info(f"ğŸ“¥ æ”¶åˆ°å“åº”: {len(response_data)}å­—èŠ‚")
                    logger.debug(f"ğŸ“¥ å“åº”å†…å®¹: {json.dumps(response_data, ensure_ascii=False, indent=2)}")

                    parsed_response = self._parse_response(response_data)

                    # ROS2å‘å¸ƒ
                    if self.node:
                        msg = String()
                        msg.data = json.dumps({
                            'type': 'llm_response',
                            'text': parsed_response.text,
                            'model': parsed_response.model,
                            'usage': parsed_response.usage,
                            'request_id': parsed_response.request_id
                        })
                        self.node.get_logger().info(f"å‘å¸ƒLLMå“åº”åˆ°ROS2è¯é¢˜")

                    return parsed_response

            except Exception as e:
                self._error_count += 1
                logger.error(f"âŒ é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {e}")
                raise

    async def chat_stream_async(
        self,
        messages: List[Dict[str, str]],
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> AsyncGenerator[str, None]:
        """
        å¼‚æ­¥æµå¼èŠå¤©å¯¹è¯

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            max_tokens: æœ€å¤§è¾“å‡ºtokens
            temperature: é‡‡æ ·æ¸©åº¦

        Yields:
            str: æµå¼å“åº”çš„æ–‡æœ¬ç‰‡æ®µ
        """
        if not self.session:
            await self._init_session()

        async with self._rate_limiter:
            await self._rate_limit()

            request = QwenRequest(
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                stream=True
            )

            payload = self._build_request_payload(request)

            try:
                logger.info(f"ğŸ“¤ å‘é€æµå¼è¯·æ±‚: {len(messages)}æ¡æ¶ˆæ¯")

                async with self.session.post(
                    self.config.api_base_url,
                    json=payload
                ) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"âŒ æµå¼APIè¯·æ±‚å¤±è´¥: {response.status}")
                        raise ClientError(f"æµå¼APIè¯·æ±‚å¤±è´¥: {response.status}")

                    async for line in response.content:
                        if line:
                            line_str = line.decode('utf-8').strip()
                            if line_str.startswith('data: '):
                                data_str = line_str[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                                if data_str == '[DONE]':
                                    break
                                try:
                                    data = json.loads(data_str)
                                    output = data.get('output', {})
                                    text = output.get('text', '')
                                    if text:
                                        yield text
                                except json.JSONDecodeError:
                                    continue

            except Exception as e:
                self._error_count += 1
                logger.error(f"âŒ é€šä¹‰åƒé—®æµå¼APIè°ƒç”¨å¤±è´¥: {e}")
                raise

    def _chat_sync(
        self,
        messages: List[Dict[str, str]],
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> QwenResponse:
        """
        åŒæ­¥èŠå¤©å¯¹è¯ (å†…éƒ¨æ–¹æ³•)

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            max_tokens: æœ€å¤§è¾“å‡ºtokens
            temperature: é‡‡æ ·æ¸©åº¦

        Returns:
            QwenResponse: å“åº”å¯¹è±¡
        """
        return asyncio.run(self.chat_async(messages, max_tokens, temperature))

    async def chat(
        self,
        user_input: str,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None
    ) -> str:
        """
        å¼‚æ­¥èŠå¤©å¯¹è¯ (ç®€åŒ–æ¥å£)

        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            max_tokens: æœ€å¤§è¾“å‡ºtokens
            temperature: é‡‡æ ·æ¸©åº¦

        Returns:
            str: å“åº”æ–‡æœ¬å†…å®¹
        """
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
        messages = [
            {"role": "user", "content": user_input}
        ]

        try:
            response = await self.chat_async(messages, max_tokens, temperature)
            return response.text if response else ""
        except Exception as e:
            logger.error(f"âŒ LLMå“åº”å¤±è´¥: {e}")
            return ""

    async def health_check(self) -> Dict[str, Any]:
        """
        å¥åº·æ£€æŸ¥

        Returns:
            Dict[str, Any]: å¥åº·æ£€æŸ¥ç»“æœ
        """
        if not self.session:
            await self._init_session()

        test_messages = [
            {"role": "user", "content": "ä½ å¥½"}
        ]

        try:
            start_time = asyncio.get_event_loop().time()
            response = await self.chat_async(test_messages)
            end_time = asyncio.get_event_loop().time()
            response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            return {
                'status': 'healthy',
                'response_time_ms': round(response_time, 2),
                'api_call_success': True,
                'error_rate': round(self._error_count / max(self._request_count, 1) * 100, 2),
                'total_requests': self._request_count,
                'total_errors': self._error_count,
                'model': response.model
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e),
                'api_call_success': False,
                'error_rate': round(self._error_count / max(self._request_count, 1) * 100, 2),
                'total_requests': self._request_count,
                'total_errors': self._error_count
            }

    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–APIè°ƒç”¨ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'total_requests': self._request_count,
            'total_errors': self._error_count,
            'error_rate': round(self._error_count / max(self._request_count, 1) * 100, 2),
            'success_rate': round((self._request_count - self._error_count) / max(self._request_count, 1) * 100, 2),
            'model': self.config.model_name,
            'config': {
                'max_tokens': self.config.max_tokens,
                'temperature': self.config.temperature,
                'timeout': self.config.timeout,
                'max_retries': self.config.max_retries
            }
        }


# ROS2èŠ‚ç‚¹é›†æˆç¤ºä¾‹
class QwenLLMNode(Node):
    """é€šä¹‰åƒé—®LLM ROS2èŠ‚ç‚¹"""

    def __init__(self):
        super().__init__('qwen_llm_node')

        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self.config = QwenConfig()
        self.client = QwenAPIClient(self.config, self)

        # ROS2è®¢é˜…è€…å’Œå‘å¸ƒè€…
        self.subscription = self.create_subscription(
            String,
            '/llm/input',
            self.llm_input_callback,
            10
        )

        self.publisher = self.create_publisher(
            String,
            '/llm/output',
            10
        )

        # å®šæ—¶å¥åº·æ£€æŸ¥
        self.timer = self.create_timer(30.0, self.health_check_callback)

        self.get_logger().info("âœ… é€šä¹‰åƒé—®LLMèŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ")

    async def llm_input_callback(self, msg):
        """å¤„ç†LLMè¾“å…¥æ¶ˆæ¯"""
        try:
            # è§£æè¾“å…¥æ¶ˆæ¯
            input_data = json.loads(msg.data)

            if input_data.get('type') == 'chat':
                messages = input_data.get('messages', [])
                max_tokens = input_data.get('max_tokens')
                temperature = input_data.get('temperature')

                # è°ƒç”¨API
                response = await self.client.chat_async(messages, max_tokens, temperature)

                # å‘å¸ƒå“åº”
                output_msg = String()
                output_msg.data = json.dumps({
                    'type': 'chat_response',
                    'text': response.text,
                    'model': response.model,
                    'usage': response.usage,
                    'request_id': response.request_id
                })
                self.publisher.publish(output_msg)

        except Exception as e:
            self.get_logger().error(f"âŒ LLMå¤„ç†å¤±è´¥: {e}")

    def health_check_callback(self):
        """å®šæ—¶å¥åº·æ£€æŸ¥å›è°ƒ"""
        # è¿™é‡Œéœ€è¦å¼‚æ­¥æ‰§è¡Œå¥åº·æ£€æŸ¥
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨rclpy.spin_until_future_complete
        pass


if __name__ == '__main__':
    # ç¤ºä¾‹ç”¨æ³•
    async def main():
        config = QwenConfig(
            model_name="qwen3-vl-plus",
            max_tokens=2000,
            temperature=0.7
        )

        async with QwenAPIClient(config) as client:
            # æµ‹è¯•APIè°ƒç”¨
            messages = [
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
            ]

            response = await client.chat_async(messages)
            print(f"ğŸ¤– å›ç­”: {response.text}")
            print(f"ğŸ“Š ä½¿ç”¨æƒ…å†µ: {response.usage}")

            # å¥åº·æ£€æŸ¥
            health = await client.health_check()
            print(f"â¤ï¸  å¥åº·çŠ¶æ€: {health}")

    asyncio.run(main())
