#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Story 2.1: é€šä¹‰åƒé—®APIé›†æˆ - APIè°ƒç”¨ç®¡ç†å™¨

APIè°ƒç”¨ç®¡ç†å’Œé™æµæ¨¡å—ï¼Œå®ç°è¯·æ±‚é˜Ÿåˆ—ç®¡ç†ã€å¹¶å‘æ§åˆ¶å’Œé…é¢ç®¡ç†ã€‚
æ”¯æŒè¿æ¥æ± å¤ç”¨ã€å¼‚æ­¥è°ƒç”¨æ”¯æŒã€æ€§èƒ½ç›‘æ§å’Œé™æµä¿æŠ¤ã€‚

ä½œè€…: Dev Agent
æ•…äº‹ID: Story 2.1
Epic: 2 - æ™ºèƒ½å¯¹è¯æ¨¡å—
"""

import os
import time
import asyncio
import logging
from typing import Dict, Any, List, Optional, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import json
import weakref
from collections import deque, defaultdict
import threading

# åŠ¨æ€å¯¼å…¥ROS2æ¨¡å—
try:
    import rclpy
    from rclpy.node import Node
    from std_msgs.msg import String
    ROS2_AVAILABLE = True
except ImportError as e:
    ROS2_AVAILABLE = False
    print(f"âš ï¸ ROS2ç¯å¢ƒä¸å¯ç”¨ï¼Œé™çº§ä¸ºçº¯Pythonæ¨¡å¼: {e}")
    # åˆ›å»ºè™šæ‹Ÿç±»ä»¥é¿å…å¯¼å…¥é”™è¯¯
    class Node:
        pass
    class String:
        pass

from .qwen_client import QwenAPIClient, QwenConfig, QwenRequest, QwenResponse


logger = logging.getLogger(__name__)


class RequestPriority(Enum):
    """è¯·æ±‚ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4


@dataclass
class RateLimitConfig:
    """é™æµé…ç½®"""
    max_requests_per_minute: int = 60
    max_requests_per_hour: int = 3600
    max_concurrent_requests: int = 10
    burst_limit: int = 20  # çªå‘è¯·æ±‚é™åˆ¶
    cooldown_period: float = 1.0  # é™æµå†·å´æ—¶é—´(ç§’)


@dataclass
class APIRequest:
    """APIè¯·æ±‚å¯¹è±¡"""
    id: str
    messages: List[Dict[str, str]]
    callback: Optional[Callable] = None
    priority: RequestPriority = RequestPriority.NORMAL
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    created_at: float = field(default_factory=time.time)
    retry_count: int = 0
    max_retries: int = 3
    timeout: float = 30.0


@dataclass
class APIResponse:
    """APIå“åº”å¯¹è±¡"""
    request_id: str
    response: QwenResponse
    success: bool
    error: Optional[str] = None
    response_time: float = 0.0
    timestamp: float = field(default_factory=time.time)


class RequestQueue:
    """è¯·æ±‚é˜Ÿåˆ—ç®¡ç†"""

    def __init__(self):
        self.queues: Dict[RequestPriority, deque] = {
            priority: deque() for priority in RequestPriority
        }
        self.active_requests: Dict[str, APIRequest] = {}
        self.lock = threading.RLock()

    def add_request(self, request: APIRequest):
        """æ·»åŠ è¯·æ±‚åˆ°é˜Ÿåˆ—"""
        with self.lock:
            self.queues[request.priority].append(request)
            logger.debug(f"ğŸ“ æ·»åŠ è¯·æ±‚åˆ°é˜Ÿåˆ—: {request.id}, ä¼˜å…ˆçº§: {request.priority.name}")

    def get_next_request(self) -> Optional[APIRequest]:
        """è·å–ä¸‹ä¸€ä¸ªè¦å¤„ç†çš„è¯·æ±‚"""
        with self.lock:
            # æŒ‰ä¼˜å…ˆçº§é¡ºåºå¤„ç†
            for priority in [RequestPriority.CRITICAL, RequestPriority.HIGH,
                           RequestPriority.NORMAL, RequestPriority.LOW]:
                if self.queues[priority]:
                    request = self.queues[priority].popleft()
                    self.active_requests[request.id] = request
                    logger.debug(f"ğŸ“¤ ä»é˜Ÿåˆ—è·å–è¯·æ±‚: {request.id}")
                    return request
            return None

    def mark_completed(self, request_id: str):
        """æ ‡è®°è¯·æ±‚å·²å®Œæˆ"""
        with self.lock:
            if request_id in self.active_requests:
                del self.active_requests[request_id]
                logger.debug(f"âœ… è¯·æ±‚å·²å®Œæˆ: {request_id}")

    def get_queue_size(self, priority: Optional[RequestPriority] = None) -> int:
        """è·å–é˜Ÿåˆ—å¤§å°"""
        with self.lock:
            if priority:
                return len(self.queues[priority])
            return sum(len(queue) for queue in self.queues.values())

    def get_active_count(self) -> int:
        """è·å–æ´»è·ƒè¯·æ±‚æ•°é‡"""
        with self.lock:
            return len(self.active_requests)


class RateLimiter:
    """é™æµå™¨"""

    def __init__(self, config: RateLimitConfig):
        self.config = config
        self.request_times: deque = deque()
        self.hourly_requests: deque = deque()
        self.burst_tokens: int = config.burst_limit
        self.last_refill = time.time()
        self.lock = threading.RLock()

    def acquire(self) -> bool:
        """
        è·å–è¯·æ±‚ä»¤ç‰Œ

        Returns:
            bool: æ˜¯å¦è·å–æˆåŠŸ
        """
        with self.lock:
            current_time = time.time()

            # æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•
            self._cleanup_old_requests(current_time)

            # æ£€æŸ¥æ¯åˆ†é’Ÿé™åˆ¶
            if len(self.request_times) >= self.config.max_requests_per_minute:
                logger.warning(f"âš ï¸ è¾¾åˆ°æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶: {self.config.max_requests_per_minute}")
                return False

            # æ£€æŸ¥æ¯å°æ—¶é™åˆ¶
            if len(self.hourly_requests) >= self.config.max_requests_per_hour:
                logger.warning(f"âš ï¸ è¾¾åˆ°æ¯å°æ—¶è¯·æ±‚é™åˆ¶: {self.config.max_requests_per_hour}")
                return False

            # æ£€æŸ¥çªå‘ä»¤ç‰Œ
            if self.burst_tokens <= 0:
                logger.warning(f"âš ï¸ çªå‘ä»¤ç‰Œè€—å°½")
                return False

            # è®°å½•è¯·æ±‚
            self.request_times.append(current_time)
            self.hourly_requests.append(current_time)
            self.burst_tokens -= 1

            logger.debug(f"âœ… è·å–è¯·æ±‚ä»¤ç‰ŒæˆåŠŸï¼Œå‰©ä½™: {self.burst_tokens}")
            return True

    def _cleanup_old_requests(self, current_time: float):
        """æ¸…ç†è¿‡æœŸçš„è¯·æ±‚è®°å½•"""
        # æ¸…ç†æ¯åˆ†é’Ÿè®°å½•
        minute_ago = current_time - 60
        while self.request_times and self.request_times[0] < minute_ago:
            self.request_times.popleft()

        # æ¸…ç†æ¯å°æ—¶è®°å½•
        hour_ago = current_time - 3600
        while self.hourly_requests and self.hourly_requests[0] < hour_ago:
            self.hourly_requests.popleft()

        # é‡ç½®çªå‘ä»¤ç‰Œ
        if current_time - self.last_refill >= self.config.cooldown_period:
            self.burst_tokens = min(self.config.burst_limit,
                                  self.burst_tokens + 1)
            self.last_refill = current_time

    def get_status(self) -> Dict[str, Any]:
        """è·å–é™æµçŠ¶æ€"""
        with self.lock:
            return {
                'requests_per_minute': len(self.request_times),
                'requests_per_hour': len(self.hourly_requests),
                'burst_tokens': self.burst_tokens,
                'max_requests_per_minute': self.config.max_requests_per_minute,
                'max_requests_per_hour': self.config.max_requests_per_hour,
                'max_burst': self.config.burst_limit
            }


class APIManager:
    """
    APIè°ƒç”¨ç®¡ç†å™¨

    åŠŸèƒ½ç‰¹æ€§:
    - è¯·æ±‚é˜Ÿåˆ—ç®¡ç†
    - å¹¶å‘æ§åˆ¶
    - é™æµä¿æŠ¤
    - è‡ªåŠ¨é‡è¯•
    - æ€§èƒ½ç›‘æ§
    - é”™è¯¯å¤„ç†
    - é…é¢ç®¡ç†
    """

    def __init__(
        self,
        config: QwenConfig,
        rate_config: Optional[RateLimitConfig] = None,
        node: Optional[Node] = None
    ):
        """
        åˆå§‹åŒ–APIç®¡ç†å™¨

        Args:
            config: APIé…ç½®
            rate_config: é™æµé…ç½®
            node: ROS2èŠ‚ç‚¹å®ä¾‹
        """
        self.config = config
        self.rate_config = rate_config or RateLimitConfig()
        self.node = node
        self.client: Optional[QwenAPIClient] = None

        # æ ¸å¿ƒç»„ä»¶
        self.request_queue = RequestQueue()
        self.rate_limiter = RateLimiter(self.rate_config)

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_response_time': 0.0,
            'average_response_time': 0.0,
            'last_request_time': 0.0,
            'peak_concurrent_requests': 0
        }

        # å›è°ƒå‡½æ•°
        self.response_callbacks: List[Callable] = []

        # æ§åˆ¶æ ‡å¿—
        self.is_running = False
        self.worker_task: Optional[asyncio.Task] = None
        self.lock = threading.RLock()

        logger.info("âœ… APIç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - æœ€å¤§å¹¶å‘: {self.rate_config.max_concurrent_requests}")
        logger.info(f"   - é™æµ: {self.rate_config.max_requests_per_minute}/åˆ†é’Ÿ")

    async def start(self):
        """å¯åŠ¨APIç®¡ç†å™¨"""
        if self.is_running:
            logger.warning("âš ï¸ APIç®¡ç†å™¨å·²åœ¨è¿è¡Œ")
            return

        self.is_running = True
        self.client = QwenAPIClient(self.config, self.node)
        await self.client._init_session()

        # å¯åŠ¨å·¥ä½œåç¨‹
        self.worker_task = asyncio.create_task(self._worker_loop())

        logger.info("ğŸš€ APIç®¡ç†å™¨å·²å¯åŠ¨")

    async def stop(self):
        """åœæ­¢APIç®¡ç†å™¨"""
        if not self.is_running:
            return

        self.is_running = False

        if self.worker_task:
            self.worker_task.cancel()
            try:
                await self.worker_task
            except asyncio.CancelledError:
                pass

        if self.client:
            await self.client.close()

        logger.info("ğŸ›‘ APIç®¡ç†å™¨å·²åœæ­¢")

    async def _worker_loop(self):
        """å·¥ä½œåç¨‹å¾ªç¯"""
        semaphore = asyncio.Semaphore(self.rate_config.max_concurrent_requests)

        while self.is_running:
            try:
                # è·å–ä¸‹ä¸€ä¸ªè¯·æ±‚
                request = self.request_queue.get_next_request()
                if not request:
                    await asyncio.sleep(0.1)
                    continue

                # æ£€æŸ¥é™æµ
                if not self.rate_limiter.acquire():
                    # é™æµå¤±è´¥ï¼Œé‡æ–°åŠ å…¥é˜Ÿåˆ—
                    self.request_queue.add_request(request)
                    await asyncio.sleep(1)
                    continue

                # å¼‚æ­¥å¤„ç†è¯·æ±‚
                asyncio.create_task(self._process_request(request, semaphore))

            except Exception as e:
                logger.error(f"âŒ å·¥ä½œå¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(1)

    async def _process_request(self, request: APIRequest, semaphore: asyncio.Semaphore):
        """å¤„ç†å•ä¸ªè¯·æ±‚"""
        start_time = time.time()

        try:
            async with semaphore:
                # æ›´æ–°å¹¶å‘ç»Ÿè®¡
                with self.lock:
                    self.stats['total_requests'] += 1
                    active_count = self.request_queue.get_active_count()
                    if active_count > self.stats['peak_concurrent_requests']:
                        self.stats['peak_concurrent_requests'] = active_count

                # è°ƒç”¨API
                response = await self.client.chat_async(
                    messages=request.messages,
                    max_tokens=request.max_tokens,
                    temperature=request.temperature
                )

                # å¤„ç†å“åº”
                response_time = time.time() - start_time
                api_response = APIResponse(
                    request_id=request.id,
                    response=response,
                    success=True,
                    response_time=response_time
                )

                # æ›´æ–°ç»Ÿè®¡
                self._update_stats(response_time, True)

                # è°ƒç”¨å›è°ƒ
                await self._handle_response(api_response)

        except Exception as e:
            # å¤„ç†é”™è¯¯å’Œé‡è¯•
            error_time = time.time() - start_time
            error_msg = str(e)

            if request.retry_count < request.max_retries:
                logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {request.id}, é”™è¯¯: {error_msg}")
                request.retry_count += 1
                await asyncio.sleep(2 ** request.retry_count)  # æŒ‡æ•°é€€é¿
                self.request_queue.add_request(request)
            else:
                logger.error(f"âŒ è¯·æ±‚æœ€ç»ˆå¤±è´¥: {request.id}, é”™è¯¯: {error_msg}")
                api_response = APIResponse(
                    request_id=request.id,
                    response=None,
                    success=False,
                    error=error_msg,
                    response_time=error_time
                )

                self._update_stats(error_time, False)
                await self._handle_response(api_response)

        finally:
            self.request_queue.mark_completed(request.id)

    def _update_stats(self, response_time: float, success: bool):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            if success:
                self.stats['successful_requests'] += 1
            else:
                self.stats['failed_requests'] += 1

            self.stats['total_response_time'] += response_time
            self.stats['average_response_time'] = (
                self.stats['total_response_time'] / self.stats['total_requests']
            )
            self.stats['last_request_time'] = time.time()

    async def _handle_response(self, api_response: APIResponse):
        """å¤„ç†APIå“åº”"""
        # è°ƒç”¨æ³¨å†Œå›è°ƒ
        for callback in self.response_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(api_response)
                else:
                    callback(api_response)
            except Exception as e:
                logger.error(f"âŒ å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")

        # å‘å¸ƒROS2æ¶ˆæ¯
        if self.node:
            msg = String()
            msg.data = json.dumps({
                'type': 'api_response',
                'request_id': api_response.request_id,
                'success': api_response.success,
                'error': api_response.error,
                'response_time': api_response.response_time,
                'timestamp': api_response.timestamp
            })
            self.node.get_logger().info(f"å‘å¸ƒAPIå“åº”åˆ°ROS2è¯é¢˜")

    async def submit_request(
        self,
        messages: List[Dict[str, str]],
        callback: Optional[Callable] = None,
        priority: RequestPriority = RequestPriority.NORMAL,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        timeout: float = 30.0
    ) -> str:
        """
        æäº¤APIè¯·æ±‚

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            callback: å“åº”å›è°ƒå‡½æ•°
            priority: è¯·æ±‚ä¼˜å…ˆçº§
            max_tokens: æœ€å¤§è¾“å‡ºtokens
            temperature: é‡‡æ ·æ¸©åº¦
            timeout: è¶…æ—¶æ—¶é—´

        Returns:
            str: è¯·æ±‚ID
        """
        if not self.is_running:
            raise RuntimeError("APIç®¡ç†å™¨æœªå¯åŠ¨")

        import uuid
        request_id = str(uuid.uuid4())[:8]

        request = APIRequest(
            id=request_id,
            messages=messages,
            callback=callback,
            priority=priority,
            max_tokens=max_tokens,
            temperature=temperature,
            timeout=timeout
        )

        self.request_queue.add_request(request)

        logger.info(f"ğŸ“ æäº¤è¯·æ±‚: {request_id}, ä¼˜å…ˆçº§: {priority.name}")
        return request_id

    def add_response_callback(self, callback: Callable):
        """æ·»åŠ å“åº”å›è°ƒå‡½æ•°"""
        self.response_callbacks.append(callback)
        logger.info(f"ğŸ“‹ æ·»åŠ å“åº”å›è°ƒ: {callback.__name__}")

    def get_status(self) -> Dict[str, Any]:
        """è·å–ç®¡ç†å™¨çŠ¶æ€"""
        with self.lock:
            queue_status = {
                'total_queue_size': self.request_queue.get_queue_size(),
                'active_requests': self.request_queue.get_active_count(),
                'peak_concurrent': self.stats['peak_concurrent_requests']
            }

            rate_status = self.rate_limiter.get_status()

            success_rate = (
                self.stats['successful_requests'] / max(self.stats['total_requests'], 1)
            ) * 100

            return {
                'is_running': self.is_running,
                'queue': queue_status,
                'rate_limiter': rate_status,
                'stats': {
                    **self.stats,
                    'success_rate': round(success_rate, 2),
                    'failure_rate': round(100 - success_rate, 2)
                }
            }

    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        with self.lock:
            return {
                'total_requests': self.stats['total_requests'],
                'successful_requests': self.stats['successful_requests'],
                'failed_requests': self.stats['failed_requests'],
                'success_rate': round(
                    self.stats['successful_requests'] / max(self.stats['total_requests'], 1) * 100,
                    2
                ),
                'average_response_time_ms': round(
                    self.stats['average_response_time'] * 1000, 2
                ),
                'peak_concurrent_requests': self.stats['peak_concurrent_requests'],
                'last_request_time': self.stats['last_request_time']
            }


# ROS2èŠ‚ç‚¹é›†æˆ
class QwenAPIManagerNode(Node):
    """é€šä¹‰åƒé—®APIç®¡ç†å™¨ROS2èŠ‚ç‚¹"""

    def __init__(self):
        super().__init__('qwen_api_manager_node')

        # åˆå§‹åŒ–é…ç½®
        self.config = QwenConfig()
        self.rate_config = RateLimitConfig(
            max_requests_per_minute=60,
            max_concurrent_requests=10
        )

        # åˆå§‹åŒ–APIç®¡ç†å™¨
        self.manager = APIManager(self.config, self.rate_config, self)

        # ROS2è®¢é˜…è€…å’Œå‘å¸ƒè€…
        self.input_subscription = self.create_subscription(
            String,
            '/llm/api/input',
            self.api_input_callback,
            10
        )

        self.output_publisher = self.create_publisher(
            String,
            '/llm/api/output',
            10
        )

        self.status_publisher = self.create_publisher(
            String,
            '/llm/api/status',
            10
        )

        # å®šæ—¶å™¨
        self.status_timer = self.create_timer(10.0, self.status_callback)

        # å¯åŠ¨ç®¡ç†å™¨
        asyncio.create_task(self._start_manager())

        self.get_logger().info("âœ… é€šä¹‰åƒé—®APIç®¡ç†å™¨èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆ")

    async def _start_manager(self):
        """å¯åŠ¨APIç®¡ç†å™¨"""
        try:
            await self.manager.start()
        except Exception as e:
            self.get_logger().error(f"âŒ APIç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {e}")

    async def api_input_callback(self, msg):
        """å¤„ç†APIè¾“å…¥æ¶ˆæ¯"""
        try:
            input_data = json.loads(msg.data)

            if input_data.get('type') == 'submit_request':
                messages = input_data.get('messages', [])
                priority = RequestPriority(input_data.get('priority', 2))
                max_tokens = input_data.get('max_tokens')
                temperature = input_data.get('temperature')

                request_id = await self.manager.submit_request(
                    messages=messages,
                    priority=priority,
                    max_tokens=max_tokens,
                    temperature=temperature
                )

                # å“åº”è¯·æ±‚ID
                response_msg = String()
                response_msg.data = json.dumps({
                    'type': 'request_submitted',
                    'request_id': request_id,
                    'status': 'queued'
                })
                self.output_publisher.publish(response_msg)

        except Exception as e:
            self.get_logger().error(f"âŒ APIè¾“å…¥å¤„ç†å¤±è´¥: {e}")

    def status_callback(self):
        """å‘å¸ƒçŠ¶æ€æ¶ˆæ¯"""
        try:
            status = self.manager.get_status()
            status_msg = String()
            status_msg.data = json.dumps(status)
            self.status_publisher.publish(status_msg)
        except Exception as e:
            self.get_logger().error(f"âŒ çŠ¶æ€å‘å¸ƒå¤±è´¥: {e}")


if __name__ == '__main__':
    # ç¤ºä¾‹ç”¨æ³•
    async def main():
        config = QwenConfig(model_name="qwen3-vl-plus")
        rate_config = RateLimitConfig(max_concurrent_requests=5)

        manager = APIManager(config, rate_config)

        # å¯åŠ¨ç®¡ç†å™¨
        await manager.start()

        # æäº¤æµ‹è¯•è¯·æ±‚
        async def test_callback(response: APIResponse):
            if response.success:
                print(f"âœ… è¯·æ±‚æˆåŠŸ: {response.request_id}")
                print(f"ğŸ“ å›ç­”: {response.response.text}")
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {response.request_id}, é”™è¯¯: {response.error}")

        request_id = await manager.submit_request(
            messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}],
            callback=test_callback,
            priority=RequestPriority.NORMAL
        )

        print(f"ğŸ“ æäº¤è¯·æ±‚: {request_id}")

        # ç­‰å¾…å¤„ç†
        await asyncio.sleep(5)

        # è·å–çŠ¶æ€
        status = manager.get_status()
        print(f"ğŸ“Š çŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")

        # åœæ­¢ç®¡ç†å™¨
        await manager.stop()

    asyncio.run(main())
