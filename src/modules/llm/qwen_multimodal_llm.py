#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Qwen3-VL-Plus å¤šæ¨¡æ€LLMé›†æˆ
æ”¯æŒæ–‡æœ¬ã€å›¾åƒç­‰å¤šæ¨¡æ€è¾“å…¥ï¼Œæä¾›æ™ºèƒ½å¯¹è¯èƒ½åŠ›
"""

import os
import json
import logging
import base64
import asyncio
import aiohttp
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class MultimodalMessage:
    """å¤šæ¨¡æ€æ¶ˆæ¯"""
    content: str
    message_type: str  # text, image, audio
    media_data: Optional[bytes] = None
    media_type: Optional[str] = None  # image/jpeg, image/png, etc.

class QwenMultimodalLLM:
    """Qwen3-VL-Plus å¤šæ¨¡æ€LLMå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str = "", model: str = "qwen3-vl-plus"):
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY", "")
        self.model = model
        self.base_url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation"
        self.session = None

        # æ”¯æŒçš„è¾“å…¥ç±»å‹
        self.supported_image_types = ["image/jpeg", "image/png", "image/webp"]
        self.supported_audio_types = ["audio/wav", "audio/mp3", "audio/flac"]

        # é»˜è®¤å‚æ•°
        self.default_temperature = 0.7
        self.default_max_tokens = 2000
        self.default_top_p = 0.8

    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        try:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=60),
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
            )
            logger.info("âœ… Qwenå¤šæ¨¡æ€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ Qwenå¤šæ¨¡æ€LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.session:
            await self.session.close()
            self.session = None

    def _prepare_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å‡†å¤‡æ¶ˆæ¯æ ¼å¼"""
        formatted_messages = []

        for msg in messages:
            if msg.get("role") in ["system", "user", "assistant"]:
                formatted_msg = {
                    "role": msg["role"],
                    "content": []
                }

                content = msg.get("content", "")
                if isinstance(content, str):
                    formatted_msg["content"].append({"text": content})
                elif isinstance(content, list):
                    for item in content:
                        if isinstance(item, str):
                            formatted_msg["content"].append({"text": item})
                        elif isinstance(item, dict):
                            if "text" in item:
                                formatted_msg["content"].append({"text": item["text"]})
                            elif "image" in item:
                                formatted_msg["content"].append({"image": item["image"]})
                            elif "audio" in item:
                                formatted_msg["content"].append({"audio": item["audio"]})

                formatted_messages.append(formatted_msg)

        return formatted_messages

    def _encode_image(self, image_data: bytes) -> str:
        """ç¼–ç å›¾åƒæ•°æ®"""
        return base64.b64encode(image_data).decode('utf-8')

    def _encode_audio(self, audio_data: bytes) -> str:
        """ç¼–ç éŸ³é¢‘æ•°æ®"""
        return base64.b64encode(audio_data).decode('utf-8')

    async def generate_response(
        self,
        prompt: str,
        context: Optional[List[Dict[str, Any]]] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        top_p: Optional[float] = None,
        images: Optional[List[bytes]] = None,
        audio_data: Optional[bytes] = None
    ) -> Optional[str]:
        """ç”Ÿæˆå¤šæ¨¡æ€å“åº”"""
        try:
            if not self.session:
                logger.error("âŒ LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return None

            # æ„å»ºæ¶ˆæ¯
            messages = []

            # æ·»åŠ ç³»ç»Ÿæç¤º
            system_prompt = """ä½ æ˜¯å‚»å¼ºï¼Œä¸€ä¸ªå‹å¥½ã€æ™ºèƒ½çš„ç²¤è¯­è¯­éŸ³åŠ©æ‰‹ã€‚ä½ å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š
1. ç”¨ç²¤è¯­å›ç­”é—®é¢˜
2. å›ç­”ç®€æ´æ˜äº†ï¼Œé€‚åˆè¯­éŸ³æ’­æ”¾
3. å…·å¤‡å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å¤„ç†å›¾åƒã€éŸ³é¢‘å’Œæ–‡æœ¬
4. ä¹äºåŠ©äººï¼Œå¯¹å„ç§é—®é¢˜éƒ½æœ‰è€å¿ƒ
5. æ”¯æŒå¤©æ°”æŸ¥è¯¢ã€æ—¶é—´è¯¢é—®ã€ç”Ÿæ´»å¸®åŠ©ç­‰åŠŸèƒ½"""

            messages.append({
                "role": "system",
                "content": system_prompt
            })

            # æ·»åŠ ä¸Šä¸‹æ–‡
            if context:
                messages.extend(context)

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_content = [{"text": prompt}]

            # æ·»åŠ å›¾åƒ
            if images:
                for i, img_data in enumerate(images):
                    user_content.append({
                        "image": f"data:image/jpeg;base64,{self._encode_image(img_data)}"
                    })

            # æ·»åŠ éŸ³é¢‘
            if audio_data:
                user_content.append({
                    "audio": f"data:audio/wav;base64,{self._encode_audio(audio_data)}"
                })

            messages.append({
                "role": "user",
                "content": user_content
            })

            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "model": self.model,
                "input": {
                    "messages": self._prepare_messages(messages)
                },
                "parameters": {
                    "temperature": temperature or self.default_temperature,
                    "max_tokens": max_tokens or self.default_max_tokens,
                    "top_p": top_p or self.default_top_p,
                    "stream": False
                }
            }

            logger.info(f"ğŸ¤– è°ƒç”¨Qwenå¤šæ¨¡æ€LLM: {prompt[:50]}...")

            # å‘é€è¯·æ±‚
            async with self.session.post(self.base_url, json=params) as response:
                if response.status == 200:
                    result = await response.json()

                    if "output" in result and "text" in result["output"]:
                        response_text = result["output"]["text"].strip()
                        logger.info(f"âœ… LLMå“åº”: {response_text[:100]}...")
                        return response_text
                    else:
                        logger.error(f"âŒ LLMå“åº”æ ¼å¼é”™è¯¯: {result}")
                        return None
                else:
                    logger.error(f"âŒ LLMè¯·æ±‚å¤±è´¥: {response.status} - {await response.text()}")
                    return None

        except Exception as e:
            logger.error(f"âŒ LLMç”Ÿæˆå“åº”å¤±è´¥: {e}")
            return None

    async def process_voice_command(
        self,
        text: str,
        previous_context: Optional[List[Dict[str, Any]]] = None
    ) -> Optional[str]:
        """å¤„ç†è¯­éŸ³å‘½ä»¤"""
        try:
            # ä¸“é—¨ä¸ºè¯­éŸ³äº¤äº’ä¼˜åŒ–çš„æç¤º
            prompt = f"ç”¨æˆ·è¯´ï¼š{text}\nè¯·ç”¨ç²¤è¯­ç®€çŸ­å›ç­”ï¼š"

            # æ„å»ºä¸Šä¸‹æ–‡
            context = []
            if previous_context:
                # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…tokenè¶…é™
                context = previous_context[-3:] if len(previous_context) > 3 else previous_context

            response = await self.generate_response(
                prompt=prompt,
                context=context,
                temperature=0.7,
                max_tokens=200  # è¯­éŸ³å›å¤é™åˆ¶åœ¨200å­—ç¬¦å†…
            )

            if response:
                # ç¡®ä¿å›å¤é€‚åˆè¯­éŸ³æ’­æ”¾
                response = response.strip()
                if len(response) > 150:
                    response = response[:150] + "..."

                logger.info(f"ğŸ¤ è¯­éŸ³å‘½ä»¤å¤„ç†: {text[:30]}... -> {response[:50]}...")
                return response
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

        except Exception as e:
            logger.error(f"âŒ è¯­éŸ³å‘½ä»¤å¤„ç†å¤±è´¥: {e}")
            return "ç³»ç»Ÿé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def analyze_image_query(
        self,
        image_data: bytes,
        query: str,
        context: Optional[List[Dict[str, Any]]] = None
    ) -> Optional[str]:
        """åˆ†æå›¾åƒæŸ¥è¯¢"""
        try:
            prompt = f"ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¹¶è¯¢é—®ï¼š{query}\nè¯·ç”¨ç²¤è¯­è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹å¹¶å›ç­”é—®é¢˜ã€‚"

            response = await self.generate_response(
                prompt=prompt,
                context=context,
                images=[image_data],
                max_tokens=500
            )

            if response:
                logger.info(f"ğŸ–¼ï¸ å›¾åƒæŸ¥è¯¢åˆ†æ: {query[:30]}...")
                return response
            else:
                return "æˆ‘æ— æ³•åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œè¯·ç¡®è®¤å›¾ç‰‡æ¸…æ™°åº¦ã€‚"

        except Exception as e:
            logger.error(f"âŒ å›¾åƒæŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            return "å›¾åƒåˆ†æé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async def get_weather_response(self, location: str = "å½“å‰åœ°ç‚¹") -> Optional[str]:
        """è·å–å¤©æ°”å›å¤"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„å¤©æ°”API
            # ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿå›å¤
            weather_responses = [
                f"{location}ä»Šæ—¥å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦é€‚å®œï¼Œé€‚åˆå‡ºè¡Œ",
                f"{location}ä»Šæ—¥å¤šäº‘ï¼Œæ¸©åº¦é€‚ä¸­ï¼Œå»ºè®®æºå¸¦å¤–å¥—",
                f"{location}ä»Šæ—¥æœ‰å°é›¨ï¼Œè®°å¾—å¸¦ä¼å‡ºé—¨",
                f"{location}ä»Šæ—¥é˜´å¤©ï¼Œæ¸©åº¦åå‡‰ï¼Œæ³¨æ„ä¿æš–"
            ]

            import random
            response = random.choice(weather_responses)

            logger.info(f"ğŸŒ¤ï¸ å¤©æ°”æŸ¥è¯¢: {location}")
            return response

        except Exception as e:
            logger.error(f"âŒ å¤©æ°”æŸ¥è¯¢å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•è·å–å¤©æ°”ä¿¡æ¯ã€‚"

    async def get_time_response(self) -> Optional[str]:
        """è·å–æ—¶é—´å›å¤"""
        try:
            import datetime
            now = datetime.datetime.now()

            # ç²¤è¯­æ—¶é—´è¡¨è¾¾
            hour = now.hour
            minute = now.minute

            if hour < 12:
                time_period = "ä¸Šåˆ"
            elif hour < 18:
                time_period = "ä¸‹åˆ"
            else:
                time_period = "æ™šä¸Š"

            response = f"ç°åœ¨ç³»{time_period}{hour:02d}ç‚¹{minute:02d}åˆ†"

            logger.info(f"â° æ—¶é—´æŸ¥è¯¢: {response}")
            return response

        except Exception as e:
            logger.error(f"âŒ æ—¶é—´æŸ¥è¯¢å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæ— æ³•è·å–å½“å‰æ—¶é—´ã€‚"

    async def handle_general_query(self, query: str) -> Optional[str]:
        """å¤„ç†ä¸€èˆ¬æŸ¥è¯¢"""
        try:
            # é€šç”¨é—®é¢˜å¤„ç†
            prompt = f"ç”¨æˆ·è¯¢é—®ï¼š{query}\nè¯·ç”¨ç²¤è¯­å‹å¥½ã€ç®€æ´åœ°å›ç­”ã€‚"

            response = await self.generate_response(
                prompt=prompt,
                max_tokens=300
            )

            if response:
                logger.info(f"ğŸ’¬ ä¸€èˆ¬æŸ¥è¯¢: {query[:30]}...")
                return response
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"

        except Exception as e:
            logger.error(f"âŒ ä¸€èˆ¬æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return "ç³»ç»Ÿé‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"

async def create_multimodal_llm(api_key: str = "", model: str = "qwen3-vl-plus") -> QwenMultimodalLLM:
    """åˆ›å»ºå¤šæ¨¡æ€LLMå®ä¾‹"""
    llm = QwenMultimodalLLM(api_key=api_key, model=model)
    if await llm.initialize():
        return llm
    else:
        raise RuntimeError("å¤šæ¨¡æ€LLMåˆå§‹åŒ–å¤±è´¥")