#!/usr/bin/env python3
"""
æµå¼è¯­éŸ³åˆæˆå™¨æœåŠ¡
==================

åŸºäºWebSocket TTSçš„é«˜çº§æµå¼åˆæˆæœåŠ¡ï¼Œæä¾›ï¼š
- æ–‡æœ¬åˆ†å—å’Œæµå¼å¤„ç†
- æ™ºèƒ½éŸ³é¢‘ç¼“å­˜
- è¾¹åˆæˆè¾¹æ’­æ”¾
- æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯æ¢å¤

ä½œè€…: Developer Agent
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2025-11-16
"""

import logging
import time
import asyncio
import threading
from typing import List, Dict, Any, Optional, Callable
from dataclasses import dataclass
from datetime import datetime

from ..engine.aliyun_tts_websocket import WebSocketTTSService, StreamingTTSResult, TTSResult

logger = logging.getLogger(__name__)

@dataclass
class StreamingRequest:
    """æµå¼åˆæˆè¯·æ±‚"""
    text: str
    voice: str = "xiaoyan"
    volume: int = 50
    rate: int = 0
    pitch: int = 0
    format: str = "pcm"
    sample_rate: int = 16000
    chunk_size: int = 100  # å­—ç¬¦åˆ†å—å¤§å°
    overlap_size: int = 20  # é‡å å­—ç¬¦æ•°
    callback: Optional[Callable] = None

@dataclass
class StreamingSession:
    """æµå¼åˆæˆä¼šè¯"""
    session_id: str
    request: StreamingRequest
    start_time: float
    chunks_processed: int = 0
    total_chunks: int = 0
    audio_chunks: List[bytes] = None
    is_completed: bool = False
    error: str = ""

    def __post_init__(self):
        if self.audio_chunks is None:
            self.audio_chunks = []

class StreamingSynthesizer:
    """æµå¼è¯­éŸ³åˆæˆå™¨"""

    def __init__(self, tts_service: WebSocketTTSService):
        """
        åˆå§‹åŒ–æµå¼åˆæˆå™¨

        Args:
            tts_service: WebSocket TTSæœåŠ¡å®ä¾‹
        """
        self.tts_service = tts_service
        self.active_sessions: Dict[str, StreamingSession] = {}
        self.session_counter = 0

        # æ€§èƒ½é…ç½®
        self.max_concurrent_sessions = 5
        self.default_chunk_size = 100
        self.default_overlap = 20

        logger.info("âœ… æµå¼è¯­éŸ³åˆæˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        self.session_counter += 1
        timestamp = int(time.time() * 1000)
        return f"stream_{timestamp}_{self.session_counter}"

    def _split_text_into_chunks(self, text: str, chunk_size: int, overlap: int) -> List[str]:
        """
        å°†æ–‡æœ¬åˆ†å‰²æˆé‡å çš„å—

        Args:
            text: åŸå§‹æ–‡æœ¬
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        if len(text) <= chunk_size:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunk = text[start:end]
            chunks.append(chunk)

            # è®¡ç®—ä¸‹ä¸€ä¸ªèµ·å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
            if end >= len(text):
                break
            start = end - overlap

        return chunks

    async def synthesize_streaming(self, request: StreamingRequest) -> StreamingSession:
        """
        å¼‚æ­¥æµå¼è¯­éŸ³åˆæˆ

        Args:
            request: æµå¼åˆæˆè¯·æ±‚

        Returns:
            StreamingSession: åˆæˆä¼šè¯
        """
        session_id = self._generate_session_id()
        session = StreamingSession(
            session_id=session_id,
            request=request,
            start_time=time.time()
        )

        # æ£€æŸ¥å¹¶å‘é™åˆ¶
        if len(self.active_sessions) >= self.max_concurrent_sessions:
            session.error = "è¾¾åˆ°æœ€å¤§å¹¶å‘ä¼šè¯é™åˆ¶"
            session.is_completed = True
            return session

        self.active_sessions[session_id] = session

        try:
            # åˆ†å‰²æ–‡æœ¬
            text_chunks = self._split_text_into_chunks(
                request.text,
                request.chunk_size or self.default_chunk_size,
                request.overlap_size or self.default_overlap
            )

            session.total_chunks = len(text_chunks)
            logger.info(f"ğŸŒŠ å¼€å§‹æµå¼åˆæˆ: {session_id}, æ€»å—æ•°: {len(text_chunks)}")

            # é€å—åˆæˆ
            for i, chunk in enumerate(text_chunks):
                if session.error:  # å¦‚æœæœ‰é”™è¯¯åˆ™åœæ­¢
                    break

                logger.debug(f"ğŸµ åˆæˆå— {i+1}/{len(text_chunks)}: '{chunk[:20]}...'")

                # è°ƒç”¨TTSæœåŠ¡
                result = self.tts_service.synthesize_streaming(
                    text=chunk,
                    voice=request.voice,
                    volume=request.volume,
                    rate=request.rate,
                    pitch=request.pitch,
                    format=request.format,
                    sample_rate=request.sample_rate
                )

                if result.success:
                    session.audio_chunks.extend(result.audio_chunks)
                    session.chunks_processed += 1

                    # è°ƒç”¨å›è°ƒå‡½æ•°
                    if request.callback:
                        try:
                            await request.callback(session, i, result)
                        except Exception as e:
                            logger.warning(f"âš ï¸ å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
                else:
                    session.error = result.error
                    logger.error(f"âŒ å— {i+1} åˆæˆå¤±è´¥: {result.error}")
                    break

            session.is_completed = True
            session_time = time.time() - session.start_time
            logger.info(f"âœ… æµå¼åˆæˆå®Œæˆ: {session_id}, è€—æ—¶: {session_time:.2f}s")

        except Exception as e:
            session.error = f"æµå¼åˆæˆå¼‚å¸¸: {e}"
            session.is_completed = True
            logger.error(f"âŒ æµå¼åˆæˆå¼‚å¸¸: {e}")

        finally:
            # æ¸…ç†ä¼šè¯
            if session_id in self.active_sessions:
                del self.active_sessions[session_id]

        return session

    def synthesize_streaming_sync(self, request: StreamingRequest) -> StreamingSession:
        """
        åŒæ­¥æµå¼è¯­éŸ³åˆæˆ

        Args:
            request: æµå¼åˆæˆè¯·æ±‚

        Returns:
            StreamingSession: åˆæˆä¼šè¯
        """
        # è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(self.synthesize_streaming(request))
        finally:
            loop.close()

    def get_session_status(self, session_id: str) -> Optional[StreamingSession]:
        """
        è·å–ä¼šè¯çŠ¶æ€

        Args:
            session_id: ä¼šè¯ID

        Returns:
            StreamingSessionæˆ–None
        """
        return self.active_sessions.get(session_id)

    def cancel_session(self, session_id: str) -> bool:
        """
        å–æ¶ˆä¼šè¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            session.error = "ç”¨æˆ·å–æ¶ˆ"
            session.is_completed = True
            del self.active_sessions[session_id]
            logger.info(f"ğŸ›‘ ä¼šè¯å·²å–æ¶ˆ: {session_id}")
            return True
        return False

    def get_active_sessions_count(self) -> int:
        """è·å–æ´»è·ƒä¼šè¯æ•°é‡"""
        return len(self.active_sessions)

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return {
            "active_sessions": len(self.active_sessions),
            "max_concurrent_sessions": self.max_concurrent_sessions,
            "total_sessions_created": self.session_counter,
            "default_chunk_size": self.default_chunk_size,
            "default_overlap": self.default_overlap
        }

class TextChunker:
    """æ–‡æœ¬åˆ†å—å™¨"""

    @staticmethod
    def chunk_by_sentences(text: str, max_chunk_length: int = 200) -> List[str]:
        """
        æŒ‰å¥å­åˆ†å—

        Args:
            text: æ–‡æœ¬
            max_chunk_length: æœ€å¤§å—é•¿åº¦

        Returns:
            å¥å­å—åˆ—è¡¨
        """
        import re

        # ä¸­æ–‡å¥å­åˆ†éš”ç¬¦
        sentence_endings = r'[ã€‚ï¼ï¼Ÿï¼›â€¦]'
        sentences = re.split(sentence_endings, text)

        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if not sentence.strip():
                continue

            # å¦‚æœåŠ ä¸Šè¿™ä¸ªå¥å­ä¼šè¶…è¿‡é•¿åº¦é™åˆ¶
            if len(current_chunk + sentence) > max_chunk_length and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += sentence + "ã€‚"

        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        return chunks

    @staticmethod
    def chunk_by_punctuation(text: str, max_chunk_length: int = 150) -> List[str]:
        """
        æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å—

        Args:
            text: æ–‡æœ¬
            max_chunk_length: æœ€å¤§å—é•¿åº¦

        Returns:
            æ ‡ç‚¹å—åˆ—è¡¨
        """
        import re

        # æ ‡ç‚¹ç¬¦å·
        punctuation = r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€¦â€”]'
        segments = re.split(punctuation, text)

        chunks = []
        current_chunk = ""

        for segment in segments:
            if not segment.strip():
                continue

            if len(current_chunk + segment) > max_chunk_length and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = segment
            else:
                current_chunk += segment + "ï¼Œ"

        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        return chunks

    @staticmethod
    def chunk_smart(text: str, target_length: int = 100) -> List[str]:
        """
        æ™ºèƒ½åˆ†å—ï¼ˆä¼˜å…ˆæŒ‰å¥å­ï¼Œå…¶æ¬¡æŒ‰é•¿åº¦ï¼‰

        Args:
            text: æ–‡æœ¬
            target_length: ç›®æ ‡é•¿åº¦

        Returns:
            æ™ºèƒ½å—åˆ—è¡¨
        """
        # é¦–å…ˆå°è¯•æŒ‰å¥å­åˆ†å—
        sentence_chunks = TextChunker.chunk_by_sentences(text, target_length * 2)

        # å¦‚æœå¥å­å—å¤ªå¤§ï¼Œè¿›ä¸€æ­¥åˆ†å‰²
        final_chunks = []
        for chunk in sentence_chunks:
            if len(chunk) <= target_length:
                final_chunks.append(chunk)
            else:
                # æŒ‰é•¿åº¦åˆ†å‰²
                length_chunks = TextChunker.chunk_by_length(chunk, target_length, 10)
                final_chunks.extend(length_chunks)

        return final_chunks

    @staticmethod
    def chunk_by_length(text: str, chunk_size: int, overlap: int = 10) -> List[str]:
        """
        æŒ‰é•¿åº¦åˆ†å—

        Args:
            text: æ–‡æœ¬
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            é•¿åº¦å—åˆ—è¡¨
        """
        if len(text) <= chunk_size:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            end = min(start + chunk_size, len(text))
            chunk = text[start:end]
            chunks.append(chunk)

            if end >= len(text):
                break
            start = end - overlap

        return chunks

def create_streaming_synthesizer(tts_service: WebSocketTTSService) -> StreamingSynthesizer:
    """åˆ›å»ºæµå¼åˆæˆå™¨å®ä¾‹"""
    return StreamingSynthesizer(tts_service)