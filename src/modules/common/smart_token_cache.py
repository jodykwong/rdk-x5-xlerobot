#!/usr/bin/env python3.10
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½Tokenç¼“å­˜ç­–ç•¥ç®¡ç†å™¨ - Smart Token Cache Strategy Manager
BMad-Method v6 Brownfield Level 4 ä¼ä¸šçº§å®ç°

åŠŸèƒ½æè¿°:
- æ™ºèƒ½Tokenç¼“å­˜å’Œé¢„æµ‹æ€§åˆ·æ–°
- å¤šå±‚ç¼“å­˜ç­–ç•¥ï¼ˆå†…å­˜+ç£ç›˜+åˆ†å¸ƒå¼ï¼‰
- è‡ªé€‚åº”åˆ·æ–°ç®—æ³•
- Tokenä½¿ç”¨ç‡åˆ†æå’Œä¼˜åŒ–
- å¹¶å‘å®‰å…¨å’Œæ•…éšœæ¢å¤
- æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡

ç®—æ³•ç‰¹æ€§:
- é¢„æµ‹æ€§Tokenåˆ·æ–°ï¼ˆåœ¨ä½¿ç”¨å‰åˆ·æ–°ï¼‰
- åŸºäºä½¿ç”¨é¢‘ç‡çš„ç¼“å­˜ä¼˜å…ˆçº§
- æ™ºèƒ½å¤±è´¥æ¢å¤å’Œé‡è¯•æœºåˆ¶
- å¤šAPIå¯†é’¥è´Ÿè½½å‡è¡¡
- Tokenæ± ç®¡ç†å’Œå¤ç”¨

ä½œè€…: Claude Code
Epic: 1 - Tokenç¼“å­˜ç­–ç•¥ä¼˜åŒ–
åˆ›å»ºæ—¥æœŸ: 2025-11-19
"""

import os
import sys
import json
import time
import threading
import hashlib
import pickle
import sqlite3
import logging
from typing import Dict, List, Optional, Any, Callable, Tuple, Union
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue, Empty
import weakref
from pathlib import Path
import asyncio
from contextlib import contextmanager

# å°è¯•å¯¼å…¥é˜¿é‡Œäº‘SDK
try:
    from aliyunsdkcore.client import AcsClient
    from aliyunsdkcore.request import CommonRequest
    HAS_ALIYUN_SDK = True
except ImportError:
    HAS_ALIYUN_SDK = False

try:
    from nls.token import getToken as get_nls_token
    HAS_NLS_SDK = True
except ImportError:
    HAS_NLS_SDK = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TokenStatus(Enum):
    """TokençŠ¶æ€"""
    FRESH = "fresh"                 # æ–°Token
    ACTIVE = "active"              # æ´»è·ƒToken
    EXPIRING = "expiring"          # å³å°†è¿‡æœŸ
    EXPIRED = "expired"            # å·²è¿‡æœŸ
    ERROR = "error"                # é”™è¯¯Token


class CacheLevel(Enum):
    """ç¼“å­˜çº§åˆ«"""
    MEMORY = "memory"              # å†…å­˜ç¼“å­˜
    DISK = "disk"                  # ç£ç›˜ç¼“å­˜
    DISTRIBUTED = "distributed"    # åˆ†å¸ƒå¼ç¼“å­˜ï¼ˆæœªæ¥æ‰©å±•ï¼‰


@dataclass
class TokenMetrics:
    """TokenæŒ‡æ ‡"""
    request_count: int = 0          # è¯·æ±‚æ¬¡æ•°
    success_count: int = 0          # æˆåŠŸæ¬¡æ•°
    error_count: int = 0            # é”™è¯¯æ¬¡æ•°
    cache_hits: int = 0             # ç¼“å­˜å‘½ä¸­
    cache_misses: int = 0           # ç¼“å­˜æœªå‘½ä¸­
    avg_response_time: float = 0.0  # å¹³å‡å“åº”æ—¶é—´
    last_used: float = field(default_factory=time.time)
    creation_time: float = field(default_factory=time.time)
    priority_score: float = 1.0     # ä¼˜å…ˆçº§åˆ†æ•°

    def update_usage(self, success: bool, response_time: float = 0.0):
        """æ›´æ–°ä½¿ç”¨ç»Ÿè®¡"""
        self.request_count += 1
        self.last_used = time.time()

        if success:
            self.success_count += 1
        else:
            self.error_count += 1

        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        if response_time > 0:
            total_time = self.avg_response_time * (self.request_count - 1) + response_time
            self.avg_response_time = total_time / self.request_count

    def calculate_priority(self) -> float:
        """è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°"""
        now = time.time()
        age = now - self.creation_time
        recency = now - self.last_used

        # åŸºäºå¤šä¸ªå› ç´ è®¡ç®—ä¼˜å…ˆçº§
        usage_factor = min(self.request_count / 100.0, 1.0)  # ä½¿ç”¨é¢‘ç‡
        success_factor = self.success_count / max(self.request_count, 1)  # æˆåŠŸç‡
        recency_factor = max(0, 1 - recency / 3600.0)  # æœ€è¿‘ä½¿ç”¨
        age_factor = max(0, 1 - age / 86400.0)  # å¹´é¾„å› ç´ 

        self.priority_score = (
            usage_factor * 0.4 +
            success_factor * 0.3 +
            recency_factor * 0.2 +
            age_factor * 0.1
        )

        return self.priority_score


@dataclass
class TokenInfo:
    """Tokenä¿¡æ¯"""
    token: str
    access_key_id: str
    app_key: str
    expire_time: int
    creation_time: float = field(default_factory=time.time)
    last_refresh: float = field(default_factory=time.time)
    refresh_count: int = 0
    status: TokenStatus = TokenStatus.FRESH
    metrics: TokenMetrics = field(default_factory=TokenMetrics)

    @property
    def expires_in(self) -> float:
        """Tokenå‰©ä½™æœ‰æ•ˆæ—¶é—´ï¼ˆç§’ï¼‰"""
        return max(0, self.expire_time - time.time())

    @property
    def is_expired(self) -> bool:
        """æ˜¯å¦å·²è¿‡æœŸ"""
        return self.expires_in <= 0

    @property
    def is_expiring_soon(self, buffer_seconds: int = 300) -> bool:
        """æ˜¯å¦å³å°†è¿‡æœŸ"""
        return self.expires_in <= buffer_seconds

    def update_status(self):
        """æ›´æ–°TokençŠ¶æ€"""
        if self.is_expired:
            self.status = TokenStatus.EXPIRED
        elif self.is_expiring_soon():
            self.status = TokenStatus.EXPIRING
        else:
            self.status = TokenStatus.ACTIVE


@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    memory_cache_size: int = 100          # å†…å­˜ç¼“å­˜å¤§å°
    disk_cache_size: int = 1000           # ç£ç›˜ç¼“å­˜å¤§å°
    refresh_threshold: float = 0.8        # åˆ·æ–°é˜ˆå€¼ï¼ˆ80%æ—¶é—´ååˆ·æ–°ï¼‰
    predictive_refresh: bool = True        # é¢„æµ‹æ€§åˆ·æ–°
    max_concurrent_requests: int = 5      # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    retry_attempts: int = 3               # é‡è¯•æ¬¡æ•°
    retry_delay: float = 1.0              # é‡è¯•å»¶è¿Ÿ
    cleanup_interval: float = 300.0       # æ¸…ç†é—´éš”ï¼ˆ5åˆ†é’Ÿï¼‰
    db_path: str = "token_cache.db"       # æ•°æ®åº“è·¯å¾„


class SmartTokenCache:
    """
    æ™ºèƒ½Tokenç¼“å­˜ç®¡ç†å™¨

    ä¼ä¸šçº§Tokenç¼“å­˜å®ç°ï¼Œæ”¯æŒï¼š
    - å¤šå±‚ç¼“å­˜ç­–ç•¥
    - é¢„æµ‹æ€§åˆ·æ–°
    - æ™ºèƒ½è°ƒåº¦ç®—æ³•
    - å¹¶å‘å®‰å…¨
    - æ€§èƒ½ç›‘æ§
    """

    _instance = None
    _lock = threading.Lock()

    def __new__(cls, config: Optional[CacheConfig] = None):
        """å•ä¾‹æ¨¡å¼"""
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
            return cls._instance

    def __init__(self, config: Optional[CacheConfig] = None):
        """åˆå§‹åŒ–æ™ºèƒ½Tokenç¼“å­˜"""
        # é¿å…é‡å¤åˆå§‹åŒ–
        if hasattr(self, '_initialized'):
            return

        self.config = config or CacheConfig()
        self.memory_cache: Dict[str, TokenInfo] = {}  # å†…å­˜ç¼“å­˜
        self.lock = threading.RLock()
        self.executor = ThreadPoolExecutor(max_workers=self.config.max_concurrent_requests)
        self.cleanup_thread = None
        self.shutdown_event = threading.Event()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'token_refreshes': 0,
            'refresh_failures': 0,
            'memory_tokens': 0,
            'disk_tokens': 0
        }

        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()

        # å¯åŠ¨æ¸…ç†ä»»åŠ¡
        self._start_cleanup_thread()

        self._initialized = True
        logger.info("âœ… æ™ºèƒ½Tokenç¼“å­˜åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  - å†…å­˜ç¼“å­˜å¤§å°: {self.config.memory_cache_size}")
        logger.info(f"  - ç£ç›˜ç¼“å­˜å¤§å°: {self.config.disk_cache_size}")
        logger.info(f"  - é¢„æµ‹æ€§åˆ·æ–°: {self.config.predictive_refresh}")

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            db_path = Path(self.config.db_path)
            if not db_path.parent.exists():
                db_path.parent.mkdir(parents=True, exist_ok=True)

            with sqlite3.connect(self.config.db_path) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS tokens (
                        cache_key TEXT PRIMARY KEY,
                        token TEXT NOT NULL,
                        access_key_id TEXT NOT NULL,
                        app_key TEXT NOT NULL,
                        expire_time INTEGER NOT NULL,
                        creation_time REAL NOT NULL,
                        last_refresh REAL NOT NULL,
                        refresh_count INTEGER DEFAULT 0,
                        status TEXT NOT NULL,
                        metrics_data TEXT NOT NULL
                    )
                ''')

                # åˆ›å»ºç´¢å¼•
                conn.execute('CREATE INDEX IF NOT EXISTS idx_expire_time ON tokens(expire_time)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_last_used ON tokens(last_refresh)')

            logger.debug(f"âœ… Tokenç¼“å­˜æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.config.db_path}")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

    def _generate_cache_key(self, access_key_id: str, app_key: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = f"{access_key_id}:{app_key}"
        return hashlib.sha256(key_data.encode()).hexdigest()

    def get_token(self, access_key_id: str, access_key_secret: str, app_key: str) -> Optional[str]:
        """
        è·å–Tokenï¼ˆæ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼‰

        Args:
            access_key_id: é˜¿é‡Œäº‘AccessKey ID
            access_key_secret: é˜¿é‡Œäº‘AccessKey Secret
            app_key: NLSåº”ç”¨Key

        Returns:
            Tokenå­—ç¬¦ä¸²æˆ–None
        """
        cache_key = self._generate_cache_key(access_key_id, app_key)
        self.stats['total_requests'] += 1

        start_time = time.time()

        try:
            # 1. å°è¯•ä»å†…å­˜ç¼“å­˜è·å–
            token_info = self._get_from_memory(cache_key)
            if token_info and not token_info.is_expired:
                if self.config.predictive_refresh and token_info.is_expiring_soon():
                    # å¼‚æ­¥åˆ·æ–°Token
                    self._async_refresh_token(access_key_id, access_key_secret, app_key, cache_key)

                token_info.metrics.update_usage(True, time.time() - start_time)
                self.stats['cache_hits'] += 1
                return token_info.token

            # 2. å°è¯•ä»ç£ç›˜ç¼“å­˜è·å–
            token_info = self._get_from_disk(cache_key)
            if token_info and not token_info.is_expired:
                # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
                self._store_in_memory(cache_key, token_info)

                if self.config.predictive_refresh and token_info.is_expiring_soon():
                    # å¼‚æ­¥åˆ·æ–°Token
                    self._async_refresh_token(access_key_id, access_key_secret, app_key, cache_key)

                token_info.metrics.update_usage(True, time.time() - start_time)
                self.stats['cache_hits'] += 1
                return token_info.token

            # 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œè·å–æ–°Token
            self.stats['cache_misses'] += 1
            new_token_info = self._fetch_new_token(access_key_id, access_key_secret, app_key)

            if new_token_info:
                # å­˜å‚¨åˆ°ç¼“å­˜
                self._store_token(cache_key, new_token_info)
                new_token_info.metrics.update_usage(True, time.time() - start_time)
                return new_token_info.token

            return None

        except Exception as e:
            logger.error(f"âŒ è·å–Tokenå¤±è´¥: {e}")
            return None

    def _get_from_memory(self, cache_key: str) -> Optional[TokenInfo]:
        """ä»å†…å­˜ç¼“å­˜è·å–Token"""
        with self.lock:
            return self.memory_cache.get(cache_key)

    def _get_from_disk(self, cache_key: str) -> Optional[TokenInfo]:
        """ä»ç£ç›˜ç¼“å­˜è·å–Token"""
        try:
            with sqlite3.connect(self.config.db_path) as conn:
                cursor = conn.execute(
                    'SELECT token, access_key_id, app_key, expire_time, creation_time, '
                    'last_refresh, refresh_count, status, metrics_data FROM tokens WHERE cache_key = ?',
                    (cache_key,)
                )
                row = cursor.fetchone()

                if row:
                    metrics_data = json.loads(row[8])
                    metrics = TokenMetrics(**metrics_data)

                    token_info = TokenInfo(
                        token=row[0],
                        access_key_id=row[1],
                        app_key=row[2],
                        expire_time=row[3],
                        creation_time=row[4],
                        last_refresh=row[5],
                        refresh_count=row[6],
                        status=TokenStatus(row[7]),
                        metrics=metrics
                    )

                    token_info.update_status()
                    return token_info

        except Exception as e:
            logger.error(f"âŒ ç£ç›˜ç¼“å­˜è¯»å–å¤±è´¥: {e}")

        return None

    def _fetch_new_token(self, access_key_id: str, access_key_secret: str, app_key: str) -> Optional[TokenInfo]:
        """è·å–æ–°Token"""
        try:
            # ä¼˜å…ˆä½¿ç”¨NLS SDK
            if HAS_NLS_SDK:
                token = get_nls_token(access_key_id, access_key_secret)
                if token:
                    expire_time = int(time.time() + 23.5 * 3600)  # 23.5å°æ—¶åè¿‡æœŸ
                    return TokenInfo(
                        token=token,
                        access_key_id=access_key_id,
                        app_key=app_key,
                        expire_time=expire_time
                    )

            # å¤‡é€‰ï¼šä½¿ç”¨é˜¿é‡Œäº‘SDK
            elif HAS_ALIYUN_SDK:
                return self._fetch_token_with_aliyun_sdk(access_key_id, access_key_secret, app_key)

            else:
                logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„Tokenè·å–æ–¹å¼")
                return None

        except Exception as e:
            logger.error(f"âŒ è·å–æ–°Tokenå¤±è´¥: {e}")
            self.stats['refresh_failures'] += 1
            return None

    def _fetch_token_with_aliyun_sdk(self, access_key_id: str, access_key_secret: str, app_key: str) -> Optional[TokenInfo]:
        """ä½¿ç”¨é˜¿é‡Œäº‘SDKè·å–Token"""
        try:
            client = AcsClient(access_key_id, access_key_secret, "cn-shanghai")
            request = CommonRequest()
            request.set_accept_format('json')
            request.set_domain('nls-meta.cn-shanghai.aliyuncs.com')
            request.set_method('POST')
            request.set_version('2019-02-28')
            request.set_action_name('CreateToken')

            response = client.do_action_with_exception(request)
            result = json.loads(response)

            if 'Token' in result:
                token_info = TokenInfo(
                    token=result['Token']['Id'],
                    access_key_id=access_key_id,
                    app_key=app_key,
                    expire_time=result['Token']['ExpireTime'] // 1000
                )
                return token_info
            else:
                logger.error(f"âŒ Tokenå“åº”æ ¼å¼é”™è¯¯: {result}")
                return None

        except Exception as e:
            logger.error(f"âŒ é˜¿é‡Œäº‘SDKè·å–Tokenå¤±è´¥: {e}")
            return None

    def _store_token(self, cache_key: str, token_info: TokenInfo):
        """å­˜å‚¨Tokenåˆ°ç¼“å­˜"""
        try:
            # å­˜å‚¨åˆ°å†…å­˜ç¼“å­˜
            self._store_in_memory(cache_key, token_info)

            # å­˜å‚¨åˆ°ç£ç›˜ç¼“å­˜
            self._store_in_disk(cache_key, token_info)

            # æ›´æ–°ç»Ÿè®¡
            self.stats['memory_tokens'] = len(self.memory_cache)
            self.stats['token_refreshes'] += 1

            logger.debug(f"âœ… Tokenå·²ç¼“å­˜: {cache_key}")

        except Exception as e:
            logger.error(f"âŒ Tokenç¼“å­˜å­˜å‚¨å¤±è´¥: {e}")

    def _store_in_memory(self, cache_key: str, token_info: TokenInfo):
        """å­˜å‚¨åˆ°å†…å­˜ç¼“å­˜"""
        with self.lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            if len(self.memory_cache) >= self.config.memory_cache_size:
                self._evict_least_useful()

            self.memory_cache[cache_key] = token_info

    def _store_in_disk(self, cache_key: str, token_info: TokenInfo):
        """å­˜å‚¨åˆ°ç£ç›˜ç¼“å­˜"""
        try:
            with sqlite3.connect(self.config.db_path) as conn:
                conn.execute('''
                    INSERT OR REPLACE INTO tokens (
                        cache_key, token, access_key_id, app_key, expire_time,
                        creation_time, last_refresh, refresh_count, status, metrics_data
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    cache_key,
                    token_info.token,
                    token_info.access_key_id,
                    token_info.app_key,
                    token_info.expire_time,
                    token_info.creation_time,
                    token_info.last_refresh,
                    token_info.refresh_count,
                    token_info.status.value,
                    json.dumps(asdict(token_info.metrics))
                ))

        except Exception as e:
            logger.error(f"âŒ ç£ç›˜ç¼“å­˜å­˜å‚¨å¤±è´¥: {e}")

    def _evict_least_useful(self):
        """é©±é€æœ€ä¸æœ‰ç”¨çš„Token"""
        if not self.memory_cache:
            return

        # è®¡ç®—æ¯ä¸ªTokençš„ä¼˜å…ˆçº§
        token_priorities = []
        for cache_key, token_info in self.memory_cache.items():
            priority = token_info.metrics.calculate_priority()
            token_priorities.append((cache_key, priority))

        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œç§»é™¤æœ€ä½ä¼˜å…ˆçº§çš„Token
        token_priorities.sort(key=lambda x: x[1])
        evict_count = max(1, len(self.memory_cache) // 4)  # ç§»é™¤25%çš„Token

        for cache_key, _ in token_priorities[:evict_count]:
            del self.memory_cache[cache_key]
            logger.debug(f"ğŸ—‘ï¸ é©±é€Token: {cache_key}")

    def _async_refresh_token(self, access_key_id: str, access_key_secret: str, app_key: str, cache_key: str):
        """å¼‚æ­¥åˆ·æ–°Token"""
        if not self.config.predictive_refresh:
            return

        # æäº¤å¼‚æ­¥ä»»åŠ¡
        future = self.executor.submit(self._refresh_token, access_key_id, access_key_secret, app_key, cache_key)

        # ä½¿ç”¨å›è°ƒå¤„ç†ç»“æœï¼ˆå¯é€‰ï¼‰
        def handle_result(fut):
            try:
                result = fut.result()
                if result:
                    logger.debug(f"ğŸ”„ é¢„æµ‹æ€§Tokenåˆ·æ–°æˆåŠŸ: {cache_key}")
                else:
                    logger.warning(f"âš ï¸ é¢„æµ‹æ€§Tokenåˆ·æ–°å¤±è´¥: {cache_key}")
            except Exception as e:
                logger.error(f"âŒ é¢„æµ‹æ€§Tokenåˆ·æ–°å¼‚å¸¸: {e}")

        future.add_done_callback(handle_result)

    def _refresh_token(self, access_key_id: str, access_key_secret: str, app_key: str, cache_key: str) -> bool:
        """åˆ·æ–°Token"""
        try:
            new_token_info = self._fetch_new_token(access_key_id, access_key_secret, app_key)
            if new_token_info:
                # æ›´æ–°åˆ·æ–°è®¡æ•°
                existing_token = self._get_from_memory(cache_key) or self._get_from_disk(cache_key)
                if existing_token:
                    new_token_info.refresh_count = existing_token.refresh_count + 1
                    new_token_info.metrics = existing_token.metrics

                self._store_token(cache_key, new_token_info)
                return True
            return False

        except Exception as e:
            logger.error(f"âŒ Tokenåˆ·æ–°å¤±è´¥: {e}")
            return False

    def _start_cleanup_thread(self):
        """å¯åŠ¨æ¸…ç†çº¿ç¨‹"""
        if not self.cleanup_thread or not self.cleanup_thread.is_alive():
            self.cleanup_thread = threading.Thread(
                target=self._cleanup_worker,
                name="token-cache-cleanup",
                daemon=True
            )
            self.cleanup_thread.start()
            logger.debug("ğŸ§¹ Tokenç¼“å­˜æ¸…ç†çº¿ç¨‹å·²å¯åŠ¨")

    def _cleanup_worker(self):
        """æ¸…ç†å·¥ä½œçº¿ç¨‹"""
        while not self.shutdown_event.is_set():
            try:
                self._perform_cleanup()
                self.shutdown_event.wait(self.config.cleanup_interval)
            except Exception as e:
                logger.error(f"âŒ æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
                self.shutdown_event.wait(10.0)

    def _perform_cleanup(self):
        """æ‰§è¡Œæ¸…ç†"""
        try:
            # æ¸…ç†å†…å­˜ç¼“å­˜
            self._cleanup_memory_cache()

            # æ¸…ç†ç£ç›˜ç¼“å­˜
            self._cleanup_disk_cache()

            # æ›´æ–°ç»Ÿè®¡
            self.stats['memory_tokens'] = len(self.memory_cache)

            logger.debug("ğŸ§¹ Tokenç¼“å­˜æ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

    def _cleanup_memory_cache(self):
        """æ¸…ç†å†…å­˜ç¼“å­˜"""
        with self.lock:
            expired_keys = []
            for cache_key, token_info in self.memory_cache.items():
                if token_info.is_expired:
                    expired_keys.append(cache_key)

            for key in expired_keys:
                del self.memory_cache[key]
                logger.debug(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸToken: {key}")

    def _cleanup_disk_cache(self):
        """æ¸…ç†ç£ç›˜ç¼“å­˜"""
        try:
            current_time = time.time()
            cutoff_time = current_time - 86400  # 24å°æ—¶å‰

            with sqlite3.connect(self.config.db_path) as conn:
                cursor = conn.execute(
                    'DELETE FROM tokens WHERE expire_time < ?',
                    (cutoff_time,)
                )
                deleted_count = cursor.rowcount

                if deleted_count > 0:
                    logger.debug(f"ğŸ—‘ï¸ æ¸…ç†ç£ç›˜è¿‡æœŸToken: {deleted_count}ä¸ª")

        except Exception as e:
            logger.error(f"âŒ ç£ç›˜ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            hit_rate = 0.0
            if self.stats['total_requests'] > 0:
                hit_rate = self.stats['cache_hits'] / self.stats['total_requests'] * 100

            return {
                'total_requests': self.stats['total_requests'],
                'cache_hits': self.stats['cache_hits'],
                'cache_misses': self.stats['cache_misses'],
                'hit_rate_percent': round(hit_rate, 2),
                'token_refreshes': self.stats['token_refreshes'],
                'refresh_failures': self.stats['refresh_failures'],
                'memory_tokens': len(self.memory_cache),
                'config': asdict(self.config)
            }

    def get_token_details(self) -> List[Dict[str, Any]]:
        """è·å–Tokenè¯¦ç»†ä¿¡æ¯"""
        details = []

        with self.lock:
            for cache_key, token_info in self.memory_cache.items():
                details.append({
                    'cache_key': cache_key,
                    'access_key_id': token_info.access_key_id,
                    'app_key': token_info.app_key,
                    'status': token_info.status.value,
                    'expires_in': token_info.expires_in,
                    'refresh_count': token_info.refresh_count,
                    'priority_score': token_info.metrics.calculate_priority(),
                    'request_count': token_info.metrics.request_count,
                    'success_rate': (token_info.metrics.success_count /
                                   max(token_info.metrics.request_count, 1)) * 100
                })

        return details

    def preload_tokens(self, credentials_list: List[Tuple[str, str, str]]):
        """é¢„åŠ è½½Tokens"""
        logger.info(f"ğŸš€ é¢„åŠ è½½ {len(credentials_list)} ä¸ªTokens...")

        futures = []
        for access_key_id, access_key_secret, app_key in credentials_list:
            future = self.executor.submit(
                self.get_token, access_key_id, access_key_secret, app_key
            )
            futures.append(future)

        # ç­‰å¾…å®Œæˆ
        success_count = 0
        for future in as_completed(futures):
            try:
                if future.result():
                    success_count += 1
            except Exception as e:
                logger.error(f"âŒ Tokené¢„åŠ è½½å¤±è´¥: {e}")

        logger.info(f"âœ… Tokené¢„åŠ è½½å®Œæˆ: {success_count}/{len(credentials_list)} æˆåŠŸ")

    def shutdown(self):
        """å…³é—­ç¼“å­˜ç®¡ç†å™¨"""
        logger.info("ğŸ›‘ å…³é—­æ™ºèƒ½Tokenç¼“å­˜...")

        self.shutdown_event.set()

        # ç­‰å¾…æ¸…ç†çº¿ç¨‹ç»“æŸ
        if self.cleanup_thread and self.cleanup_thread.is_alive():
            self.cleanup_thread.join(timeout=5.0)

        # å…³é—­çº¿ç¨‹æ± 
        self.executor.shutdown(wait=True)

        logger.info("âœ… æ™ºèƒ½Tokenç¼“å­˜å·²å…³é—­")


# å…¨å±€å®ä¾‹
_smart_cache = None
_cache_lock = threading.Lock()


def get_smart_token_cache(config: Optional[CacheConfig] = None) -> SmartTokenCache:
    """è·å–å…¨å±€æ™ºèƒ½Tokenç¼“å­˜å®ä¾‹"""
    global _smart_cache

    with _cache_lock:
        if _smart_cache is None:
            _smart_cache = SmartTokenCache(config)
        return _smart_cache


def get_token(access_key_id: str, access_key_secret: str, app_key: str) -> Optional[str]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–Token"""
    cache = get_smart_token_cache()
    return cache.get_token(access_key_id, access_key_secret, app_key)


# æµ‹è¯•å’ŒéªŒè¯å‡½æ•°
def test_smart_token_cache():
    """æµ‹è¯•æ™ºèƒ½Tokenç¼“å­˜åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•æ™ºèƒ½Tokenç¼“å­˜åŠŸèƒ½")

    try:
        # åˆ›å»ºé…ç½®
        config = CacheConfig(
            memory_cache_size=10,
            predictive_refresh=True,
            cleanup_interval=30.0
        )

        # åˆ›å»ºç¼“å­˜å®ä¾‹
        cache = SmartTokenCache(config)

        # æ¨¡æ‹Ÿè·å–Tokenï¼ˆéœ€è¦çœŸå®å‡­è¯ï¼‰
        access_key_id = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_ID', '')
        access_key_secret = os.getenv('ALIBABA_CLOUD_ACCESS_KEY_SECRET', '')
        app_key = os.getenv('ALIYUN_NLS_APPKEY', '')

        if not all([access_key_id, access_key_secret, app_key]):
            logger.warning("âš ï¸ ç¼ºå°‘ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡Tokenè·å–æµ‹è¯•")
        else:
            # æµ‹è¯•Tokenè·å–
            token = cache.get_token(access_key_id, access_key_secret, app_key)
            if token:
                logger.info(f"âœ… Tokenè·å–æˆåŠŸ: {token[:20]}...")
            else:
                logger.error("âŒ Tokenè·å–å¤±è´¥")

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = cache.get_stats()
        logger.info(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: {stats}")

        # æ¸…ç†
        cache.shutdown()

        logger.info("ğŸ‰ æ™ºèƒ½Tokenç¼“å­˜æµ‹è¯•å®Œæˆ")
        return True

    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½Tokenç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_smart_token_cache()