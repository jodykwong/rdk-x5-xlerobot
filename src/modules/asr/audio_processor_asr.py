#!/usr/bin/env python3
"""
ASRéŸ³é¢‘å¤„ç†æ¨¡å—

ä¸“é—¨ä¸ºè¯­éŸ³è¯†åˆ«ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†ï¼š
- éŸ³é¢‘æ•°æ®æ ¼å¼è½¬æ¢
- éŸ³é¢‘è´¨é‡ä¼˜åŒ–
- è¯­éŸ³æ®µæ£€æµ‹å’Œåˆ†å‰²
- æ‰¹é‡éŸ³é¢‘å¤„ç†

ä½œè€…: Dev Agent
æ—¥æœŸ: 2025-11-08
Epic: 1 - ASRè¯­éŸ³è¯†åˆ«æ¨¡å—
Story: 1.1 - ç²¤è¯­è¯­éŸ³è¯†åˆ«åŸºç¡€åŠŸèƒ½
Phase: 3 - åŸºç¡€è¯­éŸ³è¯†åˆ«
Task: 3.2 - å®ç°éŸ³é¢‘æ•°æ®æ ¼å¼è½¬æ¢å’Œæ‰“åŒ…
"""

import numpy as np
import logging
import wave
import io
import base64
from typing import List, Optional, Tuple, Dict, Any
from dataclasses import dataclass
import soundfile as sf
import threading
from queue import Queue, Empty
import time

try:
    import librosa
except ImportError:
    librosa = None
    logging.warning("librosa not available, using fallback resampling methods")

logger = logging.getLogger(__name__)


@dataclass
class AudioSegment:
    """éŸ³é¢‘æ®µä¿¡æ¯"""
    data: np.ndarray
    sample_rate: int
    start_time: float
    end_time: float
    energy: float
    is_speech: bool
    confidence: float


@dataclass
class ASRAudioConfig:
    """ASRéŸ³é¢‘é…ç½®"""
    target_sample_rate: int = 16000
    target_channels: int = 1  # å•å£°é“
    target_format: str = "pcm"  # pcm, wav
    target_bit_depth: int = 16  # 16-bit
    max_segment_duration: float = 30.0  # æœ€å¤§ç‰‡æ®µæ—¶é•¿(ç§’)
    min_segment_duration: float = 1.0   # æœ€å°ç‰‡æ®µæ—¶é•¿(ç§’)
    vad_threshold: float = 0.3  # VADé˜ˆå€¼
    enable_silence_removal: bool = True  # ç§»é™¤é™éŸ³
    max_silence_duration: float = 1.0  # æœ€å¤§é™éŸ³æ—¶é•¿(ç§’)


class ASRAudioProcessor:
    """
    ASRéŸ³é¢‘å¤„ç†å™¨

    ä¸“é—¨ä¸ºè¯­éŸ³è¯†åˆ«ä¼˜åŒ–çš„éŸ³é¢‘å¤„ç†æ¨¡å—
    """

    def __init__(self, config: Optional[ASRAudioConfig] = None):
        """
        åˆå§‹åŒ–ASRéŸ³é¢‘å¤„ç†å™¨

        Args:
            config: éŸ³é¢‘é…ç½®
        """
        self.config = config or ASRAudioConfig()

        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = Queue(maxsize=1000)
        self.processed_segments = Queue(maxsize=100)

        # å¤„ç†çŠ¶æ€
        self.is_processing = False
        self.total_samples_processed = 0
        self.total_duration_processed = 0.0

        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.Lock()

        logger.info(f"ASRAudioProcessor åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  ç›®æ ‡é‡‡æ ·ç‡: {self.config.target_sample_rate}Hz")
        logger.info(f"  ç›®æ ‡æ ¼å¼: {self.config.target_format}")
        logger.info(f"  æœ€å¤§ç‰‡æ®µæ—¶é•¿: {self.config.max_segment_duration}s")

    def convert_audio_format(self,
                             audio_data,
                             source_sample_rate: int,
                             source_channels: int = 1,
                             source_bit_depth: int = 16) -> bytes:
        """
        è½¬æ¢éŸ³é¢‘æ ¼å¼åˆ°ASRè¦æ±‚çš„æ ¼å¼

        Args:
            audio_data: åŸå§‹éŸ³é¢‘æ•°æ® (numpy.ndarray æˆ– bytes)
            source_sample_rate: åŸå§‹é‡‡æ ·ç‡
            source_channels: åŸå§‹å£°é“æ•°
            source_bit_depth: åŸå§‹ä½æ·±åº¦

        Returns:
            bytes: è½¬æ¢åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            with self._lock:
                # ç±»å‹æ£€æŸ¥å’Œè½¬æ¢
                if isinstance(audio_data, bytes):
                    # å¦‚æœæ˜¯bytesï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
                    try:
                        # å‡è®¾16ä½PCMæ•°æ®
                        audio_data = np.frombuffer(audio_data, dtype=np.int16)
                        logger.debug(f"éŸ³é¢‘æ•°æ®ä»bytesè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œé•¿åº¦: {len(audio_data)}")
                    except Exception as e:
                        logger.error(f"bytesè½¬numpyæ•°ç»„å¤±è´¥: {e}")
                        return b""
                elif not isinstance(audio_data, np.ndarray):
                    logger.error(f"éŸ³é¢‘æ•°æ®å¿…é¡»æ˜¯numpy.ndarrayæˆ–bytesï¼Œä½†å¾—åˆ°: {type(audio_data)}")
                    return b""

                # ç°åœ¨audio_dataä¿è¯æ˜¯numpyæ•°ç»„ï¼Œç»§ç»­å¤„ç†
                # è½¬æ¢ä¸ºå•å£°é“
                if source_channels > 1:
                    audio_data = np.mean(audio_data.reshape(-1, source_channels), axis=1)
                elif source_channels == 0:
                    audio_data = audio_data

                # è½¬æ¢é‡‡æ ·ç‡
                if source_sample_rate != self.config.target_sample_rate:
                    if librosa is not None:
                        audio_data = librosa.resample(
                            audio_data,
                            orig_sr=source_sample_rate,
                            target_sr=self.config.target_sample_rate
                        )
                    else:
                        # ä½¿ç”¨ç®€å•çš„çº¿æ€§æ’å€¼
                        audio_data = self._resample_audio_linear(
                            audio_data,
                            source_sample_rate,
                            self.config.target_sample_rate
                        )

                # è½¬æ¢ä½æ·±åº¦
                if source_bit_depth != self.config.target_bit_depth:
                    audio_data = self._convert_bit_depth(
                        audio_data,
                        source_bit_depth,
                        self.config.target_bit_depth
                    )

                # å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´
                audio_data = np.clip(audio_data / 32768.0, -1.0, 1.0)

                # è½¬æ¢ä¸ºå­—èŠ‚æµ
                if self.config.target_format.lower() == "pcm":
                    return self._convert_to_pcm(audio_data)
                elif self.config.target_format.lower() == "wav":
                    return self._convert_to_wav(audio_data)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {self.config.target_format}")

        except Exception as e:
            logger.error(f"éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            return b""

    def _resample_audio_linear(self, audio_data: np.ndarray, source_sr: int, target_sr: int) -> np.ndarray:
        """çº¿æ€§æ’å€¼é‡é‡‡æ ·"""
        try:
            # è®¡ç®—é‡é‡‡æ ·æ¯”ä¾‹
            ratio = target_sr / source_sr
            target_length = int(len(audio_data) * ratio)

            # çº¿æ€§æ’å€¼
            indices = np.linspace(0, len(audio_data) - 1, target_length)
            return np.interp(indices, np.arange(len(audio_data)), audio_data)
        except Exception as e:
            logger.error(f"çº¿æ€§é‡é‡‡æ ·å¤±è´¥: {e}")
            return audio_data

    def _convert_bit_depth(self, audio_data: np.ndarray, source_depth: int, target_depth: int) -> np.ndarray:
        """è½¬æ¢ä½æ·±åº¦"""
        try:
            if source_depth == 16 and target_depth == 16:
                return audio_data
            elif source_depth == 32 and target_depth == 16:
                return (audio_data / 65536.0).astype(np.float32)
            elif source_depth == 16 and target_depth == 32:
                return (audio_data * 65536.0).astype(np.int32)
            else:
                # é€šç”¨è½¬æ¢
                max_val = 2 ** (source_depth - 1)
                target_max_val = 2 ** (target_depth - 1)
                return (audio_data / max_val * target_max_val).astype(np.int16 if target_depth == 16 else np.int32)
        except Exception as e:
            logger.error(f"ä½æ·±åº¦è½¬æ¢å¤±è´¥: {e}")
            return audio_data

    def _convert_to_pcm(self, audio_data: np.ndarray) -> bytes:
        """è½¬æ¢ä¸ºPCMæ ¼å¼"""
        try:
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            pcm_data = (audio_data * 32767).astype(np.int16)
            return pcm_data.tobytes()
        except Exception as e:
            logger.error(f"PCMè½¬æ¢å¤±è´¥: {e}")
            return b""

    def _convert_to_wav(self, audio_data: np.ndarray) -> bytes:
        """è½¬æ¢ä¸ºWAVæ ¼å¼"""
        try:
            buffer = io.BytesIO()

            with wave.open(buffer, 'wb') as wav_file:
                wav_file.setnchannels(self.config.target_channels)
                wav_file.setsampwidth(self.config.target_bit_depth // 8)
                wav_file.setframerate(self.config.target_sample_rate)
                wav_file.writeframes(audio_data.astype(np.int16))

            return buffer.getvalue()
        except Exception as e:
            logger.error(f"WAVè½¬æ¢å¤±è´¥: {e}")
            return b""

    def convert_to_base64(self, audio_bytes: bytes) -> str:
        """
        è½¬æ¢ä¸ºBase64æ ¼å¼

        Args:
            audio_bytes: éŸ³é¢‘å­—èŠ‚æ•°æ®

        Returns:
            str: Base64ç¼–ç çš„å­—ç¬¦ä¸²
        """
        try:
            return base64.b64encode(audio_bytes).decode('utf-8')
        except Exception as e:
            logger.error(f"Base64è½¬æ¢å¤±è´¥: {e}")
            return ""

    def detect_voice_activity(self, audio_data: np.ndarray, sample_rate: int) -> np.ndarray:
        """
        è¯­éŸ³æ´»åŠ¨æ£€æµ‹

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡

        Returns:
            np.ndarray: VADæ ‡è®°
        """
        try:
            # ç®€å•çš„èƒ½é‡VAD
            frame_length = min(len(audio_data), 1024)
            hop_length = 512

            frames = []
            for i in range(0, len(audio_data) - frame_length + 1, hop_length):
                frame = audio_data[i:i + frame_length]
                energy = np.sum(frame ** 2)
                frames.append(energy)

            if not frames:
                return np.array([True])  # ç©ºéŸ³é¢‘é»˜è®¤å‡è®¾ä¸ºè¯­éŸ³

            # å½’ä¸€åŒ–èƒ½é‡
            energy_array = np.array(frames)
            max_energy = np.max(energy_array)
            if max_energy > 0:
                normalized_energy = energy_array / max_energy
            else:
                normalized_energy = energy_array

            # åº”ç”¨é˜ˆå€¼
            vad_flags = normalized_energy > self.config.vad_threshold

            return vad_flags

        except Exception as e:
            logger.error(f"VADæ£€æµ‹å¤±è´¥: {e}")
            return np.array([True] * (len(audio_data) // 512))  # é»˜è®¤å‡è®¾ä¸ºè¯­éŸ³

    def segment_audio(self, audio_data: np.ndarray, sample_rate: int) -> List[AudioSegment]:
        """
        åˆ†å‰²éŸ³é¢‘ä¸ºè¯­éŸ³æ®µ

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡

        Returns:
            List[AudioSegment]: éŸ³é¢‘æ®µåˆ—è¡¨
        """
        try:
            segments = []

            # æ£€æµ‹è¯­éŸ³æ´»åŠ¨
            vad_flags = self.detect_voice_activity(audio_data, sample_rate)
            frame_length = min(len(audio_data), 1024)
            hop_length = 512

            # ç”ŸæˆéŸ³é¢‘æ®µ
            i = 0
            while i < len(audio_data):
                if i + frame_length > len(audio_data):
                    break

                frame = audio_data[i:i + frame_length]
                is_speech = i // hop_length < len(vad_flags) and vad_flags[i // hop_length]

                start_time = i / sample_rate
                end_time = (i + len(frame)) / sample_rate
                duration = end_time - start_time

                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°/æœ€å¤§æ—¶é•¿è¦æ±‚
                if duration >= self.config.min_segment_duration and duration <= self.config.max_segment_duration:
                    energy = np.sum(frame ** 2)
                    segment = AudioSegment(
                        data=frame,
                        sample_rate=sample_rate,
                        start_time=start_time,
                        end_time=end_time,
                        energy=energy,
                        is_speech=is_speech,
                        confidence=0.8 if is_speech else 0.2
                    )
                    segments.append(segment)

                i += hop_length

            # åˆå¹¶ç›¸é‚»çš„è¯­éŸ³æ®µ
            merged_segments = self._merge_adjacent_segments(segments)

            logger.info(f"éŸ³é¢‘åˆ†å‰²å®Œæˆ: {len(merged_segments)} ä¸ªæ®µ")
            return merged_segments

        except Exception as e:
            logger.error(f"éŸ³é¢‘åˆ†å‰²å¤±è´¥: {e}")
            return []

    def _merge_adjacent_segments(self, segments: List[AudioSegment]) -> List[AudioSegment]:
        """åˆå¹¶ç›¸é‚»çš„éŸ³é¢‘æ®µ"""
        if not segments:
            return []

        merged = [segments[0]]

        for current in segments[1:]:
            last = merged[-1]

            # æ£€æŸ¥æ˜¯å¦ç›¸é‚»ä¸”éƒ½æ˜¯è¯­éŸ³
            if (current.is_speech and last.is_speech and
                current.start_time - last.end_time < 0.5):  # é—´éš”å°äº0.5ç§’
                # åˆå¹¶æ®µ
                merged_data = np.concatenate([last.data, current.data])
                merged[-1] = AudioSegment(
                    data=merged_data,
                    sample_rate=current.sample_rate,
                    start_time=last.start_time,
                    end_time=current.end_time,
                    energy=last.energy + current.energy,
                    is_speech=True,
                    confidence=(last.confidence + current.confidence) / 2
                )
            else:
                merged.append(current)

        return merged

    def process_audio_batch(self, audio_batch: List[Tuple[np.ndarray, int]]) -> List[bytes]:
        """
        æ‰¹é‡å¤„ç†éŸ³é¢‘æ•°æ®

        Args:
            audio_batch: éŸ³é¢‘æ‰¹æ¬¡ [(audio_data, sample_rate), ...]

        Returns:
            List[bytes]: å¤„ç†åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            processed_audio = []

            for audio_data, sample_rate in audio_batch:
                # è½¬æ¢æ ¼å¼
                audio_bytes = self.convert_audio_format(
                    audio_data, sample_rate
                )

                if audio_bytes:
                    processed_audio.append(audio_bytes)

            logger.info(f"æ‰¹é‡éŸ³é¢‘å¤„ç†å®Œæˆ: {len(processed_audio)}/{len(audio_batch)} ä¸ªéŸ³é¢‘")
            return processed_audio

        except Exception as e:
            logger.error(f"æ‰¹é‡éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
            return []

    def add_audio_to_buffer(self, audio_data: np.ndarray, sample_rate: int) -> bool:
        """
        æ·»åŠ éŸ³é¢‘åˆ°ç¼“å†²åŒº

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡

        Returns:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # è½¬æ¢ä¸ºASRæ ¼å¼
            audio_bytes = self.convert_audio_format(audio_data, sample_rate)

            if audio_bytes:
                self.audio_buffer.put(audio_bytes)
                return True

            return False

        except Exception as e:
            logger.error(f"æ·»åŠ éŸ³é¢‘åˆ°ç¼“å†²åŒºå¤±è´¥: {e}")
            return False

    def get_processed_audio(self, timeout: float = 1.0) -> Optional[bytes]:
        """
        ä»å¤„ç†é˜Ÿåˆ—è·å–éŸ³é¢‘

        Args:
            timeout: è¶…æ—¶æ—¶é—´(ç§’)

        Returns:
            bytes: å¤„ç†åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            return self.processed_segments.get(timeout=timeout)
        except Empty:
            return None

    def start_processing(self) -> None:
        """å¼€å§‹éŸ³é¢‘å¤„ç†"""
        with self._lock:
            self.is_processing = True
        logger.info("å¼€å§‹ASRéŸ³é¢‘å¤„ç†")

    def stop_processing(self) -> None:
        """åœæ­¢éŸ³é¢‘å¤„ç†"""
        with self._lock:
            self.is_processing = False
        logger.info("åœæ­¢ASRéŸ³é¢‘å¤„ç†")

    def get_processing_statistics(self) -> Dict[str, Any]:
        """
        è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        with self._lock:
            return {
                "is_processing": self.is_processing,
                "total_samples_processed": self.total_samples_processed,
                "total_duration_processed": self.total_duration_processed,
                "buffer_size": self.audio_buffer.qsize(),
                "processed_segments_count": self.processed_segments.qsize(),
                "target_sample_rate": self.config.target_sample_rate,
                "target_format": self.config.target_format
            }

    def reset_statistics(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            self.total_samples_processed = 0
            self.total_duration_processed = 0.0
        logger.info("ASRéŸ³é¢‘å¤„ç†ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")


# å·¥å‚å‡½æ•°
def create_asr_audio_processor(sample_rate: int = 16000,
                              format: str = "pcm",
                              **kwargs) -> ASRAudioProcessor:
    """
    åˆ›å»ºASRéŸ³é¢‘å¤„ç†å™¨çš„å·¥å‚å‡½æ•°

    Args:
        sample_rate: é‡‡æ ·ç‡
        format: éŸ³é¢‘æ ¼å¼
        **kwargs: å…¶ä»–é…ç½®å‚æ•°

    Returns:
        ASRAudioProcessor: ASRéŸ³é¢‘å¤„ç†å™¨å®ä¾‹
    """
    config = ASRAudioConfig(
        target_sample_rate=sample_rate,
        target_format=format,
        **kwargs
    )

    return ASRAudioProcessor(config)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    print("ğŸµ ASRéŸ³é¢‘å¤„ç†å™¨æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºå¤„ç†å™¨
    processor = create_asr_audio_processor(
        sample_rate=16000,
        format="pcm"
    )

    # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
    duration = 5.0
    sample_rate = 16000
    t = np.linspace(0, duration, int(sample_rate * duration))

    # ç”Ÿæˆæ··åˆä¿¡å·ï¼ˆè¯­éŸ³ + é™éŸ³ + å™ªå£°ï¼‰
    speech_signal = 0.5 * np.sin(2 * np.pi * 440 * t)  # è¯­éŸ³
    silence_segment = np.zeros(int(sample_rate * 1.0))  # 1ç§’é™éŸ³
    noise_segment = 0.1 * np.random.randn(int(sample_rate * 2.0))  # 2ç§’å™ªå£°

    test_audio = np.concatenate([speech_signal, silence_segment, noise_segment])

    print(f"\nğŸµ æµ‹è¯•éŸ³é¢‘å¤„ç†")
    print(f"éŸ³é¢‘é•¿åº¦: {len(test_audio)} æ ·æœ¬ ({duration:.1f}ç§’)")
    print(f"é‡‡æ ·ç‡: {sample_rate}Hz")

    # è½¬æ¢éŸ³é¢‘æ ¼å¼
    converted_audio = processor.convert_audio_format(test_audio, sample_rate)
    print(f"è½¬æ¢åéŸ³é¢‘å¤§å°: {len(converted_audio)} å­—èŠ‚")

    # éŸ³é¢‘åˆ†å‰²
    segments = processor.segment_audio(test_audio, sample_rate)
    print(f"éŸ³é¢‘åˆ†å‰²ç»“æœ: {len(segments)} ä¸ªæ®µ")

    # æ˜¾ç¤ºæ®µä¿¡æ¯
    for i, segment in enumerate(segments):
        print(f"  æ®µ {i+1}: {segment.start_time:.2f}s - {segment.end_time:.2f}s, "
              f"è¯­éŸ³={segment.is_speech}, èƒ½é‡={segment.energy:.2f}")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = processor.get_processing_statistics()
    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")

    print("âœ… æµ‹è¯•å®Œæˆ")